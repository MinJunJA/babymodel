{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Nnjk0mrD532NCWIyg4u1oO3aaXmsa2Ey",
      "authorship_tag": "ABX9TyMyqbb7/YUMbqgGOZqBss8f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinJunJA/babymodel/blob/master/newdata_crnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ndnt2MBp9jLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PSf_HfTyRGq",
        "outputId": "85a2c523-6086-483c-f7b4-f901ba40d3d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=63\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=63\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=63\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "247/247 [==============================] - 23s 16ms/step - loss: 1.5942 - accuracy: 0.3827 - val_loss: 1.6651 - val_accuracy: 0.3505\n",
            "Epoch 2/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 1.4355 - accuracy: 0.4571 - val_loss: 1.3217 - val_accuracy: 0.4977\n",
            "Epoch 3/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.3432 - accuracy: 0.4980 - val_loss: 1.2653 - val_accuracy: 0.5240\n",
            "Epoch 4/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.2482 - accuracy: 0.5469 - val_loss: 1.2380 - val_accuracy: 0.5445\n",
            "Epoch 5/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.1524 - accuracy: 0.5860 - val_loss: 1.1414 - val_accuracy: 0.5776\n",
            "Epoch 6/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 1.0359 - accuracy: 0.6403 - val_loss: 1.1181 - val_accuracy: 0.6119\n",
            "Epoch 7/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.9493 - accuracy: 0.6765 - val_loss: 1.0233 - val_accuracy: 0.6393\n",
            "Epoch 8/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.8490 - accuracy: 0.7119 - val_loss: 1.0364 - val_accuracy: 0.6416\n",
            "Epoch 9/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7530 - accuracy: 0.7523 - val_loss: 0.9609 - val_accuracy: 0.6644\n",
            "Epoch 10/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.6718 - accuracy: 0.7820 - val_loss: 0.9391 - val_accuracy: 0.7032\n",
            "Epoch 11/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.5974 - accuracy: 0.8163 - val_loss: 0.9323 - val_accuracy: 0.6895\n",
            "Epoch 12/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.5171 - accuracy: 0.8370 - val_loss: 0.9047 - val_accuracy: 0.7386\n",
            "Epoch 13/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.4887 - accuracy: 0.8499 - val_loss: 0.8384 - val_accuracy: 0.7580\n",
            "Epoch 14/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4133 - accuracy: 0.8700 - val_loss: 0.8143 - val_accuracy: 0.7717\n",
            "Epoch 15/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3510 - accuracy: 0.8954 - val_loss: 0.8317 - val_accuracy: 0.7774\n",
            "Epoch 16/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3429 - accuracy: 0.8933 - val_loss: 0.8284 - val_accuracy: 0.7717\n",
            "Epoch 17/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3239 - accuracy: 0.9040 - val_loss: 0.7607 - val_accuracy: 0.7911\n",
            "Epoch 18/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.2772 - accuracy: 0.9176 - val_loss: 0.8194 - val_accuracy: 0.7900\n",
            "Epoch 19/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2435 - accuracy: 0.9293 - val_loss: 0.7890 - val_accuracy: 0.7957\n",
            "Epoch 20/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.2419 - accuracy: 0.9248 - val_loss: 0.7860 - val_accuracy: 0.8082\n",
            "Epoch 21/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2047 - accuracy: 0.9399 - val_loss: 0.8247 - val_accuracy: 0.8002\n",
            "Epoch 22/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2393 - accuracy: 0.9304 - val_loss: 0.8512 - val_accuracy: 0.8025\n",
            "Epoch 23/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2020 - accuracy: 0.9399 - val_loss: 0.8004 - val_accuracy: 0.8105\n",
            "Epoch 24/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1870 - accuracy: 0.9444 - val_loss: 0.8196 - val_accuracy: 0.8276\n",
            "Epoch 25/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1797 - accuracy: 0.9462 - val_loss: 0.8540 - val_accuracy: 0.8071\n",
            "Epoch 26/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1501 - accuracy: 0.9570 - val_loss: 0.9278 - val_accuracy: 0.8025\n",
            "Epoch 27/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1562 - accuracy: 0.9540 - val_loss: 0.8558 - val_accuracy: 0.8082\n",
            "Epoch 28/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1391 - accuracy: 0.9598 - val_loss: 0.9737 - val_accuracy: 0.7979\n",
            "Epoch 29/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1533 - accuracy: 0.9562 - val_loss: 0.8953 - val_accuracy: 0.8139\n",
            "Epoch 30/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1857 - accuracy: 0.9443 - val_loss: 0.8289 - val_accuracy: 0.8253\n",
            "Epoch 31/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1403 - accuracy: 0.9580 - val_loss: 0.8301 - val_accuracy: 0.8288\n",
            "Epoch 32/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1256 - accuracy: 0.9648 - val_loss: 0.9179 - val_accuracy: 0.8094\n",
            "Epoch 33/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1179 - accuracy: 0.9655 - val_loss: 0.8499 - val_accuracy: 0.8265\n",
            "Epoch 34/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1365 - accuracy: 0.9619 - val_loss: 0.8674 - val_accuracy: 0.8253\n",
            "Epoch 35/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1336 - accuracy: 0.9620 - val_loss: 0.9217 - val_accuracy: 0.8196\n",
            "Epoch 36/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1152 - accuracy: 0.9685 - val_loss: 0.9844 - val_accuracy: 0.8014\n",
            "Epoch 37/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1345 - accuracy: 0.9632 - val_loss: 0.9018 - val_accuracy: 0.8151\n",
            "Epoch 38/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1066 - accuracy: 0.9691 - val_loss: 0.9323 - val_accuracy: 0.8242\n",
            "Epoch 39/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1086 - accuracy: 0.9694 - val_loss: 0.8619 - val_accuracy: 0.8413\n",
            "Epoch 40/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0936 - accuracy: 0.9736 - val_loss: 0.9837 - val_accuracy: 0.8208\n",
            "Epoch 41/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1057 - accuracy: 0.9702 - val_loss: 0.9458 - val_accuracy: 0.8311\n",
            "Epoch 42/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1361 - accuracy: 0.9611 - val_loss: 0.8515 - val_accuracy: 0.8333\n",
            "Epoch 43/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0926 - accuracy: 0.9728 - val_loss: 0.8850 - val_accuracy: 0.8265\n",
            "Epoch 44/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.0671 - accuracy: 0.9810 - val_loss: 0.9965 - val_accuracy: 0.8185\n",
            "Epoch 45/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0864 - accuracy: 0.9745 - val_loss: 0.9897 - val_accuracy: 0.8253\n",
            "Epoch 46/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0917 - accuracy: 0.9735 - val_loss: 1.0121 - val_accuracy: 0.8208\n",
            "Epoch 47/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0917 - accuracy: 0.9746 - val_loss: 0.9791 - val_accuracy: 0.8311\n",
            "Epoch 48/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0968 - accuracy: 0.9755 - val_loss: 0.9297 - val_accuracy: 0.8265\n",
            "Epoch 49/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1339 - accuracy: 0.9615 - val_loss: 0.8636 - val_accuracy: 0.8208\n",
            "Epoch 50/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0799 - accuracy: 0.9756 - val_loss: 0.9043 - val_accuracy: 0.8265\n",
            "Epoch 51/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0935 - accuracy: 0.9728 - val_loss: 0.9033 - val_accuracy: 0.8265\n",
            "Epoch 52/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0852 - accuracy: 0.9769 - val_loss: 0.9675 - val_accuracy: 0.8231\n",
            "Epoch 53/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1018 - accuracy: 0.9703 - val_loss: 0.9560 - val_accuracy: 0.8196\n",
            "Epoch 54/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.0704 - accuracy: 0.9797 - val_loss: 0.9504 - val_accuracy: 0.8368\n",
            "Epoch 55/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0797 - accuracy: 0.9784 - val_loss: 0.9320 - val_accuracy: 0.8219\n",
            "Epoch 56/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0650 - accuracy: 0.9817 - val_loss: 0.9714 - val_accuracy: 0.8299\n",
            "Epoch 57/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0869 - accuracy: 0.9756 - val_loss: 0.9202 - val_accuracy: 0.8288\n",
            "Epoch 58/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0661 - accuracy: 0.9815 - val_loss: 1.0030 - val_accuracy: 0.8219\n",
            "Epoch 59/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.0625 - accuracy: 0.9817 - val_loss: 1.0544 - val_accuracy: 0.8082\n",
            "Epoch 60/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0628 - accuracy: 0.9821 - val_loss: 0.9548 - val_accuracy: 0.8311\n",
            "Epoch 61/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0860 - accuracy: 0.9759 - val_loss: 0.9749 - val_accuracy: 0.8071\n",
            "Epoch 62/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1123 - accuracy: 0.9675 - val_loss: 0.9326 - val_accuracy: 0.8242\n",
            "Epoch 63/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0804 - accuracy: 0.9780 - val_loss: 1.0152 - val_accuracy: 0.8185\n",
            "Epoch 64/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0814 - accuracy: 0.9780 - val_loss: 0.9842 - val_accuracy: 0.8276\n",
            "Epoch 65/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0809 - accuracy: 0.9770 - val_loss: 0.9752 - val_accuracy: 0.8253\n",
            "Epoch 66/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0648 - accuracy: 0.9822 - val_loss: 0.9922 - val_accuracy: 0.8265\n",
            "Epoch 67/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0669 - accuracy: 0.9803 - val_loss: 1.0373 - val_accuracy: 0.8322\n",
            "Epoch 68/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0850 - accuracy: 0.9760 - val_loss: 0.9646 - val_accuracy: 0.8276\n",
            "Epoch 69/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0956 - accuracy: 0.9738 - val_loss: 1.0005 - val_accuracy: 0.8105\n",
            "Epoch 70/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0615 - accuracy: 0.9822 - val_loss: 0.9623 - val_accuracy: 0.8288\n",
            "Epoch 71/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0633 - accuracy: 0.9818 - val_loss: 1.0057 - val_accuracy: 0.8253\n",
            "Epoch 72/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0745 - accuracy: 0.9807 - val_loss: 0.9882 - val_accuracy: 0.8219\n",
            "Epoch 73/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0490 - accuracy: 0.9846 - val_loss: 1.0835 - val_accuracy: 0.8242\n",
            "Epoch 74/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0568 - accuracy: 0.9853 - val_loss: 1.0717 - val_accuracy: 0.8265\n",
            "Epoch 75/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0964 - accuracy: 0.9744 - val_loss: 0.9358 - val_accuracy: 0.8368\n",
            "Epoch 76/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0515 - accuracy: 0.9872 - val_loss: 1.0303 - val_accuracy: 0.8299\n",
            "Epoch 77/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1029 - accuracy: 0.9702 - val_loss: 1.0167 - val_accuracy: 0.8276\n",
            "Epoch 78/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1045 - accuracy: 0.9704 - val_loss: 0.9387 - val_accuracy: 0.8333\n",
            "Epoch 79/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0418 - accuracy: 0.9895 - val_loss: 0.9927 - val_accuracy: 0.8299\n",
            "Epoch 80/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0589 - accuracy: 0.9841 - val_loss: 1.0538 - val_accuracy: 0.8311\n",
            "Epoch 81/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0870 - accuracy: 0.9769 - val_loss: 1.0138 - val_accuracy: 0.8288\n",
            "Epoch 82/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0921 - accuracy: 0.9760 - val_loss: 1.0320 - val_accuracy: 0.8345\n",
            "Epoch 83/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0457 - accuracy: 0.9872 - val_loss: 1.0562 - val_accuracy: 0.8219\n",
            "Epoch 84/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0486 - accuracy: 0.9850 - val_loss: 1.1399 - val_accuracy: 0.8231\n",
            "Epoch 85/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0466 - accuracy: 0.9870 - val_loss: 1.0460 - val_accuracy: 0.8311\n",
            "Epoch 86/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0405 - accuracy: 0.9878 - val_loss: 1.1543 - val_accuracy: 0.8128\n",
            "Epoch 87/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0581 - accuracy: 0.9837 - val_loss: 1.0711 - val_accuracy: 0.8276\n",
            "Epoch 88/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0615 - accuracy: 0.9831 - val_loss: 1.0898 - val_accuracy: 0.8276\n",
            "Epoch 89/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0462 - accuracy: 0.9872 - val_loss: 1.0901 - val_accuracy: 0.8333\n",
            "Epoch 90/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0468 - accuracy: 0.9874 - val_loss: 1.0758 - val_accuracy: 0.8299\n",
            "Epoch 91/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0642 - accuracy: 0.9829 - val_loss: 1.0929 - val_accuracy: 0.8253\n",
            "Epoch 92/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.0608 - accuracy: 0.9844 - val_loss: 1.1031 - val_accuracy: 0.8208\n",
            "Epoch 93/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0812 - accuracy: 0.9785 - val_loss: 1.0157 - val_accuracy: 0.8311\n",
            "Epoch 94/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0534 - accuracy: 0.9857 - val_loss: 1.1444 - val_accuracy: 0.8174\n",
            "Epoch 95/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0680 - accuracy: 0.9806 - val_loss: 1.0412 - val_accuracy: 0.8242\n",
            "Epoch 96/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0494 - accuracy: 0.9865 - val_loss: 0.9592 - val_accuracy: 0.8322\n",
            "Epoch 97/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0573 - accuracy: 0.9844 - val_loss: 1.0341 - val_accuracy: 0.8219\n",
            "Epoch 98/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0592 - accuracy: 0.9841 - val_loss: 1.1004 - val_accuracy: 0.8185\n",
            "Epoch 99/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0392 - accuracy: 0.9896 - val_loss: 1.0664 - val_accuracy: 0.8174\n",
            "Epoch 100/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0676 - accuracy: 0.9816 - val_loss: 1.0088 - val_accuracy: 0.8311\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 1.2364 - accuracy: 0.8004\n",
            "Accuracy: 0.8003654479980469\n"
          ]
        }
      ],
      "source": [
        "#crnn3 - 데이터 증강\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
        "\n",
        "# 데이터셋 디렉토리 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 클래스 레이블 설정 (클래스별 디렉토리 이름으로 가정)\n",
        "class_labels = os.listdir(data_dir)\n",
        "\n",
        "# MFCC 계수 개수 설정\n",
        "n_mfcc = 12\n",
        "\n",
        "# 데이터셋과 레이블을 저장할 리스트\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        X.append(mfccs.T)\n",
        "        labels.append(label)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X = np.array(X)\n",
        "\n",
        "# 레이블을 정수형으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(class_labels)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# 최대 길이에 맞춰 MFCC 벡터를 패딩\n",
        "max_length = max(len(mfccs) for mfccs in X)\n",
        "X = np.array([np.pad(mfccs, ((0, max_length - len(mfccs)), (0, 0)), mode='constant') for mfccs in X])\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 증강 생성기 설정\n",
        "audio_augmentations = Compose([\n",
        "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.01),\n",
        "    TimeStretch(min_rate=0.8, max_rate=1.25),\n",
        "    PitchShift(min_semitones=-4, max_semitones=4),\n",
        "    Shift(min_fraction=-0.2, max_fraction=0.2)\n",
        "])\n",
        "\n",
        "# 오디오 데이터 증강 함수\n",
        "def augment_audio(audio):\n",
        "    return audio_augmentations(samples=audio, sample_rate=16000)\n",
        "\n",
        "# 증강된 오디오 데이터 생성\n",
        "X_train_augmented = np.array([augment_audio(np.transpose(audio)) for audio in X_train])\n",
        "X_train_augmented = np.array([np.transpose(audio) for audio in X_train_augmented])\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())  # BatchNormalization 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())  # BatchNormalization 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(BatchNormalization())  # BatchNormalization 추가\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경\n",
        "model.add(Reshape((X_train.shape[1] // 8, (X_train.shape[2] // 8) * 256)))  # Reshape 추가\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audiomentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw00RMcHzC-u",
        "outputId": "92f2f19a-c3e8-4da4-c782-75d24f9c9852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.31.0-py3-none-any.whl (70 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/70.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.23.5)\n",
            "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.10.0.post2)\n",
            "Requirement already satisfied: scipy<2,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.10.1)\n",
            "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.3.5)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2023.7.22)\n",
            "Installing collected packages: audiomentations\n",
            "Successfully installed audiomentations-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CRNN2\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "# 데이터셋 디렉토리 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 클래스 레이블 설정 (클래스별 디렉토리 이름으로 가정)\n",
        "class_labels = os.listdir(data_dir)\n",
        "\n",
        "# MFCC 계수 개수 설정\n",
        "n_mfcc = 12\n",
        "\n",
        "# 데이터셋과 레이블을 저장할 리스트\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        X.append(mfccs.T)\n",
        "        labels.append(label)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X = np.array(X)\n",
        "\n",
        "# 레이블을 정수형으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(class_labels)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# 최대 길이에 맞춰 MFCC 벡터를 패딩\n",
        "max_length = max(len(mfccs) for mfccs in X)\n",
        "X = np.array([np.pad(mfccs, ((0, max_length - len(mfccs)), (0, 0)), mode='constant') for mfccs in X])\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())  # BatchNormalization 추가\n",
        "\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())  # BatchNormalization 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(BatchNormalization())  # BatchNormalization 추가\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경\n",
        "model.add(Reshape((X_train.shape[1] // 8, (X_train.shape[2] // 8) * 256)))  # Reshape 추가\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Col6xcvvzE-K",
        "outputId": "36c433d0-e30d-413a-e968-257ea3de390e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "247/247 [==============================] - 11s 15ms/step - loss: 1.6055 - accuracy: 0.3626 - val_loss: 1.4459 - val_accuracy: 0.4247\n",
            "Epoch 2/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.4522 - accuracy: 0.4460 - val_loss: 1.3488 - val_accuracy: 0.4977\n",
            "Epoch 3/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.3592 - accuracy: 0.4949 - val_loss: 1.2937 - val_accuracy: 0.5171\n",
            "Epoch 4/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2503 - accuracy: 0.5463 - val_loss: 1.2009 - val_accuracy: 0.5559\n",
            "Epoch 5/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.1690 - accuracy: 0.5814 - val_loss: 1.1799 - val_accuracy: 0.5708\n",
            "Epoch 6/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.0632 - accuracy: 0.6301 - val_loss: 1.1272 - val_accuracy: 0.5811\n",
            "Epoch 7/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.9784 - accuracy: 0.6662 - val_loss: 1.0622 - val_accuracy: 0.6267\n",
            "Epoch 8/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.8803 - accuracy: 0.7053 - val_loss: 0.9897 - val_accuracy: 0.6621\n",
            "Epoch 9/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.7895 - accuracy: 0.7348 - val_loss: 1.0606 - val_accuracy: 0.6404\n",
            "Epoch 10/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.7104 - accuracy: 0.7673 - val_loss: 1.0122 - val_accuracy: 0.6861\n",
            "Epoch 11/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6342 - accuracy: 0.7924 - val_loss: 1.0116 - val_accuracy: 0.6918\n",
            "Epoch 12/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.5570 - accuracy: 0.8254 - val_loss: 0.8822 - val_accuracy: 0.7226\n",
            "Epoch 13/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.4928 - accuracy: 0.8525 - val_loss: 0.8858 - val_accuracy: 0.7329\n",
            "Epoch 14/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.4306 - accuracy: 0.8693 - val_loss: 0.8437 - val_accuracy: 0.7603\n",
            "Epoch 15/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4074 - accuracy: 0.8740 - val_loss: 0.8523 - val_accuracy: 0.7637\n",
            "Epoch 16/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3587 - accuracy: 0.8942 - val_loss: 0.8090 - val_accuracy: 0.7831\n",
            "Epoch 17/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.3141 - accuracy: 0.9067 - val_loss: 0.8081 - val_accuracy: 0.7717\n",
            "Epoch 18/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.2989 - accuracy: 0.9121 - val_loss: 0.8624 - val_accuracy: 0.7763\n",
            "Epoch 19/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.3096 - accuracy: 0.9088 - val_loss: 0.8996 - val_accuracy: 0.7808\n",
            "Epoch 20/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.2621 - accuracy: 0.9239 - val_loss: 0.8363 - val_accuracy: 0.7991\n",
            "Epoch 21/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2360 - accuracy: 0.9292 - val_loss: 0.9557 - val_accuracy: 0.7797\n",
            "Epoch 22/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2090 - accuracy: 0.9402 - val_loss: 0.8953 - val_accuracy: 0.7991\n",
            "Epoch 23/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.2117 - accuracy: 0.9359 - val_loss: 0.9170 - val_accuracy: 0.8037\n",
            "Epoch 24/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2056 - accuracy: 0.9378 - val_loss: 0.8660 - val_accuracy: 0.8014\n",
            "Epoch 25/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1703 - accuracy: 0.9520 - val_loss: 0.8941 - val_accuracy: 0.8151\n",
            "Epoch 26/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2048 - accuracy: 0.9382 - val_loss: 0.9307 - val_accuracy: 0.7922\n",
            "Epoch 27/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1793 - accuracy: 0.9479 - val_loss: 0.8991 - val_accuracy: 0.8025\n",
            "Epoch 28/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1528 - accuracy: 0.9547 - val_loss: 0.9193 - val_accuracy: 0.8059\n",
            "Epoch 29/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1487 - accuracy: 0.9580 - val_loss: 0.9822 - val_accuracy: 0.8025\n",
            "Epoch 30/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1380 - accuracy: 0.9611 - val_loss: 0.8758 - val_accuracy: 0.8208\n",
            "Epoch 31/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1449 - accuracy: 0.9572 - val_loss: 0.8818 - val_accuracy: 0.8082\n",
            "Epoch 32/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1343 - accuracy: 0.9606 - val_loss: 0.9602 - val_accuracy: 0.8208\n",
            "Epoch 33/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1426 - accuracy: 0.9575 - val_loss: 0.9263 - val_accuracy: 0.8048\n",
            "Epoch 34/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1197 - accuracy: 0.9671 - val_loss: 1.0725 - val_accuracy: 0.7922\n",
            "Epoch 35/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1868 - accuracy: 0.9453 - val_loss: 0.9650 - val_accuracy: 0.8174\n",
            "Epoch 36/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1503 - accuracy: 0.9557 - val_loss: 0.9414 - val_accuracy: 0.8048\n",
            "Epoch 37/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0916 - accuracy: 0.9751 - val_loss: 0.8870 - val_accuracy: 0.8322\n",
            "Epoch 38/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1179 - accuracy: 0.9658 - val_loss: 0.9386 - val_accuracy: 0.8139\n",
            "Epoch 39/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0982 - accuracy: 0.9713 - val_loss: 1.0170 - val_accuracy: 0.8231\n",
            "Epoch 40/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0880 - accuracy: 0.9782 - val_loss: 1.0085 - val_accuracy: 0.8219\n",
            "Epoch 41/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0983 - accuracy: 0.9722 - val_loss: 1.0213 - val_accuracy: 0.8196\n",
            "Epoch 42/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1041 - accuracy: 0.9724 - val_loss: 1.0014 - val_accuracy: 0.8037\n",
            "Epoch 43/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1096 - accuracy: 0.9685 - val_loss: 0.9674 - val_accuracy: 0.8116\n",
            "Epoch 44/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1470 - accuracy: 0.9554 - val_loss: 0.9080 - val_accuracy: 0.8265\n",
            "Epoch 45/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0940 - accuracy: 0.9731 - val_loss: 0.9836 - val_accuracy: 0.8196\n",
            "Epoch 46/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0906 - accuracy: 0.9736 - val_loss: 0.9595 - val_accuracy: 0.8299\n",
            "Epoch 47/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0839 - accuracy: 0.9774 - val_loss: 1.0188 - val_accuracy: 0.8265\n",
            "Epoch 48/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0898 - accuracy: 0.9745 - val_loss: 1.1246 - val_accuracy: 0.7968\n",
            "Epoch 49/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1005 - accuracy: 0.9719 - val_loss: 1.0218 - val_accuracy: 0.8276\n",
            "Epoch 50/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1379 - accuracy: 0.9618 - val_loss: 0.9113 - val_accuracy: 0.8208\n",
            "Epoch 51/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0985 - accuracy: 0.9721 - val_loss: 0.9709 - val_accuracy: 0.8208\n",
            "Epoch 52/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0793 - accuracy: 0.9798 - val_loss: 0.9816 - val_accuracy: 0.8299\n",
            "Epoch 53/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0857 - accuracy: 0.9727 - val_loss: 1.0164 - val_accuracy: 0.8219\n",
            "Epoch 54/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.0818 - accuracy: 0.9787 - val_loss: 1.0101 - val_accuracy: 0.8174\n",
            "Epoch 55/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1162 - accuracy: 0.9678 - val_loss: 0.9467 - val_accuracy: 0.8253\n",
            "Epoch 56/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0575 - accuracy: 0.9826 - val_loss: 0.9833 - val_accuracy: 0.8322\n",
            "Epoch 57/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0632 - accuracy: 0.9818 - val_loss: 1.0146 - val_accuracy: 0.8208\n",
            "Epoch 58/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0988 - accuracy: 0.9723 - val_loss: 1.0131 - val_accuracy: 0.8219\n",
            "Epoch 59/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0552 - accuracy: 0.9840 - val_loss: 1.0111 - val_accuracy: 0.8265\n",
            "Epoch 60/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0830 - accuracy: 0.9763 - val_loss: 0.9623 - val_accuracy: 0.8356\n",
            "Epoch 61/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0744 - accuracy: 0.9796 - val_loss: 1.0668 - val_accuracy: 0.8299\n",
            "Epoch 62/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1040 - accuracy: 0.9703 - val_loss: 0.9576 - val_accuracy: 0.8253\n",
            "Epoch 63/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0857 - accuracy: 0.9768 - val_loss: 1.0573 - val_accuracy: 0.8219\n",
            "Epoch 64/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0689 - accuracy: 0.9818 - val_loss: 0.9860 - val_accuracy: 0.8356\n",
            "Epoch 65/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0812 - accuracy: 0.9777 - val_loss: 0.9953 - val_accuracy: 0.8128\n",
            "Epoch 66/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0847 - accuracy: 0.9759 - val_loss: 0.9953 - val_accuracy: 0.8174\n",
            "Epoch 67/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0701 - accuracy: 0.9808 - val_loss: 0.9997 - val_accuracy: 0.8219\n",
            "Epoch 68/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0734 - accuracy: 0.9793 - val_loss: 1.0225 - val_accuracy: 0.8219\n",
            "Epoch 69/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0662 - accuracy: 0.9817 - val_loss: 1.0453 - val_accuracy: 0.8105\n",
            "Epoch 70/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0855 - accuracy: 0.9754 - val_loss: 0.9952 - val_accuracy: 0.8356\n",
            "Epoch 71/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0676 - accuracy: 0.9807 - val_loss: 1.0737 - val_accuracy: 0.8174\n",
            "Epoch 72/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0735 - accuracy: 0.9806 - val_loss: 1.1067 - val_accuracy: 0.8151\n",
            "Epoch 73/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0779 - accuracy: 0.9787 - val_loss: 1.0829 - val_accuracy: 0.8116\n",
            "Epoch 74/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0719 - accuracy: 0.9798 - val_loss: 1.2304 - val_accuracy: 0.8128\n",
            "Epoch 75/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0599 - accuracy: 0.9824 - val_loss: 1.1437 - val_accuracy: 0.8151\n",
            "Epoch 76/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0836 - accuracy: 0.9771 - val_loss: 1.1736 - val_accuracy: 0.8265\n",
            "Epoch 77/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0701 - accuracy: 0.9802 - val_loss: 1.0596 - val_accuracy: 0.8196\n",
            "Epoch 78/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0753 - accuracy: 0.9797 - val_loss: 1.1347 - val_accuracy: 0.8185\n",
            "Epoch 79/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0648 - accuracy: 0.9845 - val_loss: 1.1015 - val_accuracy: 0.8128\n",
            "Epoch 80/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1154 - accuracy: 0.9694 - val_loss: 1.0447 - val_accuracy: 0.8105\n",
            "Epoch 81/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.0586 - accuracy: 0.9826 - val_loss: 1.1128 - val_accuracy: 0.8231\n",
            "Epoch 82/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0686 - accuracy: 0.9834 - val_loss: 1.1469 - val_accuracy: 0.8048\n",
            "Epoch 83/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0529 - accuracy: 0.9865 - val_loss: 1.1605 - val_accuracy: 0.8151\n",
            "Epoch 84/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 1.1886 - val_accuracy: 0.8196\n",
            "Epoch 85/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0635 - accuracy: 0.9837 - val_loss: 1.1171 - val_accuracy: 0.8185\n",
            "Epoch 86/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0683 - accuracy: 0.9811 - val_loss: 1.1297 - val_accuracy: 0.8231\n",
            "Epoch 87/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0516 - accuracy: 0.9868 - val_loss: 1.1510 - val_accuracy: 0.8219\n",
            "Epoch 88/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0676 - accuracy: 0.9802 - val_loss: 1.1026 - val_accuracy: 0.8162\n",
            "Epoch 89/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0592 - accuracy: 0.9836 - val_loss: 1.0918 - val_accuracy: 0.8174\n",
            "Epoch 90/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0604 - accuracy: 0.9839 - val_loss: 1.1126 - val_accuracy: 0.8174\n",
            "Epoch 91/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0634 - accuracy: 0.9843 - val_loss: 1.1082 - val_accuracy: 0.8242\n",
            "Epoch 92/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.0860 - accuracy: 0.9782 - val_loss: 1.0615 - val_accuracy: 0.8208\n",
            "Epoch 93/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0460 - accuracy: 0.9862 - val_loss: 1.1502 - val_accuracy: 0.8231\n",
            "Epoch 94/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1131 - accuracy: 0.9707 - val_loss: 1.0854 - val_accuracy: 0.8174\n",
            "Epoch 95/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0609 - accuracy: 0.9837 - val_loss: 1.0480 - val_accuracy: 0.8196\n",
            "Epoch 96/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0635 - accuracy: 0.9846 - val_loss: 1.0264 - val_accuracy: 0.8436\n",
            "Epoch 97/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0470 - accuracy: 0.9881 - val_loss: 1.1207 - val_accuracy: 0.8242\n",
            "Epoch 98/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0406 - accuracy: 0.9877 - val_loss: 1.1553 - val_accuracy: 0.8333\n",
            "Epoch 99/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0860 - accuracy: 0.9763 - val_loss: 1.0883 - val_accuracy: 0.8139\n",
            "Epoch 100/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0385 - accuracy: 0.9900 - val_loss: 1.1687 - val_accuracy: 0.8174\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 1.2257 - accuracy: 0.8054\n",
            "Accuracy: 0.8053905963897705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropout 추가\n",
        "\n",
        "#CRNN\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "# 데이터셋 디렉토리 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 클래스 레이블 설정 (클래스별 디렉토리 이름으로 가정)\n",
        "class_labels = os.listdir(data_dir)\n",
        "\n",
        "# MFCC 계수 개수 설정\n",
        "n_mfcc = 12\n",
        "\n",
        "# 데이터셋과 레이블을 저장할 리스트\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        X.append(mfccs.T)\n",
        "        labels.append(label)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X = np.array(X)\n",
        "\n",
        "# 레이블을 정수형으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(class_labels)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# 최대 길이에 맞춰 MFCC 벡터를 패딩\n",
        "max_length = max(len(mfccs) for mfccs in X)\n",
        "X = np.array([np.pad(mfccs, ((0, max_length - len(mfccs)), (0, 0)), mode='constant') for mfccs in X])\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경\n",
        "model.add(Reshape((X_train.shape[1] // 8, (X_train.shape[2] // 8) * 256)))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "air-xUUHBTtP",
        "outputId": "8b2cbb41-e27f-44fd-b1eb-f3c12203f7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "247/247 [==============================] - 23s 16ms/step - loss: 1.6196 - accuracy: 0.3493 - val_loss: 1.4711 - val_accuracy: 0.4361\n",
            "Epoch 2/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.4969 - accuracy: 0.4121 - val_loss: 1.4166 - val_accuracy: 0.4635\n",
            "Epoch 3/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.4234 - accuracy: 0.4490 - val_loss: 1.3223 - val_accuracy: 0.4909\n",
            "Epoch 4/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.3635 - accuracy: 0.4870 - val_loss: 1.2268 - val_accuracy: 0.5320\n",
            "Epoch 5/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.3045 - accuracy: 0.5130 - val_loss: 1.2204 - val_accuracy: 0.5400\n",
            "Epoch 6/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.2382 - accuracy: 0.5389 - val_loss: 1.1951 - val_accuracy: 0.5639\n",
            "Epoch 7/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.1955 - accuracy: 0.5593 - val_loss: 1.1253 - val_accuracy: 0.5856\n",
            "Epoch 8/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.1627 - accuracy: 0.5739 - val_loss: 1.1208 - val_accuracy: 0.5936\n",
            "Epoch 9/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.1082 - accuracy: 0.5959 - val_loss: 1.0890 - val_accuracy: 0.6164\n",
            "Epoch 10/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.0695 - accuracy: 0.6209 - val_loss: 1.0315 - val_accuracy: 0.6199\n",
            "Epoch 11/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.0344 - accuracy: 0.6332 - val_loss: 1.0480 - val_accuracy: 0.6244\n",
            "Epoch 12/100\n",
            "247/247 [==============================] - 6s 23ms/step - loss: 1.0014 - accuracy: 0.6464 - val_loss: 1.0629 - val_accuracy: 0.6153\n",
            "Epoch 13/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.9584 - accuracy: 0.6615 - val_loss: 1.0079 - val_accuracy: 0.6484\n",
            "Epoch 14/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9345 - accuracy: 0.6718 - val_loss: 0.9376 - val_accuracy: 0.6667\n",
            "Epoch 15/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.8990 - accuracy: 0.6893 - val_loss: 0.9733 - val_accuracy: 0.6416\n",
            "Epoch 16/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8868 - accuracy: 0.6922 - val_loss: 0.9233 - val_accuracy: 0.6678\n",
            "Epoch 17/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8268 - accuracy: 0.7164 - val_loss: 0.8852 - val_accuracy: 0.6838\n",
            "Epoch 18/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8115 - accuracy: 0.7231 - val_loss: 0.8590 - val_accuracy: 0.7032\n",
            "Epoch 19/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7840 - accuracy: 0.7316 - val_loss: 0.8756 - val_accuracy: 0.7032\n",
            "Epoch 20/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.7795 - accuracy: 0.7339 - val_loss: 0.8966 - val_accuracy: 0.6918\n",
            "Epoch 21/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7253 - accuracy: 0.7575 - val_loss: 0.8503 - val_accuracy: 0.7043\n",
            "Epoch 22/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7340 - accuracy: 0.7472 - val_loss: 0.8207 - val_accuracy: 0.7237\n",
            "Epoch 23/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7120 - accuracy: 0.7602 - val_loss: 0.8052 - val_accuracy: 0.7340\n",
            "Epoch 24/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6553 - accuracy: 0.7776 - val_loss: 0.8140 - val_accuracy: 0.7260\n",
            "Epoch 25/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.6862 - accuracy: 0.7651 - val_loss: 0.8243 - val_accuracy: 0.7306\n",
            "Epoch 26/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6477 - accuracy: 0.7873 - val_loss: 0.7504 - val_accuracy: 0.7534\n",
            "Epoch 27/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6194 - accuracy: 0.7930 - val_loss: 0.7730 - val_accuracy: 0.7420\n",
            "Epoch 28/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6221 - accuracy: 0.7985 - val_loss: 0.7300 - val_accuracy: 0.7603\n",
            "Epoch 29/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.6080 - accuracy: 0.8007 - val_loss: 0.7702 - val_accuracy: 0.7477\n",
            "Epoch 30/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.5732 - accuracy: 0.8153 - val_loss: 0.7723 - val_accuracy: 0.7683\n",
            "Epoch 31/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.5668 - accuracy: 0.8101 - val_loss: 0.6853 - val_accuracy: 0.7888\n",
            "Epoch 32/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.5661 - accuracy: 0.8151 - val_loss: 0.6973 - val_accuracy: 0.7751\n",
            "Epoch 33/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.5508 - accuracy: 0.8252 - val_loss: 0.6744 - val_accuracy: 0.7945\n",
            "Epoch 34/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.5391 - accuracy: 0.8254 - val_loss: 0.7149 - val_accuracy: 0.7820\n",
            "Epoch 35/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.5277 - accuracy: 0.8302 - val_loss: 0.7202 - val_accuracy: 0.7774\n",
            "Epoch 36/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.5206 - accuracy: 0.8291 - val_loss: 0.6753 - val_accuracy: 0.7922\n",
            "Epoch 37/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.5177 - accuracy: 0.8282 - val_loss: 0.6800 - val_accuracy: 0.7991\n",
            "Epoch 38/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.5181 - accuracy: 0.8324 - val_loss: 0.6890 - val_accuracy: 0.7934\n",
            "Epoch 39/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.4850 - accuracy: 0.8440 - val_loss: 0.7046 - val_accuracy: 0.7888\n",
            "Epoch 40/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4767 - accuracy: 0.8456 - val_loss: 0.7072 - val_accuracy: 0.8014\n",
            "Epoch 41/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4601 - accuracy: 0.8511 - val_loss: 0.6609 - val_accuracy: 0.8059\n",
            "Epoch 42/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4642 - accuracy: 0.8489 - val_loss: 0.6485 - val_accuracy: 0.8116\n",
            "Epoch 43/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.4594 - accuracy: 0.8530 - val_loss: 0.7232 - val_accuracy: 0.7968\n",
            "Epoch 44/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.4462 - accuracy: 0.8573 - val_loss: 0.6620 - val_accuracy: 0.8196\n",
            "Epoch 45/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4288 - accuracy: 0.8601 - val_loss: 0.6657 - val_accuracy: 0.8196\n",
            "Epoch 46/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4519 - accuracy: 0.8542 - val_loss: 0.7366 - val_accuracy: 0.8048\n",
            "Epoch 47/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4026 - accuracy: 0.8749 - val_loss: 0.7027 - val_accuracy: 0.8048\n",
            "Epoch 48/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.4074 - accuracy: 0.8719 - val_loss: 0.6790 - val_accuracy: 0.8151\n",
            "Epoch 49/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4252 - accuracy: 0.8640 - val_loss: 0.6394 - val_accuracy: 0.8185\n",
            "Epoch 50/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4021 - accuracy: 0.8680 - val_loss: 0.6781 - val_accuracy: 0.8094\n",
            "Epoch 51/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4021 - accuracy: 0.8734 - val_loss: 0.6778 - val_accuracy: 0.8242\n",
            "Epoch 52/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3671 - accuracy: 0.8831 - val_loss: 0.6748 - val_accuracy: 0.8196\n",
            "Epoch 53/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.3586 - accuracy: 0.8820 - val_loss: 0.6619 - val_accuracy: 0.8219\n",
            "Epoch 54/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3842 - accuracy: 0.8754 - val_loss: 0.6970 - val_accuracy: 0.8185\n",
            "Epoch 55/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3715 - accuracy: 0.8795 - val_loss: 0.6312 - val_accuracy: 0.8311\n",
            "Epoch 56/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3825 - accuracy: 0.8758 - val_loss: 0.6987 - val_accuracy: 0.8231\n",
            "Epoch 57/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3825 - accuracy: 0.8773 - val_loss: 0.6929 - val_accuracy: 0.8196\n",
            "Epoch 58/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.3771 - accuracy: 0.8832 - val_loss: 0.6599 - val_accuracy: 0.8253\n",
            "Epoch 59/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.3348 - accuracy: 0.8935 - val_loss: 0.7538 - val_accuracy: 0.8128\n",
            "Epoch 60/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3466 - accuracy: 0.8946 - val_loss: 0.6977 - val_accuracy: 0.8208\n",
            "Epoch 61/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3248 - accuracy: 0.8950 - val_loss: 0.7149 - val_accuracy: 0.8139\n",
            "Epoch 62/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.3422 - accuracy: 0.8913 - val_loss: 0.7041 - val_accuracy: 0.8185\n",
            "Epoch 63/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3541 - accuracy: 0.8865 - val_loss: 0.6277 - val_accuracy: 0.8333\n",
            "Epoch 64/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3133 - accuracy: 0.9003 - val_loss: 0.7050 - val_accuracy: 0.8276\n",
            "Epoch 65/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3116 - accuracy: 0.9002 - val_loss: 0.6513 - val_accuracy: 0.8333\n",
            "Epoch 66/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3380 - accuracy: 0.8927 - val_loss: 0.6999 - val_accuracy: 0.8231\n",
            "Epoch 67/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.3145 - accuracy: 0.8968 - val_loss: 0.6865 - val_accuracy: 0.8368\n",
            "Epoch 68/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3168 - accuracy: 0.9016 - val_loss: 0.6734 - val_accuracy: 0.8368\n",
            "Epoch 69/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3064 - accuracy: 0.9049 - val_loss: 0.7137 - val_accuracy: 0.8288\n",
            "Epoch 70/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2913 - accuracy: 0.9068 - val_loss: 0.7558 - val_accuracy: 0.8196\n",
            "Epoch 71/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3010 - accuracy: 0.9078 - val_loss: 0.7251 - val_accuracy: 0.8322\n",
            "Epoch 72/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.3155 - accuracy: 0.9027 - val_loss: 0.7062 - val_accuracy: 0.8208\n",
            "Epoch 73/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3023 - accuracy: 0.9036 - val_loss: 0.7247 - val_accuracy: 0.8288\n",
            "Epoch 74/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2927 - accuracy: 0.9100 - val_loss: 0.6590 - val_accuracy: 0.8470\n",
            "Epoch 75/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2853 - accuracy: 0.9102 - val_loss: 0.7160 - val_accuracy: 0.8185\n",
            "Epoch 76/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.2713 - accuracy: 0.9176 - val_loss: 0.6925 - val_accuracy: 0.8447\n",
            "Epoch 77/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2731 - accuracy: 0.9176 - val_loss: 0.7371 - val_accuracy: 0.8196\n",
            "Epoch 78/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2930 - accuracy: 0.9059 - val_loss: 0.6829 - val_accuracy: 0.8333\n",
            "Epoch 79/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2922 - accuracy: 0.9086 - val_loss: 0.7335 - val_accuracy: 0.8265\n",
            "Epoch 80/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2871 - accuracy: 0.9097 - val_loss: 0.7301 - val_accuracy: 0.8413\n",
            "Epoch 81/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.2958 - accuracy: 0.9067 - val_loss: 0.6931 - val_accuracy: 0.8413\n",
            "Epoch 82/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2455 - accuracy: 0.9248 - val_loss: 0.7540 - val_accuracy: 0.8356\n",
            "Epoch 83/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2746 - accuracy: 0.9140 - val_loss: 0.7471 - val_accuracy: 0.8345\n",
            "Epoch 84/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2694 - accuracy: 0.9130 - val_loss: 0.7432 - val_accuracy: 0.8322\n",
            "Epoch 85/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2569 - accuracy: 0.9186 - val_loss: 0.7208 - val_accuracy: 0.8333\n",
            "Epoch 86/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.2570 - accuracy: 0.9201 - val_loss: 0.6954 - val_accuracy: 0.8379\n",
            "Epoch 87/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2508 - accuracy: 0.9208 - val_loss: 0.7427 - val_accuracy: 0.8356\n",
            "Epoch 88/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2373 - accuracy: 0.9262 - val_loss: 0.7648 - val_accuracy: 0.8390\n",
            "Epoch 89/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2611 - accuracy: 0.9177 - val_loss: 0.7228 - val_accuracy: 0.8368\n",
            "Epoch 90/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2438 - accuracy: 0.9265 - val_loss: 0.7125 - val_accuracy: 0.8425\n",
            "Epoch 91/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.2461 - accuracy: 0.9243 - val_loss: 0.6825 - val_accuracy: 0.8390\n",
            "Epoch 92/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2766 - accuracy: 0.9118 - val_loss: 0.7274 - val_accuracy: 0.8345\n",
            "Epoch 93/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2538 - accuracy: 0.9231 - val_loss: 0.7648 - val_accuracy: 0.8231\n",
            "Epoch 94/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2449 - accuracy: 0.9265 - val_loss: 0.7810 - val_accuracy: 0.8231\n",
            "Epoch 95/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.2537 - accuracy: 0.9229 - val_loss: 0.7279 - val_accuracy: 0.8276\n",
            "Epoch 96/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2376 - accuracy: 0.9275 - val_loss: 0.7778 - val_accuracy: 0.8333\n",
            "Epoch 97/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2267 - accuracy: 0.9284 - val_loss: 0.7978 - val_accuracy: 0.8208\n",
            "Epoch 98/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2372 - accuracy: 0.9299 - val_loss: 0.7426 - val_accuracy: 0.8390\n",
            "Epoch 99/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2372 - accuracy: 0.9272 - val_loss: 0.7642 - val_accuracy: 0.8333\n",
            "Epoch 100/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.2265 - accuracy: 0.9290 - val_loss: 0.7411 - val_accuracy: 0.8322\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.8362 - accuracy: 0.8159\n",
            "Accuracy: 0.8158976435661316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropout 추가\n",
        "\n",
        "#CRNN\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "# 데이터셋 디렉토리 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 클래스 레이블 설정 (클래스별 디렉토리 이름으로 가정)\n",
        "class_labels = os.listdir(data_dir)\n",
        "\n",
        "# MFCC 계수 개수 설정\n",
        "n_mfcc = 12\n",
        "\n",
        "# 데이터셋과 레이블을 저장할 리스트\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        X.append(mfccs.T)\n",
        "        labels.append(label)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X = np.array(X)\n",
        "\n",
        "# 레이블을 정수형으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(class_labels)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# 최대 길이에 맞춰 MFCC 벡터를 패딩\n",
        "max_length = max(len(mfccs) for mfccs in X)\n",
        "X = np.array([np.pad(mfccs, ((0, max_length - len(mfccs)), (0, 0)), mode='constant') for mfccs in X])\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경\n",
        "model.add(Reshape((X_train.shape[1] // 8, (X_train.shape[2] // 8) * 256)))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qRGWt9yKf9h",
        "outputId": "e1578ffd-b9c7-408a-e45a-3ee8d685cdb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "247/247 [==============================] - 10s 16ms/step - loss: 1.8781 - accuracy: 0.2480 - val_loss: 1.7806 - val_accuracy: 0.3139\n",
            "Epoch 2/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.7839 - accuracy: 0.2838 - val_loss: 1.6892 - val_accuracy: 0.3265\n",
            "Epoch 3/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.7233 - accuracy: 0.3131 - val_loss: 1.6339 - val_accuracy: 0.3402\n",
            "Epoch 4/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.6753 - accuracy: 0.3388 - val_loss: 1.5901 - val_accuracy: 0.3676\n",
            "Epoch 5/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.6380 - accuracy: 0.3550 - val_loss: 1.5590 - val_accuracy: 0.3836\n",
            "Epoch 6/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.6088 - accuracy: 0.3593 - val_loss: 1.5490 - val_accuracy: 0.3813\n",
            "Epoch 7/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.5845 - accuracy: 0.3719 - val_loss: 1.5330 - val_accuracy: 0.3858\n",
            "Epoch 8/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.5667 - accuracy: 0.3794 - val_loss: 1.5004 - val_accuracy: 0.4053\n",
            "Epoch 9/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.5499 - accuracy: 0.3883 - val_loss: 1.5063 - val_accuracy: 0.4007\n",
            "Epoch 10/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.5316 - accuracy: 0.3958 - val_loss: 1.4790 - val_accuracy: 0.4155\n",
            "Epoch 11/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.5163 - accuracy: 0.4040 - val_loss: 1.4822 - val_accuracy: 0.4030\n",
            "Epoch 12/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.5086 - accuracy: 0.4152 - val_loss: 1.4794 - val_accuracy: 0.4178\n",
            "Epoch 13/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.4935 - accuracy: 0.4154 - val_loss: 1.4729 - val_accuracy: 0.4144\n",
            "Epoch 14/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.4781 - accuracy: 0.4229 - val_loss: 1.4474 - val_accuracy: 0.4315\n",
            "Epoch 15/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.4792 - accuracy: 0.4248 - val_loss: 1.4534 - val_accuracy: 0.4235\n",
            "Epoch 16/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.4596 - accuracy: 0.4397 - val_loss: 1.4256 - val_accuracy: 0.4361\n",
            "Epoch 17/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.4549 - accuracy: 0.4411 - val_loss: 1.4096 - val_accuracy: 0.4521\n",
            "Epoch 18/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.4318 - accuracy: 0.4445 - val_loss: 1.4019 - val_accuracy: 0.4543\n",
            "Epoch 19/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.4184 - accuracy: 0.4547 - val_loss: 1.4048 - val_accuracy: 0.4566\n",
            "Epoch 20/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.4156 - accuracy: 0.4582 - val_loss: 1.3731 - val_accuracy: 0.4806\n",
            "Epoch 21/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.4023 - accuracy: 0.4642 - val_loss: 1.3680 - val_accuracy: 0.4669\n",
            "Epoch 22/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.3939 - accuracy: 0.4639 - val_loss: 1.3556 - val_accuracy: 0.4886\n",
            "Epoch 23/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.3770 - accuracy: 0.4791 - val_loss: 1.3599 - val_accuracy: 0.4737\n",
            "Epoch 24/100\n",
            "247/247 [==============================] - 4s 18ms/step - loss: 1.3683 - accuracy: 0.4860 - val_loss: 1.3353 - val_accuracy: 0.5023\n",
            "Epoch 25/100\n",
            "247/247 [==============================] - 4s 18ms/step - loss: 1.3710 - accuracy: 0.4803 - val_loss: 1.3518 - val_accuracy: 0.4806\n",
            "Epoch 26/100\n",
            "247/247 [==============================] - 5s 21ms/step - loss: 1.3511 - accuracy: 0.4898 - val_loss: 1.3311 - val_accuracy: 0.4977\n",
            "Epoch 27/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 1.3505 - accuracy: 0.4956 - val_loss: 1.3218 - val_accuracy: 0.4829\n",
            "Epoch 28/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.3378 - accuracy: 0.4893 - val_loss: 1.3217 - val_accuracy: 0.5023\n",
            "Epoch 29/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.3198 - accuracy: 0.5024 - val_loss: 1.3169 - val_accuracy: 0.4943\n",
            "Epoch 30/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.3185 - accuracy: 0.5060 - val_loss: 1.2958 - val_accuracy: 0.5068\n",
            "Epoch 31/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.3093 - accuracy: 0.5091 - val_loss: 1.2757 - val_accuracy: 0.5411\n",
            "Epoch 32/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.2980 - accuracy: 0.5168 - val_loss: 1.2745 - val_accuracy: 0.5114\n",
            "Epoch 33/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.2835 - accuracy: 0.5227 - val_loss: 1.2563 - val_accuracy: 0.5365\n",
            "Epoch 34/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.2800 - accuracy: 0.5262 - val_loss: 1.2551 - val_accuracy: 0.5377\n",
            "Epoch 35/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.2753 - accuracy: 0.5300 - val_loss: 1.2509 - val_accuracy: 0.5422\n",
            "Epoch 36/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2659 - accuracy: 0.5305 - val_loss: 1.2313 - val_accuracy: 0.5308\n",
            "Epoch 37/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.2480 - accuracy: 0.5362 - val_loss: 1.2543 - val_accuracy: 0.5285\n",
            "Epoch 38/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 1.2459 - accuracy: 0.5381 - val_loss: 1.2449 - val_accuracy: 0.5525\n",
            "Epoch 39/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.2345 - accuracy: 0.5395 - val_loss: 1.2563 - val_accuracy: 0.5263\n",
            "Epoch 40/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.2269 - accuracy: 0.5419 - val_loss: 1.2263 - val_accuracy: 0.5388\n",
            "Epoch 41/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.2146 - accuracy: 0.5517 - val_loss: 1.1980 - val_accuracy: 0.5548\n",
            "Epoch 42/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.1974 - accuracy: 0.5635 - val_loss: 1.2483 - val_accuracy: 0.5388\n",
            "Epoch 43/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.2034 - accuracy: 0.5607 - val_loss: 1.1967 - val_accuracy: 0.5605\n",
            "Epoch 44/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.1924 - accuracy: 0.5617 - val_loss: 1.1782 - val_accuracy: 0.5742\n",
            "Epoch 45/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.1875 - accuracy: 0.5667 - val_loss: 1.1988 - val_accuracy: 0.5502\n",
            "Epoch 46/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.1690 - accuracy: 0.5682 - val_loss: 1.2142 - val_accuracy: 0.5457\n",
            "Epoch 47/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.1555 - accuracy: 0.5775 - val_loss: 1.1755 - val_accuracy: 0.5582\n",
            "Epoch 48/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.1581 - accuracy: 0.5743 - val_loss: 1.2188 - val_accuracy: 0.5411\n",
            "Epoch 49/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.1612 - accuracy: 0.5797 - val_loss: 1.1593 - val_accuracy: 0.5799\n",
            "Epoch 50/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.1334 - accuracy: 0.5891 - val_loss: 1.1003 - val_accuracy: 0.5959\n",
            "Epoch 51/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.1345 - accuracy: 0.5901 - val_loss: 1.1406 - val_accuracy: 0.5788\n",
            "Epoch 52/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.1252 - accuracy: 0.5942 - val_loss: 1.1058 - val_accuracy: 0.5856\n",
            "Epoch 53/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.1142 - accuracy: 0.6012 - val_loss: 1.1001 - val_accuracy: 0.5947\n",
            "Epoch 54/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.1042 - accuracy: 0.6001 - val_loss: 1.1081 - val_accuracy: 0.5925\n",
            "Epoch 55/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.1121 - accuracy: 0.6030 - val_loss: 1.1065 - val_accuracy: 0.5925\n",
            "Epoch 56/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.0861 - accuracy: 0.6088 - val_loss: 1.0877 - val_accuracy: 0.5982\n",
            "Epoch 57/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.0809 - accuracy: 0.6125 - val_loss: 1.0560 - val_accuracy: 0.6039\n",
            "Epoch 58/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.0866 - accuracy: 0.6111 - val_loss: 1.0506 - val_accuracy: 0.6221\n",
            "Epoch 59/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.0642 - accuracy: 0.6144 - val_loss: 1.0374 - val_accuracy: 0.6164\n",
            "Epoch 60/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0636 - accuracy: 0.6209 - val_loss: 1.0342 - val_accuracy: 0.6142\n",
            "Epoch 61/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0555 - accuracy: 0.6263 - val_loss: 1.0654 - val_accuracy: 0.6119\n",
            "Epoch 62/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0413 - accuracy: 0.6333 - val_loss: 1.0248 - val_accuracy: 0.6199\n",
            "Epoch 63/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.0254 - accuracy: 0.6366 - val_loss: 1.0281 - val_accuracy: 0.6347\n",
            "Epoch 64/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.0229 - accuracy: 0.6329 - val_loss: 1.0203 - val_accuracy: 0.6267\n",
            "Epoch 65/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0391 - accuracy: 0.6340 - val_loss: 1.1330 - val_accuracy: 0.5982\n",
            "Epoch 66/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0124 - accuracy: 0.6409 - val_loss: 0.9889 - val_accuracy: 0.6336\n",
            "Epoch 67/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0132 - accuracy: 0.6447 - val_loss: 0.9923 - val_accuracy: 0.6404\n",
            "Epoch 68/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.0085 - accuracy: 0.6404 - val_loss: 1.0420 - val_accuracy: 0.6050\n",
            "Epoch 69/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.0045 - accuracy: 0.6456 - val_loss: 1.0168 - val_accuracy: 0.6404\n",
            "Epoch 70/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9860 - accuracy: 0.6506 - val_loss: 1.0056 - val_accuracy: 0.6267\n",
            "Epoch 71/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.9627 - accuracy: 0.6579 - val_loss: 1.0019 - val_accuracy: 0.6313\n",
            "Epoch 72/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9739 - accuracy: 0.6609 - val_loss: 0.9584 - val_accuracy: 0.6507\n",
            "Epoch 73/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.9609 - accuracy: 0.6572 - val_loss: 0.9466 - val_accuracy: 0.6667\n",
            "Epoch 74/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9572 - accuracy: 0.6680 - val_loss: 0.9891 - val_accuracy: 0.6427\n",
            "Epoch 75/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9397 - accuracy: 0.6684 - val_loss: 0.9686 - val_accuracy: 0.6632\n",
            "Epoch 76/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.9440 - accuracy: 0.6656 - val_loss: 0.9539 - val_accuracy: 0.6701\n",
            "Epoch 77/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9416 - accuracy: 0.6677 - val_loss: 0.9473 - val_accuracy: 0.6678\n",
            "Epoch 78/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.9248 - accuracy: 0.6725 - val_loss: 0.9345 - val_accuracy: 0.6781\n",
            "Epoch 79/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9017 - accuracy: 0.6913 - val_loss: 0.8995 - val_accuracy: 0.6689\n",
            "Epoch 80/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.9078 - accuracy: 0.6827 - val_loss: 0.9269 - val_accuracy: 0.6712\n",
            "Epoch 81/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9004 - accuracy: 0.6812 - val_loss: 0.9701 - val_accuracy: 0.6610\n",
            "Epoch 82/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9002 - accuracy: 0.6861 - val_loss: 0.9129 - val_accuracy: 0.6804\n",
            "Epoch 83/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.8898 - accuracy: 0.6917 - val_loss: 0.9174 - val_accuracy: 0.6769\n",
            "Epoch 84/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8835 - accuracy: 0.6907 - val_loss: 0.8849 - val_accuracy: 0.7078\n",
            "Epoch 85/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.8794 - accuracy: 0.6906 - val_loss: 0.8719 - val_accuracy: 0.6929\n",
            "Epoch 86/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8817 - accuracy: 0.6985 - val_loss: 0.9001 - val_accuracy: 0.6872\n",
            "Epoch 87/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8625 - accuracy: 0.6971 - val_loss: 0.9034 - val_accuracy: 0.6815\n",
            "Epoch 88/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.8583 - accuracy: 0.7016 - val_loss: 0.9040 - val_accuracy: 0.6849\n",
            "Epoch 89/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8395 - accuracy: 0.7067 - val_loss: 0.8636 - val_accuracy: 0.7032\n",
            "Epoch 90/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.8486 - accuracy: 0.7034 - val_loss: 0.8777 - val_accuracy: 0.7043\n",
            "Epoch 91/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8396 - accuracy: 0.7132 - val_loss: 0.8773 - val_accuracy: 0.6872\n",
            "Epoch 92/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8197 - accuracy: 0.7186 - val_loss: 0.9379 - val_accuracy: 0.6655\n",
            "Epoch 93/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.8229 - accuracy: 0.7120 - val_loss: 0.8907 - val_accuracy: 0.6929\n",
            "Epoch 94/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8188 - accuracy: 0.7169 - val_loss: 0.8953 - val_accuracy: 0.6998\n",
            "Epoch 95/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8205 - accuracy: 0.7183 - val_loss: 0.8537 - val_accuracy: 0.7066\n",
            "Epoch 96/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7933 - accuracy: 0.7306 - val_loss: 0.8724 - val_accuracy: 0.7009\n",
            "Epoch 97/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.7977 - accuracy: 0.7166 - val_loss: 0.8634 - val_accuracy: 0.7055\n",
            "Epoch 98/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.8005 - accuracy: 0.7197 - val_loss: 0.8877 - val_accuracy: 0.6826\n",
            "Epoch 99/100\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.7836 - accuracy: 0.7273 - val_loss: 0.8861 - val_accuracy: 0.7032\n",
            "Epoch 100/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7875 - accuracy: 0.7283 - val_loss: 0.9040 - val_accuracy: 0.6872\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.9384 - accuracy: 0.6752\n",
            "Accuracy: 0.6751941442489624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 데이터 폴더 경로\n",
        "data_path = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 수정된 분류 레이블\n",
        "labels = ['awake', 'diaper', 'hug', 'hungry', 'sad', 'sleepy', 'uncomfortable']\n",
        "\n",
        "# 데이터 및 레이블 저장을 위한 리스트\n",
        "data = []\n",
        "target = []\n",
        "\n",
        "# 각 분류별로 멜 스펙트로그램 생성 및 데이터 수집\n",
        "for label in labels:\n",
        "    label_path = os.path.join(data_path, label)\n",
        "    for filename in os.listdir(label_path):\n",
        "        if filename.endswith('.wav'):\n",
        "            file_path = os.path.join(label_path, filename)\n",
        "\n",
        "            # 오디오 파일 로드 및 멜 스펙트로그램 생성\n",
        "            y, sr = librosa.load(file_path)\n",
        "            mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "\n",
        "            # 멜 스펙트로그램 크기 조정\n",
        "            mel_spectrogram = mel_spectrogram[:, :128]\n",
        "\n",
        "            # 데이터 및 레이블 추가\n",
        "            data.append(mel_spectrogram)\n",
        "            target.append(label)\n",
        "\n",
        "# 데이터 전처리\n",
        "data = np.array(data)\n",
        "encoder = LabelEncoder()\n",
        "target = encoder.fit_transform(target)\n",
        "target = tf.keras.utils.to_categorical(target)\n",
        "\n",
        "# 훈련 및 테스트 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 설계\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(mel_spectrogram.shape[0], mel_spectrogram.shape[1])),\n",
        "    tf.keras.layers.Reshape((mel_spectrogram.shape[0], mel_spectrogram.shape[1], 1)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(labels), activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=1)\n",
        "\n",
        "# 학습 과정 시각화\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1GFlXXRO9qR8",
        "outputId": "145637bf-f3a0-4860-d2e2-b0520322de76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "247/247 [==============================] - 14s 10ms/step - loss: 2.2232 - accuracy: 0.1742 - val_loss: 1.9257 - val_accuracy: 0.1861\n",
            "Epoch 2/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 1.8411 - accuracy: 0.2631 - val_loss: 1.8473 - val_accuracy: 0.2888\n",
            "Epoch 3/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 1.6538 - accuracy: 0.3685 - val_loss: 1.7376 - val_accuracy: 0.3630\n",
            "Epoch 4/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 1.3341 - accuracy: 0.5196 - val_loss: 1.6592 - val_accuracy: 0.4361\n",
            "Epoch 5/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.9763 - accuracy: 0.6769 - val_loss: 1.7054 - val_accuracy: 0.4966\n",
            "Epoch 6/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.7300 - accuracy: 0.7774 - val_loss: 1.8253 - val_accuracy: 0.5468\n",
            "Epoch 7/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.5321 - accuracy: 0.8393 - val_loss: 2.0020 - val_accuracy: 0.5765\n",
            "Epoch 8/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.4041 - accuracy: 0.8804 - val_loss: 2.3174 - val_accuracy: 0.5833\n",
            "Epoch 9/100\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3172 - accuracy: 0.9024 - val_loss: 2.7012 - val_accuracy: 0.5799\n",
            "Epoch 10/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.3115 - accuracy: 0.9072 - val_loss: 2.6835 - val_accuracy: 0.5970\n",
            "Epoch 11/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.2763 - accuracy: 0.9185 - val_loss: 2.7901 - val_accuracy: 0.5925\n",
            "Epoch 12/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 0.2510 - accuracy: 0.9278 - val_loss: 2.9151 - val_accuracy: 0.6039\n",
            "Epoch 13/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.2684 - accuracy: 0.9243 - val_loss: 2.8421 - val_accuracy: 0.6301\n",
            "Epoch 14/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.1922 - accuracy: 0.9426 - val_loss: 3.2751 - val_accuracy: 0.6062\n",
            "Epoch 15/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 0.1661 - accuracy: 0.9469 - val_loss: 3.5350 - val_accuracy: 0.6073\n",
            "Epoch 16/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 0.1724 - accuracy: 0.9485 - val_loss: 3.7755 - val_accuracy: 0.6005\n",
            "Epoch 17/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1823 - accuracy: 0.9490 - val_loss: 3.9030 - val_accuracy: 0.6301\n",
            "Epoch 18/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.2261 - accuracy: 0.9425 - val_loss: 3.5704 - val_accuracy: 0.6073\n",
            "Epoch 19/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.1713 - accuracy: 0.9496 - val_loss: 3.8275 - val_accuracy: 0.6176\n",
            "Epoch 20/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.1559 - accuracy: 0.9577 - val_loss: 4.1135 - val_accuracy: 0.6279\n",
            "Epoch 21/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1571 - accuracy: 0.9598 - val_loss: 4.2309 - val_accuracy: 0.6119\n",
            "Epoch 22/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1288 - accuracy: 0.9623 - val_loss: 4.3430 - val_accuracy: 0.6370\n",
            "Epoch 23/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1190 - accuracy: 0.9665 - val_loss: 4.5385 - val_accuracy: 0.6119\n",
            "Epoch 24/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1211 - accuracy: 0.9615 - val_loss: 4.5903 - val_accuracy: 0.6279\n",
            "Epoch 25/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.1687 - accuracy: 0.9575 - val_loss: 5.0067 - val_accuracy: 0.6142\n",
            "Epoch 26/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1705 - accuracy: 0.9567 - val_loss: 4.5630 - val_accuracy: 0.6176\n",
            "Epoch 27/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.1414 - accuracy: 0.9627 - val_loss: 4.5672 - val_accuracy: 0.6153\n",
            "Epoch 28/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.1141 - accuracy: 0.9679 - val_loss: 4.6732 - val_accuracy: 0.6279\n",
            "Epoch 29/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1057 - accuracy: 0.9684 - val_loss: 5.1873 - val_accuracy: 0.6164\n",
            "Epoch 30/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1166 - accuracy: 0.9688 - val_loss: 5.3213 - val_accuracy: 0.6073\n",
            "Epoch 31/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1154 - accuracy: 0.9695 - val_loss: 4.9332 - val_accuracy: 0.6210\n",
            "Epoch 32/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.1123 - accuracy: 0.9705 - val_loss: 4.8471 - val_accuracy: 0.6290\n",
            "Epoch 33/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0960 - accuracy: 0.9722 - val_loss: 5.4393 - val_accuracy: 0.6176\n",
            "Epoch 34/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1243 - accuracy: 0.9708 - val_loss: 4.8209 - val_accuracy: 0.6039\n",
            "Epoch 35/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0987 - accuracy: 0.9723 - val_loss: 5.5524 - val_accuracy: 0.6256\n",
            "Epoch 36/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0960 - accuracy: 0.9731 - val_loss: 5.4564 - val_accuracy: 0.6244\n",
            "Epoch 37/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 0.0760 - accuracy: 0.9763 - val_loss: 6.0727 - val_accuracy: 0.6267\n",
            "Epoch 38/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0987 - accuracy: 0.9740 - val_loss: 5.4360 - val_accuracy: 0.6358\n",
            "Epoch 39/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0902 - accuracy: 0.9741 - val_loss: 5.4896 - val_accuracy: 0.6290\n",
            "Epoch 40/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1260 - accuracy: 0.9740 - val_loss: 5.3578 - val_accuracy: 0.6221\n",
            "Epoch 41/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0944 - accuracy: 0.9742 - val_loss: 5.3844 - val_accuracy: 0.6187\n",
            "Epoch 42/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0928 - accuracy: 0.9766 - val_loss: 5.7918 - val_accuracy: 0.6199\n",
            "Epoch 43/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0853 - accuracy: 0.9777 - val_loss: 5.9976 - val_accuracy: 0.6210\n",
            "Epoch 44/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 0.0669 - accuracy: 0.9802 - val_loss: 6.1785 - val_accuracy: 0.6130\n",
            "Epoch 45/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0641 - accuracy: 0.9817 - val_loss: 6.2676 - val_accuracy: 0.6301\n",
            "Epoch 46/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0570 - accuracy: 0.9827 - val_loss: 6.7742 - val_accuracy: 0.6187\n",
            "Epoch 47/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0553 - accuracy: 0.9841 - val_loss: 7.0624 - val_accuracy: 0.6233\n",
            "Epoch 48/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0781 - accuracy: 0.9780 - val_loss: 6.4550 - val_accuracy: 0.6244\n",
            "Epoch 49/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1008 - accuracy: 0.9782 - val_loss: 7.1360 - val_accuracy: 0.6199\n",
            "Epoch 50/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1057 - accuracy: 0.9773 - val_loss: 6.7346 - val_accuracy: 0.6084\n",
            "Epoch 51/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 0.1173 - accuracy: 0.9745 - val_loss: 6.7393 - val_accuracy: 0.6176\n",
            "Epoch 52/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0891 - accuracy: 0.9804 - val_loss: 6.1911 - val_accuracy: 0.6244\n",
            "Epoch 53/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0725 - accuracy: 0.9810 - val_loss: 6.9145 - val_accuracy: 0.6313\n",
            "Epoch 54/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0657 - accuracy: 0.9811 - val_loss: 6.9914 - val_accuracy: 0.6301\n",
            "Epoch 55/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0995 - accuracy: 0.9807 - val_loss: 6.9946 - val_accuracy: 0.6210\n",
            "Epoch 56/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0560 - accuracy: 0.9849 - val_loss: 6.9721 - val_accuracy: 0.6313\n",
            "Epoch 57/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0613 - accuracy: 0.9849 - val_loss: 7.1562 - val_accuracy: 0.6290\n",
            "Epoch 58/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 0.0676 - accuracy: 0.9849 - val_loss: 7.9927 - val_accuracy: 0.6187\n",
            "Epoch 59/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0597 - accuracy: 0.9840 - val_loss: 7.2084 - val_accuracy: 0.6336\n",
            "Epoch 60/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0476 - accuracy: 0.9853 - val_loss: 7.5170 - val_accuracy: 0.6347\n",
            "Epoch 61/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0493 - accuracy: 0.9853 - val_loss: 7.9206 - val_accuracy: 0.6244\n",
            "Epoch 62/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 7.9038 - val_accuracy: 0.6416\n",
            "Epoch 63/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0482 - accuracy: 0.9853 - val_loss: 7.9107 - val_accuracy: 0.6290\n",
            "Epoch 64/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0417 - accuracy: 0.9865 - val_loss: 8.9006 - val_accuracy: 0.6336\n",
            "Epoch 65/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 0.0557 - accuracy: 0.9848 - val_loss: 8.7473 - val_accuracy: 0.6244\n",
            "Epoch 66/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1087 - accuracy: 0.9796 - val_loss: 7.9693 - val_accuracy: 0.6153\n",
            "Epoch 67/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.1011 - accuracy: 0.9788 - val_loss: 7.4038 - val_accuracy: 0.6073\n",
            "Epoch 68/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0912 - accuracy: 0.9808 - val_loss: 7.0981 - val_accuracy: 0.6176\n",
            "Epoch 69/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0780 - accuracy: 0.9820 - val_loss: 7.0367 - val_accuracy: 0.6256\n",
            "Epoch 70/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0698 - accuracy: 0.9846 - val_loss: 7.1558 - val_accuracy: 0.6313\n",
            "Epoch 71/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0578 - accuracy: 0.9848 - val_loss: 7.6914 - val_accuracy: 0.6153\n",
            "Epoch 72/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0415 - accuracy: 0.9865 - val_loss: 7.7951 - val_accuracy: 0.6267\n",
            "Epoch 73/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 7.9203 - val_accuracy: 0.6267\n",
            "Epoch 74/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0423 - accuracy: 0.9867 - val_loss: 8.1407 - val_accuracy: 0.6267\n",
            "Epoch 75/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 8.2198 - val_accuracy: 0.6256\n",
            "Epoch 76/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 8.4091 - val_accuracy: 0.6233\n",
            "Epoch 77/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 9.2261 - val_accuracy: 0.6244\n",
            "Epoch 78/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 9.7383 - val_accuracy: 0.6187\n",
            "Epoch 79/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 10.1525 - val_accuracy: 0.6096\n",
            "Epoch 80/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0885 - accuracy: 0.9834 - val_loss: 8.0863 - val_accuracy: 0.6199\n",
            "Epoch 81/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.1217 - accuracy: 0.9775 - val_loss: 7.9632 - val_accuracy: 0.6187\n",
            "Epoch 82/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.1264 - accuracy: 0.9802 - val_loss: 7.5674 - val_accuracy: 0.6336\n",
            "Epoch 83/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0576 - accuracy: 0.9865 - val_loss: 7.8441 - val_accuracy: 0.6484\n",
            "Epoch 84/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0434 - accuracy: 0.9878 - val_loss: 8.3814 - val_accuracy: 0.6290\n",
            "Epoch 85/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0419 - accuracy: 0.9884 - val_loss: 8.6113 - val_accuracy: 0.6290\n",
            "Epoch 86/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 8.9412 - val_accuracy: 0.6256\n",
            "Epoch 87/100\n",
            "247/247 [==============================] - 2s 9ms/step - loss: 0.0324 - accuracy: 0.9893 - val_loss: 9.3406 - val_accuracy: 0.6267\n",
            "Epoch 88/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0324 - accuracy: 0.9893 - val_loss: 9.6165 - val_accuracy: 0.6290\n",
            "Epoch 89/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0308 - accuracy: 0.9898 - val_loss: 9.9792 - val_accuracy: 0.6336\n",
            "Epoch 90/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0374 - accuracy: 0.9901 - val_loss: 9.5343 - val_accuracy: 0.6279\n",
            "Epoch 91/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0440 - accuracy: 0.9893 - val_loss: 10.1018 - val_accuracy: 0.6233\n",
            "Epoch 92/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0873 - accuracy: 0.9851 - val_loss: 8.1151 - val_accuracy: 0.6324\n",
            "Epoch 93/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0653 - accuracy: 0.9864 - val_loss: 9.4349 - val_accuracy: 0.6267\n",
            "Epoch 94/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0767 - accuracy: 0.9844 - val_loss: 9.5239 - val_accuracy: 0.6176\n",
            "Epoch 95/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0849 - accuracy: 0.9865 - val_loss: 8.6371 - val_accuracy: 0.6301\n",
            "Epoch 96/100\n",
            "247/247 [==============================] - 2s 7ms/step - loss: 0.0609 - accuracy: 0.9886 - val_loss: 9.2878 - val_accuracy: 0.6313\n",
            "Epoch 97/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0404 - accuracy: 0.9881 - val_loss: 9.4846 - val_accuracy: 0.6427\n",
            "Epoch 98/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0491 - accuracy: 0.9887 - val_loss: 9.4369 - val_accuracy: 0.6347\n",
            "Epoch 99/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0512 - accuracy: 0.9883 - val_loss: 8.8760 - val_accuracy: 0.6370\n",
            "Epoch 100/100\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.0424 - accuracy: 0.9881 - val_loss: 9.0792 - val_accuracy: 0.6381\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 0s 5ms/step - loss: 11.9616 - accuracy: 0.6254\n",
            "Test Loss: 11.9616\n",
            "Test Accuracy: 0.6254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropout 추가\n",
        "#CRNN\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Reshape\n",
        "import tensorflow as tf\n",
        "\n",
        "# 데이터셋 디렉토리 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 클래스 레이블 설정 (클래스별 디렉토리 이름으로 가정)\n",
        "class_labels = os.listdir(data_dir)\n",
        "\n",
        "# MFCC 계수 개수 설정\n",
        "n_mfcc = 12\n",
        "\n",
        "# 데이터셋과 레이블을 저장할 리스트\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        X.append(mfccs.T)\n",
        "        labels.append(label)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X = np.array(X)\n",
        "\n",
        "# 레이블을 정수형으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(class_labels)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# 최대 길이에 맞춰 MFCC 벡터를 패딩\n",
        "max_length = max(len(mfccs) for mfccs in X)\n",
        "X = np.array([np.pad(mfccs, ((0, max_length - len(mfccs)), (0, 0)), mode='constant') for mfccs in X])\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경\n",
        "model.add(Reshape((X_train.shape[1] // 8, (X_train.shape[2] // 8) * 256)))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "initial_lr = 0.001  # 초기 학습률 설정\n",
        "\n",
        "# Learning Rate를 조정할 함수 정의\n",
        "def lr_schedule(epoch):\n",
        "    decay_rate = 0.9   # 학습률 감소 비율\n",
        "    decay_steps = 10    # 학습률 감소 주기 (에폭 단위)\n",
        "    lr = initial_lr * decay_rate**(epoch // decay_steps)\n",
        "    return lr\n",
        "\n",
        "# Learning Rate Scheduler 콜백 생성\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습 (Learning Rate Scheduler 콜백 추가)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[lr_scheduler])\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "2vuhpx-j9qZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc8813a-ba4c-4029-b430-2120d51ba19f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "247/247 [==============================] - 25s 23ms/step - loss: 1.6272 - accuracy: 0.3498 - val_loss: 1.6423 - val_accuracy: 0.3767 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.5131 - accuracy: 0.4058 - val_loss: 1.4114 - val_accuracy: 0.4406 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.4364 - accuracy: 0.4497 - val_loss: 1.3356 - val_accuracy: 0.4783 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.3731 - accuracy: 0.4839 - val_loss: 1.3033 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.3130 - accuracy: 0.5103 - val_loss: 1.2252 - val_accuracy: 0.5434 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 1.2637 - accuracy: 0.5340 - val_loss: 1.1691 - val_accuracy: 0.5719 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2090 - accuracy: 0.5555 - val_loss: 1.1777 - val_accuracy: 0.5674 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.1554 - accuracy: 0.5829 - val_loss: 1.1355 - val_accuracy: 0.5845 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.1360 - accuracy: 0.5909 - val_loss: 1.0561 - val_accuracy: 0.5970 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.0715 - accuracy: 0.6121 - val_loss: 1.0974 - val_accuracy: 0.6142 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.0326 - accuracy: 0.6313 - val_loss: 1.0186 - val_accuracy: 0.6393 - lr: 9.0000e-04\n",
            "Epoch 12/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9994 - accuracy: 0.6478 - val_loss: 1.0160 - val_accuracy: 0.6393 - lr: 9.0000e-04\n",
            "Epoch 13/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9649 - accuracy: 0.6605 - val_loss: 0.9752 - val_accuracy: 0.6416 - lr: 9.0000e-04\n",
            "Epoch 14/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9178 - accuracy: 0.6835 - val_loss: 0.9067 - val_accuracy: 0.6781 - lr: 9.0000e-04\n",
            "Epoch 15/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.8869 - accuracy: 0.6884 - val_loss: 0.9192 - val_accuracy: 0.6667 - lr: 9.0000e-04\n",
            "Epoch 16/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.8695 - accuracy: 0.7028 - val_loss: 0.8860 - val_accuracy: 0.6918 - lr: 9.0000e-04\n",
            "Epoch 17/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8237 - accuracy: 0.7195 - val_loss: 0.8450 - val_accuracy: 0.7237 - lr: 9.0000e-04\n",
            "Epoch 18/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8120 - accuracy: 0.7195 - val_loss: 0.8401 - val_accuracy: 0.7032 - lr: 9.0000e-04\n",
            "Epoch 19/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.7861 - accuracy: 0.7306 - val_loss: 0.8741 - val_accuracy: 0.7112 - lr: 9.0000e-04\n",
            "Epoch 20/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.7601 - accuracy: 0.7434 - val_loss: 0.7908 - val_accuracy: 0.7363 - lr: 9.0000e-04\n",
            "Epoch 21/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.7282 - accuracy: 0.7517 - val_loss: 0.7821 - val_accuracy: 0.7397 - lr: 8.1000e-04\n",
            "Epoch 22/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6994 - accuracy: 0.7660 - val_loss: 0.8055 - val_accuracy: 0.7466 - lr: 8.1000e-04\n",
            "Epoch 23/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6865 - accuracy: 0.7646 - val_loss: 0.8059 - val_accuracy: 0.7386 - lr: 8.1000e-04\n",
            "Epoch 24/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.6552 - accuracy: 0.7768 - val_loss: 0.7586 - val_accuracy: 0.7523 - lr: 8.1000e-04\n",
            "Epoch 25/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.6427 - accuracy: 0.7840 - val_loss: 0.7947 - val_accuracy: 0.7614 - lr: 8.1000e-04\n",
            "Epoch 26/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6131 - accuracy: 0.7966 - val_loss: 0.7586 - val_accuracy: 0.7717 - lr: 8.1000e-04\n",
            "Epoch 27/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6185 - accuracy: 0.7924 - val_loss: 0.7151 - val_accuracy: 0.7763 - lr: 8.1000e-04\n",
            "Epoch 28/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6070 - accuracy: 0.7977 - val_loss: 0.7159 - val_accuracy: 0.7820 - lr: 8.1000e-04\n",
            "Epoch 29/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.5921 - accuracy: 0.8049 - val_loss: 0.7234 - val_accuracy: 0.7797 - lr: 8.1000e-04\n",
            "Epoch 30/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.5594 - accuracy: 0.8168 - val_loss: 0.6938 - val_accuracy: 0.7797 - lr: 8.1000e-04\n",
            "Epoch 31/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5454 - accuracy: 0.8216 - val_loss: 0.7444 - val_accuracy: 0.7900 - lr: 7.2900e-04\n",
            "Epoch 32/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5312 - accuracy: 0.8280 - val_loss: 0.7168 - val_accuracy: 0.7934 - lr: 7.2900e-04\n",
            "Epoch 33/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.5144 - accuracy: 0.8329 - val_loss: 0.7083 - val_accuracy: 0.7945 - lr: 7.2900e-04\n",
            "Epoch 34/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.5263 - accuracy: 0.8282 - val_loss: 0.6848 - val_accuracy: 0.7957 - lr: 7.2900e-04\n",
            "Epoch 35/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.5112 - accuracy: 0.8353 - val_loss: 0.7129 - val_accuracy: 0.7900 - lr: 7.2900e-04\n",
            "Epoch 36/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4853 - accuracy: 0.8427 - val_loss: 0.6912 - val_accuracy: 0.8048 - lr: 7.2900e-04\n",
            "Epoch 37/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5019 - accuracy: 0.8363 - val_loss: 0.6769 - val_accuracy: 0.8105 - lr: 7.2900e-04\n",
            "Epoch 38/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.4766 - accuracy: 0.8466 - val_loss: 0.6682 - val_accuracy: 0.8059 - lr: 7.2900e-04\n",
            "Epoch 39/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.4631 - accuracy: 0.8493 - val_loss: 0.6748 - val_accuracy: 0.8174 - lr: 7.2900e-04\n",
            "Epoch 40/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4558 - accuracy: 0.8545 - val_loss: 0.6793 - val_accuracy: 0.8128 - lr: 7.2900e-04\n",
            "Epoch 41/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4133 - accuracy: 0.8696 - val_loss: 0.6835 - val_accuracy: 0.8253 - lr: 6.5610e-04\n",
            "Epoch 42/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4236 - accuracy: 0.8630 - val_loss: 0.7109 - val_accuracy: 0.8082 - lr: 6.5610e-04\n",
            "Epoch 43/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.4106 - accuracy: 0.8678 - val_loss: 0.6957 - val_accuracy: 0.8208 - lr: 6.5610e-04\n",
            "Epoch 44/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.4064 - accuracy: 0.8693 - val_loss: 0.6802 - val_accuracy: 0.8208 - lr: 6.5610e-04\n",
            "Epoch 45/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3918 - accuracy: 0.8730 - val_loss: 0.6767 - val_accuracy: 0.8265 - lr: 6.5610e-04\n",
            "Epoch 46/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3997 - accuracy: 0.8685 - val_loss: 0.7118 - val_accuracy: 0.8162 - lr: 6.5610e-04\n",
            "Epoch 47/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.3985 - accuracy: 0.8743 - val_loss: 0.7026 - val_accuracy: 0.8242 - lr: 6.5610e-04\n",
            "Epoch 48/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.3911 - accuracy: 0.8744 - val_loss: 0.7131 - val_accuracy: 0.8185 - lr: 6.5610e-04\n",
            "Epoch 49/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3940 - accuracy: 0.8784 - val_loss: 0.7180 - val_accuracy: 0.8116 - lr: 6.5610e-04\n",
            "Epoch 50/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3841 - accuracy: 0.8771 - val_loss: 0.6754 - val_accuracy: 0.8231 - lr: 6.5610e-04\n",
            "Epoch 51/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3752 - accuracy: 0.8804 - val_loss: 0.7027 - val_accuracy: 0.8231 - lr: 5.9049e-04\n",
            "Epoch 52/100\n",
            "247/247 [==============================] - 5s 21ms/step - loss: 0.3581 - accuracy: 0.8855 - val_loss: 0.6851 - val_accuracy: 0.8322 - lr: 5.9049e-04\n",
            "Epoch 53/100\n",
            "247/247 [==============================] - 4s 18ms/step - loss: 0.3495 - accuracy: 0.8874 - val_loss: 0.6989 - val_accuracy: 0.8288 - lr: 5.9049e-04\n",
            "Epoch 54/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3350 - accuracy: 0.8923 - val_loss: 0.6958 - val_accuracy: 0.8379 - lr: 5.9049e-04\n",
            "Epoch 55/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3427 - accuracy: 0.8879 - val_loss: 0.6930 - val_accuracy: 0.8345 - lr: 5.9049e-04\n",
            "Epoch 56/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3367 - accuracy: 0.8931 - val_loss: 0.7178 - val_accuracy: 0.8311 - lr: 5.9049e-04\n",
            "Epoch 57/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.3178 - accuracy: 0.9013 - val_loss: 0.6878 - val_accuracy: 0.8402 - lr: 5.9049e-04\n",
            "Epoch 58/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.3121 - accuracy: 0.9034 - val_loss: 0.7189 - val_accuracy: 0.8322 - lr: 5.9049e-04\n",
            "Epoch 59/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3108 - accuracy: 0.9031 - val_loss: 0.7221 - val_accuracy: 0.8299 - lr: 5.9049e-04\n",
            "Epoch 60/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3102 - accuracy: 0.9015 - val_loss: 0.6955 - val_accuracy: 0.8356 - lr: 5.9049e-04\n",
            "Epoch 61/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2955 - accuracy: 0.9039 - val_loss: 0.7335 - val_accuracy: 0.8345 - lr: 5.3144e-04\n",
            "Epoch 62/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.2962 - accuracy: 0.9057 - val_loss: 0.6963 - val_accuracy: 0.8447 - lr: 5.3144e-04\n",
            "Epoch 63/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2898 - accuracy: 0.9068 - val_loss: 0.7226 - val_accuracy: 0.8436 - lr: 5.3144e-04\n",
            "Epoch 64/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2837 - accuracy: 0.9121 - val_loss: 0.7417 - val_accuracy: 0.8425 - lr: 5.3144e-04\n",
            "Epoch 65/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2896 - accuracy: 0.9115 - val_loss: 0.7126 - val_accuracy: 0.8368 - lr: 5.3144e-04\n",
            "Epoch 66/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.2868 - accuracy: 0.9104 - val_loss: 0.7270 - val_accuracy: 0.8345 - lr: 5.3144e-04\n",
            "Epoch 67/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.2851 - accuracy: 0.9120 - val_loss: 0.6924 - val_accuracy: 0.8447 - lr: 5.3144e-04\n",
            "Epoch 68/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2628 - accuracy: 0.9152 - val_loss: 0.6973 - val_accuracy: 0.8413 - lr: 5.3144e-04\n",
            "Epoch 69/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2732 - accuracy: 0.9148 - val_loss: 0.6952 - val_accuracy: 0.8345 - lr: 5.3144e-04\n",
            "Epoch 70/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2781 - accuracy: 0.9099 - val_loss: 0.6992 - val_accuracy: 0.8402 - lr: 5.3144e-04\n",
            "Epoch 71/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.2542 - accuracy: 0.9203 - val_loss: 0.7101 - val_accuracy: 0.8322 - lr: 4.7830e-04\n",
            "Epoch 72/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2429 - accuracy: 0.9223 - val_loss: 0.7104 - val_accuracy: 0.8459 - lr: 4.7830e-04\n",
            "Epoch 73/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2555 - accuracy: 0.9199 - val_loss: 0.7093 - val_accuracy: 0.8379 - lr: 4.7830e-04\n",
            "Epoch 74/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2385 - accuracy: 0.9247 - val_loss: 0.6926 - val_accuracy: 0.8436 - lr: 4.7830e-04\n",
            "Epoch 75/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.2634 - accuracy: 0.9184 - val_loss: 0.6778 - val_accuracy: 0.8436 - lr: 4.7830e-04\n",
            "Epoch 76/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.2296 - accuracy: 0.9294 - val_loss: 0.7102 - val_accuracy: 0.8459 - lr: 4.7830e-04\n",
            "Epoch 77/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2451 - accuracy: 0.9237 - val_loss: 0.6986 - val_accuracy: 0.8493 - lr: 4.7830e-04\n",
            "Epoch 78/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2492 - accuracy: 0.9239 - val_loss: 0.6660 - val_accuracy: 0.8447 - lr: 4.7830e-04\n",
            "Epoch 79/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2087 - accuracy: 0.9335 - val_loss: 0.7281 - val_accuracy: 0.8425 - lr: 4.7830e-04\n",
            "Epoch 80/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.2344 - accuracy: 0.9279 - val_loss: 0.7255 - val_accuracy: 0.8447 - lr: 4.7830e-04\n",
            "Epoch 81/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.2213 - accuracy: 0.9304 - val_loss: 0.7066 - val_accuracy: 0.8470 - lr: 4.3047e-04\n",
            "Epoch 82/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2104 - accuracy: 0.9337 - val_loss: 0.7129 - val_accuracy: 0.8459 - lr: 4.3047e-04\n",
            "Epoch 83/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2215 - accuracy: 0.9284 - val_loss: 0.7102 - val_accuracy: 0.8470 - lr: 4.3047e-04\n",
            "Epoch 84/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2202 - accuracy: 0.9327 - val_loss: 0.6631 - val_accuracy: 0.8425 - lr: 4.3047e-04\n",
            "Epoch 85/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.2162 - accuracy: 0.9323 - val_loss: 0.7135 - val_accuracy: 0.8459 - lr: 4.3047e-04\n",
            "Epoch 86/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2091 - accuracy: 0.9369 - val_loss: 0.6664 - val_accuracy: 0.8493 - lr: 4.3047e-04\n",
            "Epoch 87/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1956 - accuracy: 0.9373 - val_loss: 0.6548 - val_accuracy: 0.8573 - lr: 4.3047e-04\n",
            "Epoch 88/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2107 - accuracy: 0.9338 - val_loss: 0.6614 - val_accuracy: 0.8505 - lr: 4.3047e-04\n",
            "Epoch 89/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.2108 - accuracy: 0.9355 - val_loss: 0.7137 - val_accuracy: 0.8470 - lr: 4.3047e-04\n",
            "Epoch 90/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.2061 - accuracy: 0.9344 - val_loss: 0.6901 - val_accuracy: 0.8470 - lr: 4.3047e-04\n",
            "Epoch 91/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1775 - accuracy: 0.9469 - val_loss: 0.7141 - val_accuracy: 0.8562 - lr: 3.8742e-04\n",
            "Epoch 92/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1938 - accuracy: 0.9420 - val_loss: 0.7245 - val_accuracy: 0.8516 - lr: 3.8742e-04\n",
            "Epoch 93/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2003 - accuracy: 0.9397 - val_loss: 0.7032 - val_accuracy: 0.8550 - lr: 3.8742e-04\n",
            "Epoch 94/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1874 - accuracy: 0.9403 - val_loss: 0.7147 - val_accuracy: 0.8482 - lr: 3.8742e-04\n",
            "Epoch 95/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.1997 - accuracy: 0.9398 - val_loss: 0.6844 - val_accuracy: 0.8562 - lr: 3.8742e-04\n",
            "Epoch 96/100\n",
            "247/247 [==============================] - 5s 20ms/step - loss: 0.1860 - accuracy: 0.9411 - val_loss: 0.7170 - val_accuracy: 0.8413 - lr: 3.8742e-04\n",
            "Epoch 97/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.1862 - accuracy: 0.9401 - val_loss: 0.7427 - val_accuracy: 0.8447 - lr: 3.8742e-04\n",
            "Epoch 98/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.1913 - accuracy: 0.9384 - val_loss: 0.7082 - val_accuracy: 0.8539 - lr: 3.8742e-04\n",
            "Epoch 99/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.2022 - accuracy: 0.9388 - val_loss: 0.7095 - val_accuracy: 0.8527 - lr: 3.8742e-04\n",
            "Epoch 100/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1859 - accuracy: 0.9439 - val_loss: 0.7365 - val_accuracy: 0.8459 - lr: 3.8742e-04\n",
            "69/69 [==============================] - 1s 9ms/step - loss: 0.9132 - accuracy: 0.8173\n",
            "Accuracy: 0.8172681331634521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 증강을 넣은 버전\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Reshape\n",
        "import tensorflow as tf\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Gain\n",
        "\n",
        "# 데이터셋 디렉토리 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 클래스 레이블 설정 (클래스별 디렉토리 이름으로 가정)\n",
        "class_labels = os.listdir(data_dir)\n",
        "\n",
        "# MFCC 계수 개수 설정\n",
        "n_mfcc = 12\n",
        "\n",
        "# 데이터셋과 레이블을 저장할 리스트\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "\n",
        "        # 데이터 증강을 위한 변환 적용\n",
        "        transform = Compose([\n",
        "            AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015),\n",
        "            TimeStretch(min_rate=0.8, max_rate=1.2),\n",
        "            PitchShift(min_semitones=-4, max_semitones=4),\n",
        "            Gain(min_gain_in_db=-6, max_gain_in_db=6)\n",
        "        ])\n",
        "        y_augmented = transform(samples=y, sample_rate=sr)\n",
        "\n",
        "        # 증강된 음성 데이터로 MFCC 계산\n",
        "        mfccs = librosa.feature.mfcc(y=y_augmented, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "        X.append(mfccs.T)\n",
        "        labels.append(label)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X = np.array(X)\n",
        "\n",
        "# 레이블을 정수형으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(class_labels)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# 최대 길이에 맞춰 MFCC 벡터를 패딩\n",
        "max_length = max(len(mfccs) for mfccs in X)\n",
        "X = np.array([np.pad(mfccs, ((0, max_length - len(mfccs)), (0, 0)), mode='constant') for mfccs in X])\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경\n",
        "model.add(Reshape((X_train.shape[1] // 8, (X_train.shape[2] // 8) * 256)))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "initial_lr = 0.001  # 초기 학습률 설정\n",
        "\n",
        "# Learning Rate를 조정할 함수 정의\n",
        "def lr_schedule(epoch):\n",
        "    decay_rate = 0.9   # 학습률 감소 비율\n",
        "    decay_steps = 10    # 학습률 감소 주기 (에폭 단위)\n",
        "    lr = initial_lr * decay_rate**(epoch // decay_steps)\n",
        "    return lr\n",
        "\n",
        "# Learning Rate Scheduler 콜백 생성\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습 (Learning Rate Scheduler 콜백 추가)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[lr_scheduler])\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "GQUJvWWp9qb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a133bbba-a595-448b-87e9-7f1c39f844a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "247/247 [==============================] - 12s 18ms/step - loss: 1.8278 - accuracy: 0.2454 - val_loss: 1.7378 - val_accuracy: 0.3048 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.7398 - accuracy: 0.2930 - val_loss: 1.7183 - val_accuracy: 0.2968 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.7031 - accuracy: 0.3195 - val_loss: 1.6376 - val_accuracy: 0.3345 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.6726 - accuracy: 0.3360 - val_loss: 1.6600 - val_accuracy: 0.3208 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.6517 - accuracy: 0.3473 - val_loss: 1.6143 - val_accuracy: 0.3573 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 1.6173 - accuracy: 0.3578 - val_loss: 1.6102 - val_accuracy: 0.3642 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.5926 - accuracy: 0.3833 - val_loss: 1.5935 - val_accuracy: 0.3550 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.5731 - accuracy: 0.3883 - val_loss: 1.5711 - val_accuracy: 0.3642 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.5491 - accuracy: 0.3968 - val_loss: 1.5669 - val_accuracy: 0.3756 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.5273 - accuracy: 0.4161 - val_loss: 1.5359 - val_accuracy: 0.3858 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 1.4961 - accuracy: 0.4295 - val_loss: 1.5268 - val_accuracy: 0.4144 - lr: 9.0000e-04\n",
            "Epoch 12/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.4778 - accuracy: 0.4412 - val_loss: 1.5219 - val_accuracy: 0.4247 - lr: 9.0000e-04\n",
            "Epoch 13/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.4516 - accuracy: 0.4478 - val_loss: 1.4908 - val_accuracy: 0.4429 - lr: 9.0000e-04\n",
            "Epoch 14/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.4333 - accuracy: 0.4603 - val_loss: 1.5076 - val_accuracy: 0.4235 - lr: 9.0000e-04\n",
            "Epoch 15/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.4137 - accuracy: 0.4685 - val_loss: 1.4928 - val_accuracy: 0.4315 - lr: 9.0000e-04\n",
            "Epoch 16/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 1.3920 - accuracy: 0.4746 - val_loss: 1.5055 - val_accuracy: 0.4189 - lr: 9.0000e-04\n",
            "Epoch 17/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 1.3623 - accuracy: 0.4877 - val_loss: 1.5172 - val_accuracy: 0.4189 - lr: 9.0000e-04\n",
            "Epoch 18/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.3555 - accuracy: 0.4917 - val_loss: 1.4946 - val_accuracy: 0.4486 - lr: 9.0000e-04\n",
            "Epoch 19/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.3154 - accuracy: 0.5135 - val_loss: 1.5204 - val_accuracy: 0.4281 - lr: 9.0000e-04\n",
            "Epoch 20/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.3165 - accuracy: 0.5131 - val_loss: 1.4687 - val_accuracy: 0.4486 - lr: 9.0000e-04\n",
            "Epoch 21/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 1.2810 - accuracy: 0.5312 - val_loss: 1.4890 - val_accuracy: 0.4532 - lr: 8.1000e-04\n",
            "Epoch 22/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.2707 - accuracy: 0.5324 - val_loss: 1.4720 - val_accuracy: 0.4418 - lr: 8.1000e-04\n",
            "Epoch 23/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2372 - accuracy: 0.5427 - val_loss: 1.4629 - val_accuracy: 0.4658 - lr: 8.1000e-04\n",
            "Epoch 24/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2416 - accuracy: 0.5476 - val_loss: 1.4585 - val_accuracy: 0.4623 - lr: 8.1000e-04\n",
            "Epoch 25/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.2192 - accuracy: 0.5493 - val_loss: 1.4598 - val_accuracy: 0.4589 - lr: 8.1000e-04\n",
            "Epoch 26/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.2149 - accuracy: 0.5578 - val_loss: 1.4732 - val_accuracy: 0.4566 - lr: 8.1000e-04\n",
            "Epoch 27/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.1908 - accuracy: 0.5689 - val_loss: 1.4700 - val_accuracy: 0.4600 - lr: 8.1000e-04\n",
            "Epoch 28/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.1712 - accuracy: 0.5740 - val_loss: 1.4868 - val_accuracy: 0.4692 - lr: 8.1000e-04\n",
            "Epoch 29/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.1471 - accuracy: 0.5901 - val_loss: 1.4591 - val_accuracy: 0.4646 - lr: 8.1000e-04\n",
            "Epoch 30/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 1.1495 - accuracy: 0.5884 - val_loss: 1.4188 - val_accuracy: 0.4749 - lr: 8.1000e-04\n",
            "Epoch 31/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.1058 - accuracy: 0.6025 - val_loss: 1.4470 - val_accuracy: 0.4680 - lr: 7.2900e-04\n",
            "Epoch 32/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.1140 - accuracy: 0.6026 - val_loss: 1.4446 - val_accuracy: 0.4909 - lr: 7.2900e-04\n",
            "Epoch 33/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.0969 - accuracy: 0.6014 - val_loss: 1.4350 - val_accuracy: 0.4829 - lr: 7.2900e-04\n",
            "Epoch 34/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.0730 - accuracy: 0.6131 - val_loss: 1.4732 - val_accuracy: 0.4806 - lr: 7.2900e-04\n",
            "Epoch 35/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 1.0638 - accuracy: 0.6152 - val_loss: 1.4711 - val_accuracy: 0.4909 - lr: 7.2900e-04\n",
            "Epoch 36/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0417 - accuracy: 0.6268 - val_loss: 1.4728 - val_accuracy: 0.4852 - lr: 7.2900e-04\n",
            "Epoch 37/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0394 - accuracy: 0.6345 - val_loss: 1.4924 - val_accuracy: 0.4817 - lr: 7.2900e-04\n",
            "Epoch 38/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0273 - accuracy: 0.6295 - val_loss: 1.4703 - val_accuracy: 0.4874 - lr: 7.2900e-04\n",
            "Epoch 39/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 1.0252 - accuracy: 0.6366 - val_loss: 1.5163 - val_accuracy: 0.4760 - lr: 7.2900e-04\n",
            "Epoch 40/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.9952 - accuracy: 0.6421 - val_loss: 1.5432 - val_accuracy: 0.4943 - lr: 7.2900e-04\n",
            "Epoch 41/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9732 - accuracy: 0.6524 - val_loss: 1.4790 - val_accuracy: 0.4840 - lr: 6.5610e-04\n",
            "Epoch 42/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9741 - accuracy: 0.6517 - val_loss: 1.5417 - val_accuracy: 0.4749 - lr: 6.5610e-04\n",
            "Epoch 43/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9716 - accuracy: 0.6552 - val_loss: 1.5058 - val_accuracy: 0.4852 - lr: 6.5610e-04\n",
            "Epoch 44/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.9532 - accuracy: 0.6633 - val_loss: 1.5125 - val_accuracy: 0.4909 - lr: 6.5610e-04\n",
            "Epoch 45/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.9591 - accuracy: 0.6624 - val_loss: 1.5083 - val_accuracy: 0.4920 - lr: 6.5610e-04\n",
            "Epoch 46/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9400 - accuracy: 0.6625 - val_loss: 1.5273 - val_accuracy: 0.4795 - lr: 6.5610e-04\n",
            "Epoch 47/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9172 - accuracy: 0.6776 - val_loss: 1.5446 - val_accuracy: 0.4954 - lr: 6.5610e-04\n",
            "Epoch 48/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9399 - accuracy: 0.6654 - val_loss: 1.5526 - val_accuracy: 0.4829 - lr: 6.5610e-04\n",
            "Epoch 49/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.9026 - accuracy: 0.6822 - val_loss: 1.5967 - val_accuracy: 0.4829 - lr: 6.5610e-04\n",
            "Epoch 50/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.9092 - accuracy: 0.6737 - val_loss: 1.5278 - val_accuracy: 0.4954 - lr: 6.5610e-04\n",
            "Epoch 51/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9055 - accuracy: 0.6794 - val_loss: 1.5221 - val_accuracy: 0.4954 - lr: 5.9049e-04\n",
            "Epoch 52/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8781 - accuracy: 0.6912 - val_loss: 1.5738 - val_accuracy: 0.4989 - lr: 5.9049e-04\n",
            "Epoch 53/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8652 - accuracy: 0.6893 - val_loss: 1.5488 - val_accuracy: 0.4954 - lr: 5.9049e-04\n",
            "Epoch 54/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.8659 - accuracy: 0.6974 - val_loss: 1.5305 - val_accuracy: 0.5126 - lr: 5.9049e-04\n",
            "Epoch 55/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.8421 - accuracy: 0.7014 - val_loss: 1.5663 - val_accuracy: 0.5023 - lr: 5.9049e-04\n",
            "Epoch 56/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8479 - accuracy: 0.6967 - val_loss: 1.5333 - val_accuracy: 0.5046 - lr: 5.9049e-04\n",
            "Epoch 57/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8360 - accuracy: 0.7101 - val_loss: 1.5946 - val_accuracy: 0.4920 - lr: 5.9049e-04\n",
            "Epoch 58/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.8335 - accuracy: 0.7081 - val_loss: 1.5734 - val_accuracy: 0.4989 - lr: 5.9049e-04\n",
            "Epoch 59/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.8222 - accuracy: 0.7127 - val_loss: 1.5507 - val_accuracy: 0.5034 - lr: 5.9049e-04\n",
            "Epoch 60/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8172 - accuracy: 0.7089 - val_loss: 1.5659 - val_accuracy: 0.4932 - lr: 5.9049e-04\n",
            "Epoch 61/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8105 - accuracy: 0.7118 - val_loss: 1.5585 - val_accuracy: 0.5126 - lr: 5.3144e-04\n",
            "Epoch 62/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8064 - accuracy: 0.7165 - val_loss: 1.6429 - val_accuracy: 0.4909 - lr: 5.3144e-04\n",
            "Epoch 63/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.7876 - accuracy: 0.7212 - val_loss: 1.6354 - val_accuracy: 0.5080 - lr: 5.3144e-04\n",
            "Epoch 64/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.7682 - accuracy: 0.7303 - val_loss: 1.6318 - val_accuracy: 0.5103 - lr: 5.3144e-04\n",
            "Epoch 65/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7777 - accuracy: 0.7218 - val_loss: 1.6391 - val_accuracy: 0.5057 - lr: 5.3144e-04\n",
            "Epoch 66/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7725 - accuracy: 0.7284 - val_loss: 1.5823 - val_accuracy: 0.5183 - lr: 5.3144e-04\n",
            "Epoch 67/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.7539 - accuracy: 0.7369 - val_loss: 1.6571 - val_accuracy: 0.5057 - lr: 5.3144e-04\n",
            "Epoch 68/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.7649 - accuracy: 0.7321 - val_loss: 1.6478 - val_accuracy: 0.5011 - lr: 5.3144e-04\n",
            "Epoch 69/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.7700 - accuracy: 0.7362 - val_loss: 1.6624 - val_accuracy: 0.4874 - lr: 5.3144e-04\n",
            "Epoch 70/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7487 - accuracy: 0.7382 - val_loss: 1.6600 - val_accuracy: 0.4932 - lr: 5.3144e-04\n",
            "Epoch 71/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.7431 - accuracy: 0.7381 - val_loss: 1.6400 - val_accuracy: 0.5000 - lr: 4.7830e-04\n",
            "Epoch 72/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7277 - accuracy: 0.7485 - val_loss: 1.6167 - val_accuracy: 0.5148 - lr: 4.7830e-04\n",
            "Epoch 73/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.7278 - accuracy: 0.7452 - val_loss: 1.6171 - val_accuracy: 0.5160 - lr: 4.7830e-04\n",
            "Epoch 74/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.7092 - accuracy: 0.7492 - val_loss: 1.6018 - val_accuracy: 0.5263 - lr: 4.7830e-04\n",
            "Epoch 75/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.7175 - accuracy: 0.7500 - val_loss: 1.5871 - val_accuracy: 0.5240 - lr: 4.7830e-04\n",
            "Epoch 76/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.7099 - accuracy: 0.7528 - val_loss: 1.6250 - val_accuracy: 0.5205 - lr: 4.7830e-04\n",
            "Epoch 77/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.7096 - accuracy: 0.7483 - val_loss: 1.6604 - val_accuracy: 0.5137 - lr: 4.7830e-04\n",
            "Epoch 78/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.7003 - accuracy: 0.7536 - val_loss: 1.6937 - val_accuracy: 0.5251 - lr: 4.7830e-04\n",
            "Epoch 79/100\n",
            "247/247 [==============================] - 5s 19ms/step - loss: 0.6826 - accuracy: 0.7654 - val_loss: 1.6876 - val_accuracy: 0.5274 - lr: 4.7830e-04\n",
            "Epoch 80/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.6998 - accuracy: 0.7514 - val_loss: 1.6713 - val_accuracy: 0.5285 - lr: 4.7830e-04\n",
            "Epoch 81/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6808 - accuracy: 0.7645 - val_loss: 1.6792 - val_accuracy: 0.5194 - lr: 4.3047e-04\n",
            "Epoch 82/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6768 - accuracy: 0.7618 - val_loss: 1.6747 - val_accuracy: 0.5228 - lr: 4.3047e-04\n",
            "Epoch 83/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.6743 - accuracy: 0.7675 - val_loss: 1.6748 - val_accuracy: 0.5137 - lr: 4.3047e-04\n",
            "Epoch 84/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.6497 - accuracy: 0.7758 - val_loss: 1.7000 - val_accuracy: 0.5171 - lr: 4.3047e-04\n",
            "Epoch 85/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6511 - accuracy: 0.7706 - val_loss: 1.6832 - val_accuracy: 0.5160 - lr: 4.3047e-04\n",
            "Epoch 86/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6554 - accuracy: 0.7707 - val_loss: 1.6899 - val_accuracy: 0.5103 - lr: 4.3047e-04\n",
            "Epoch 87/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6449 - accuracy: 0.7753 - val_loss: 1.7181 - val_accuracy: 0.5103 - lr: 4.3047e-04\n",
            "Epoch 88/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.6560 - accuracy: 0.7706 - val_loss: 1.7122 - val_accuracy: 0.5103 - lr: 4.3047e-04\n",
            "Epoch 89/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.6484 - accuracy: 0.7730 - val_loss: 1.7425 - val_accuracy: 0.5171 - lr: 4.3047e-04\n",
            "Epoch 90/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6502 - accuracy: 0.7717 - val_loss: 1.7339 - val_accuracy: 0.5183 - lr: 4.3047e-04\n",
            "Epoch 91/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6394 - accuracy: 0.7749 - val_loss: 1.7203 - val_accuracy: 0.5091 - lr: 3.8742e-04\n",
            "Epoch 92/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6306 - accuracy: 0.7850 - val_loss: 1.7072 - val_accuracy: 0.5228 - lr: 3.8742e-04\n",
            "Epoch 93/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.6302 - accuracy: 0.7802 - val_loss: 1.7351 - val_accuracy: 0.5251 - lr: 3.8742e-04\n",
            "Epoch 94/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.6160 - accuracy: 0.7836 - val_loss: 1.7775 - val_accuracy: 0.5205 - lr: 3.8742e-04\n",
            "Epoch 95/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6177 - accuracy: 0.7859 - val_loss: 1.7905 - val_accuracy: 0.5183 - lr: 3.8742e-04\n",
            "Epoch 96/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6257 - accuracy: 0.7829 - val_loss: 1.7810 - val_accuracy: 0.5171 - lr: 3.8742e-04\n",
            "Epoch 97/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6129 - accuracy: 0.7856 - val_loss: 1.7655 - val_accuracy: 0.5091 - lr: 3.8742e-04\n",
            "Epoch 98/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.6125 - accuracy: 0.7905 - val_loss: 1.7704 - val_accuracy: 0.5251 - lr: 3.8742e-04\n",
            "Epoch 99/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.5963 - accuracy: 0.7963 - val_loss: 1.7627 - val_accuracy: 0.5137 - lr: 3.8742e-04\n",
            "Epoch 100/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6154 - accuracy: 0.7844 - val_loss: 1.7658 - val_accuracy: 0.5091 - lr: 3.8742e-04\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 1.7848 - accuracy: 0.5075\n",
            "Accuracy: 0.5075376629829407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audiomentations"
      ],
      "metadata": {
        "id": "iRKCHkMu9qeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc9701a-bc8f-48b9-f2ef-55d873ba61b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.31.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m553.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.23.5)\n",
            "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.10.0.post2)\n",
            "Requirement already satisfied: scipy<2,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.10.1)\n",
            "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.3.5)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2023.7.22)\n",
            "Installing collected packages: audiomentations\n",
            "Successfully installed audiomentations-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropout 추가\n",
        "#CRNN\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Reshape\n",
        "import tensorflow as tf\n",
        "\n",
        "# 데이터셋 디렉토리 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 클래스 레이블 설정 (클래스별 디렉토리 이름으로 가정)\n",
        "class_labels = os.listdir(data_dir)\n",
        "\n",
        "# MFCC 계수 개수 설정\n",
        "n_mfcc = 12\n",
        "\n",
        "# 데이터셋과 레이블을 저장할 리스트\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        X.append(mfccs.T)\n",
        "        labels.append(label)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X = np.array(X)\n",
        "\n",
        "# 레이블을 정수형으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(class_labels)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# 최대 길이에 맞춰 MFCC 벡터를 패딩\n",
        "max_length = max(len(mfccs) for mfccs in X)\n",
        "X = np.array([np.pad(mfccs, ((0, max_length - len(mfccs)), (0, 0)), mode='constant') for mfccs in X])\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경\n",
        "model.add(Reshape((X_train.shape[1] // 8, (X_train.shape[2] // 8) * 256)))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "initial_lr = 0.002  # 초기 학습률 설정\n",
        "\n",
        "# Learning Rate를 조정할 함수 정의\n",
        "def lr_schedule(epoch):\n",
        "    decay_rate = 0.9   # 학습률 감소 비율\n",
        "    decay_steps = 10    # 학습률 감소 주기 (에폭 단위)\n",
        "    lr = initial_lr * decay_rate**(epoch // decay_steps)\n",
        "    return lr\n",
        "\n",
        "# Learning Rate Scheduler 콜백 생성\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습 (Learning Rate Scheduler 콜백 추가)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[lr_scheduler])\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q366JYVwpMkv",
        "outputId": "4ea34ad2-834f-415b-b5fe-9fb03505c56c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "247/247 [==============================] - 20s 20ms/step - loss: 1.6291 - accuracy: 0.3419 - val_loss: 1.5847 - val_accuracy: 0.3881 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.5148 - accuracy: 0.4073 - val_loss: 1.4340 - val_accuracy: 0.4463 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.4437 - accuracy: 0.4449 - val_loss: 1.3351 - val_accuracy: 0.4863 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.3807 - accuracy: 0.4821 - val_loss: 1.3538 - val_accuracy: 0.4840 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.3300 - accuracy: 0.4971 - val_loss: 1.2666 - val_accuracy: 0.5114 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2902 - accuracy: 0.5166 - val_loss: 1.2315 - val_accuracy: 0.5388 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2368 - accuracy: 0.5465 - val_loss: 1.1651 - val_accuracy: 0.5628 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 1.2065 - accuracy: 0.5537 - val_loss: 1.1712 - val_accuracy: 0.5525 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.1881 - accuracy: 0.5642 - val_loss: 1.1189 - val_accuracy: 0.6005 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.1450 - accuracy: 0.5799 - val_loss: 1.0393 - val_accuracy: 0.6313 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.0878 - accuracy: 0.6106 - val_loss: 1.0587 - val_accuracy: 0.6187 - lr: 0.0018\n",
            "Epoch 12/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 1.0578 - accuracy: 0.6178 - val_loss: 1.0057 - val_accuracy: 0.6393 - lr: 0.0018\n",
            "Epoch 13/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 1.0604 - accuracy: 0.6171 - val_loss: 0.9940 - val_accuracy: 0.6427 - lr: 0.0018\n",
            "Epoch 14/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.0004 - accuracy: 0.6418 - val_loss: 0.9791 - val_accuracy: 0.6507 - lr: 0.0018\n",
            "Epoch 15/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9812 - accuracy: 0.6472 - val_loss: 1.0020 - val_accuracy: 0.6324 - lr: 0.0018\n",
            "Epoch 16/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9645 - accuracy: 0.6625 - val_loss: 0.9628 - val_accuracy: 0.6575 - lr: 0.0018\n",
            "Epoch 17/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.9483 - accuracy: 0.6654 - val_loss: 0.9489 - val_accuracy: 0.6587 - lr: 0.0018\n",
            "Epoch 18/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.9009 - accuracy: 0.6851 - val_loss: 0.9545 - val_accuracy: 0.6416 - lr: 0.0018\n",
            "Epoch 19/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8858 - accuracy: 0.6922 - val_loss: 0.8940 - val_accuracy: 0.6815 - lr: 0.0018\n",
            "Epoch 20/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8855 - accuracy: 0.6849 - val_loss: 0.9005 - val_accuracy: 0.6758 - lr: 0.0018\n",
            "Epoch 21/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.8540 - accuracy: 0.7031 - val_loss: 0.8796 - val_accuracy: 0.6838 - lr: 0.0016\n",
            "Epoch 22/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.8284 - accuracy: 0.7120 - val_loss: 0.8865 - val_accuracy: 0.6781 - lr: 0.0016\n",
            "Epoch 23/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.8074 - accuracy: 0.7207 - val_loss: 0.8530 - val_accuracy: 0.7009 - lr: 0.0016\n",
            "Epoch 24/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.7738 - accuracy: 0.7320 - val_loss: 0.8267 - val_accuracy: 0.7226 - lr: 0.0016\n",
            "Epoch 25/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.7871 - accuracy: 0.7304 - val_loss: 0.8696 - val_accuracy: 0.7135 - lr: 0.0016\n",
            "Epoch 26/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.7744 - accuracy: 0.7368 - val_loss: 0.8322 - val_accuracy: 0.7203 - lr: 0.0016\n",
            "Epoch 27/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.7446 - accuracy: 0.7463 - val_loss: 0.8665 - val_accuracy: 0.7158 - lr: 0.0016\n",
            "Epoch 28/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.7110 - accuracy: 0.7565 - val_loss: 0.8009 - val_accuracy: 0.7340 - lr: 0.0016\n",
            "Epoch 29/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7200 - accuracy: 0.7537 - val_loss: 0.8205 - val_accuracy: 0.7352 - lr: 0.0016\n",
            "Epoch 30/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.7075 - accuracy: 0.7585 - val_loss: 0.8518 - val_accuracy: 0.7260 - lr: 0.0016\n",
            "Epoch 31/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.6653 - accuracy: 0.7777 - val_loss: 0.8270 - val_accuracy: 0.7237 - lr: 0.0015\n",
            "Epoch 32/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6542 - accuracy: 0.7795 - val_loss: 0.7986 - val_accuracy: 0.7363 - lr: 0.0015\n",
            "Epoch 33/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6497 - accuracy: 0.7779 - val_loss: 0.8076 - val_accuracy: 0.7534 - lr: 0.0015\n",
            "Epoch 34/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6490 - accuracy: 0.7765 - val_loss: 0.7614 - val_accuracy: 0.7500 - lr: 0.0015\n",
            "Epoch 35/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.6278 - accuracy: 0.7876 - val_loss: 0.7702 - val_accuracy: 0.7534 - lr: 0.0015\n",
            "Epoch 36/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.5996 - accuracy: 0.7991 - val_loss: 0.7242 - val_accuracy: 0.7648 - lr: 0.0015\n",
            "Epoch 37/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6061 - accuracy: 0.7967 - val_loss: 0.7890 - val_accuracy: 0.7648 - lr: 0.0015\n",
            "Epoch 38/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6087 - accuracy: 0.7963 - val_loss: 0.7367 - val_accuracy: 0.7671 - lr: 0.0015\n",
            "Epoch 39/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5713 - accuracy: 0.8073 - val_loss: 0.7161 - val_accuracy: 0.7705 - lr: 0.0015\n",
            "Epoch 40/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.5827 - accuracy: 0.8095 - val_loss: 0.7283 - val_accuracy: 0.7728 - lr: 0.0015\n",
            "Epoch 41/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.5698 - accuracy: 0.8108 - val_loss: 0.6872 - val_accuracy: 0.7671 - lr: 0.0013\n",
            "Epoch 42/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5392 - accuracy: 0.8230 - val_loss: 0.7257 - val_accuracy: 0.7854 - lr: 0.0013\n",
            "Epoch 43/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5302 - accuracy: 0.8313 - val_loss: 0.7412 - val_accuracy: 0.7808 - lr: 0.0013\n",
            "Epoch 44/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5329 - accuracy: 0.8233 - val_loss: 0.6750 - val_accuracy: 0.7911 - lr: 0.0013\n",
            "Epoch 45/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.5070 - accuracy: 0.8306 - val_loss: 0.6859 - val_accuracy: 0.8048 - lr: 0.0013\n",
            "Epoch 46/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.5203 - accuracy: 0.8264 - val_loss: 0.6935 - val_accuracy: 0.8025 - lr: 0.0013\n",
            "Epoch 47/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4923 - accuracy: 0.8394 - val_loss: 0.7287 - val_accuracy: 0.7945 - lr: 0.0013\n",
            "Epoch 48/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4939 - accuracy: 0.8380 - val_loss: 0.7459 - val_accuracy: 0.8048 - lr: 0.0013\n",
            "Epoch 49/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.4834 - accuracy: 0.8396 - val_loss: 0.7279 - val_accuracy: 0.7922 - lr: 0.0013\n",
            "Epoch 50/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.4852 - accuracy: 0.8414 - val_loss: 0.6812 - val_accuracy: 0.8128 - lr: 0.0013\n",
            "Epoch 51/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4457 - accuracy: 0.8549 - val_loss: 0.6870 - val_accuracy: 0.8037 - lr: 0.0012\n",
            "Epoch 52/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4428 - accuracy: 0.8615 - val_loss: 0.7072 - val_accuracy: 0.8105 - lr: 0.0012\n",
            "Epoch 53/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.4723 - accuracy: 0.8494 - val_loss: 0.7253 - val_accuracy: 0.8002 - lr: 0.0012\n",
            "Epoch 54/100\n",
            "247/247 [==============================] - 6s 22ms/step - loss: 0.4496 - accuracy: 0.8535 - val_loss: 0.7015 - val_accuracy: 0.8059 - lr: 0.0012\n",
            "Epoch 55/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.4266 - accuracy: 0.8592 - val_loss: 0.7161 - val_accuracy: 0.8094 - lr: 0.0012\n",
            "Epoch 56/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4268 - accuracy: 0.8593 - val_loss: 0.6921 - val_accuracy: 0.8242 - lr: 0.0012\n",
            "Epoch 57/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4290 - accuracy: 0.8617 - val_loss: 0.6822 - val_accuracy: 0.8139 - lr: 0.0012\n",
            "Epoch 58/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4066 - accuracy: 0.8687 - val_loss: 0.7033 - val_accuracy: 0.8174 - lr: 0.0012\n",
            "Epoch 59/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.4111 - accuracy: 0.8653 - val_loss: 0.7121 - val_accuracy: 0.8185 - lr: 0.0012\n",
            "Epoch 60/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3941 - accuracy: 0.8714 - val_loss: 0.7380 - val_accuracy: 0.8082 - lr: 0.0012\n",
            "Epoch 61/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4092 - accuracy: 0.8706 - val_loss: 0.6754 - val_accuracy: 0.8139 - lr: 0.0011\n",
            "Epoch 62/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3774 - accuracy: 0.8791 - val_loss: 0.6695 - val_accuracy: 0.8116 - lr: 0.0011\n",
            "Epoch 63/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.3680 - accuracy: 0.8824 - val_loss: 0.6669 - val_accuracy: 0.8265 - lr: 0.0011\n",
            "Epoch 64/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.3805 - accuracy: 0.8773 - val_loss: 0.6662 - val_accuracy: 0.8174 - lr: 0.0011\n",
            "Epoch 65/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3657 - accuracy: 0.8796 - val_loss: 0.7624 - val_accuracy: 0.8048 - lr: 0.0011\n",
            "Epoch 66/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3568 - accuracy: 0.8804 - val_loss: 0.6973 - val_accuracy: 0.8185 - lr: 0.0011\n",
            "Epoch 67/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3587 - accuracy: 0.8795 - val_loss: 0.7526 - val_accuracy: 0.8094 - lr: 0.0011\n",
            "Epoch 68/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.3435 - accuracy: 0.8909 - val_loss: 0.7392 - val_accuracy: 0.8196 - lr: 0.0011\n",
            "Epoch 69/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.3430 - accuracy: 0.8913 - val_loss: 0.7865 - val_accuracy: 0.8219 - lr: 0.0011\n",
            "Epoch 70/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3428 - accuracy: 0.8851 - val_loss: 0.7343 - val_accuracy: 0.8322 - lr: 0.0011\n",
            "Epoch 71/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3444 - accuracy: 0.8931 - val_loss: 0.7396 - val_accuracy: 0.8231 - lr: 9.5659e-04\n",
            "Epoch 72/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.3167 - accuracy: 0.8972 - val_loss: 0.7350 - val_accuracy: 0.8196 - lr: 9.5659e-04\n",
            "Epoch 73/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.3089 - accuracy: 0.9057 - val_loss: 0.7662 - val_accuracy: 0.8151 - lr: 9.5659e-04\n",
            "Epoch 74/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3221 - accuracy: 0.8949 - val_loss: 0.7459 - val_accuracy: 0.8276 - lr: 9.5659e-04\n",
            "Epoch 75/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3055 - accuracy: 0.9020 - val_loss: 0.7703 - val_accuracy: 0.8219 - lr: 9.5659e-04\n",
            "Epoch 76/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3235 - accuracy: 0.9010 - val_loss: 0.7499 - val_accuracy: 0.8276 - lr: 9.5659e-04\n",
            "Epoch 77/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.2942 - accuracy: 0.9001 - val_loss: 0.7414 - val_accuracy: 0.8265 - lr: 9.5659e-04\n",
            "Epoch 78/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.3054 - accuracy: 0.9054 - val_loss: 0.7501 - val_accuracy: 0.8345 - lr: 9.5659e-04\n",
            "Epoch 79/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3043 - accuracy: 0.9012 - val_loss: 0.7283 - val_accuracy: 0.8299 - lr: 9.5659e-04\n",
            "Epoch 80/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2910 - accuracy: 0.9109 - val_loss: 0.7405 - val_accuracy: 0.8322 - lr: 9.5659e-04\n",
            "Epoch 81/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2895 - accuracy: 0.9079 - val_loss: 0.7192 - val_accuracy: 0.8253 - lr: 8.6093e-04\n",
            "Epoch 82/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.2874 - accuracy: 0.9099 - val_loss: 0.7371 - val_accuracy: 0.8413 - lr: 8.6093e-04\n",
            "Epoch 83/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2835 - accuracy: 0.9096 - val_loss: 0.7556 - val_accuracy: 0.8333 - lr: 8.6093e-04\n",
            "Epoch 84/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2795 - accuracy: 0.9107 - val_loss: 0.7361 - val_accuracy: 0.8333 - lr: 8.6093e-04\n",
            "Epoch 85/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2702 - accuracy: 0.9144 - val_loss: 0.7577 - val_accuracy: 0.8333 - lr: 8.6093e-04\n",
            "Epoch 86/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.2612 - accuracy: 0.9168 - val_loss: 0.7519 - val_accuracy: 0.8413 - lr: 8.6093e-04\n",
            "Epoch 87/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.2678 - accuracy: 0.9170 - val_loss: 0.8017 - val_accuracy: 0.8288 - lr: 8.6093e-04\n",
            "Epoch 88/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2736 - accuracy: 0.9128 - val_loss: 0.8057 - val_accuracy: 0.8208 - lr: 8.6093e-04\n",
            "Epoch 89/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2673 - accuracy: 0.9152 - val_loss: 0.7795 - val_accuracy: 0.8311 - lr: 8.6093e-04\n",
            "Epoch 90/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2540 - accuracy: 0.9238 - val_loss: 0.7920 - val_accuracy: 0.8299 - lr: 8.6093e-04\n",
            "Epoch 91/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.2505 - accuracy: 0.9186 - val_loss: 0.7730 - val_accuracy: 0.8402 - lr: 7.7484e-04\n",
            "Epoch 92/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2400 - accuracy: 0.9219 - val_loss: 0.7767 - val_accuracy: 0.8345 - lr: 7.7484e-04\n",
            "Epoch 93/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2554 - accuracy: 0.9229 - val_loss: 0.7693 - val_accuracy: 0.8311 - lr: 7.7484e-04\n",
            "Epoch 94/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2409 - accuracy: 0.9227 - val_loss: 0.7586 - val_accuracy: 0.8288 - lr: 7.7484e-04\n",
            "Epoch 95/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.2350 - accuracy: 0.9265 - val_loss: 0.7502 - val_accuracy: 0.8356 - lr: 7.7484e-04\n",
            "Epoch 96/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.2355 - accuracy: 0.9279 - val_loss: 0.7439 - val_accuracy: 0.8311 - lr: 7.7484e-04\n",
            "Epoch 97/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2475 - accuracy: 0.9224 - val_loss: 0.7590 - val_accuracy: 0.8311 - lr: 7.7484e-04\n",
            "Epoch 98/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2200 - accuracy: 0.9307 - val_loss: 0.7619 - val_accuracy: 0.8333 - lr: 7.7484e-04\n",
            "Epoch 99/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2239 - accuracy: 0.9281 - val_loss: 0.7601 - val_accuracy: 0.8368 - lr: 7.7484e-04\n",
            "Epoch 100/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.2341 - accuracy: 0.9271 - val_loss: 0.7582 - val_accuracy: 0.8322 - lr: 7.7484e-04\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.9266 - accuracy: 0.8118\n",
            "Accuracy: 0.8117861747741699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropout 추가\n",
        "#CRNN\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Reshape\n",
        "import tensorflow as tf\n",
        "\n",
        "# 데이터셋 디렉토리 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 클래스 레이블 설정 (클래스별 디렉토리 이름으로 가정)\n",
        "class_labels = os.listdir(data_dir)\n",
        "\n",
        "# MFCC 계수 개수 설정\n",
        "n_mfcc = 12\n",
        "\n",
        "# 데이터셋과 레이블을 저장할 리스트\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        X.append(mfccs.T)\n",
        "        labels.append(label)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X = np.array(X)\n",
        "\n",
        "# 레이블을 정수형으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(class_labels)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# 최대 길이에 맞춰 MFCC 벡터를 패딩\n",
        "max_length = max(len(mfccs) for mfccs in X)\n",
        "X = np.array([np.pad(mfccs, ((0, max_length - len(mfccs)), (0, 0)), mode='constant') for mfccs in X])\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))  # Dropout 추가\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경\n",
        "model.add(Reshape((X_train.shape[1] // 8, (X_train.shape[2] // 8) * 256)))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "initial_lr = 0.002  # 초기 학습률 설정\n",
        "\n",
        "# Learning Rate를 조정할 함수 정의\n",
        "def lr_schedule(epoch):\n",
        "    decay_rate = 0.9   # 학습률 감소 비율\n",
        "    decay_steps = 10    # 학습률 감소 주기 (에폭 단위)\n",
        "    lr = initial_lr * decay_rate**(epoch // decay_steps)\n",
        "    return lr\n",
        "\n",
        "# Learning Rate Scheduler 콜백 생성\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습 (Learning Rate Scheduler 콜백 추가)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[lr_scheduler])\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGBH0EUCverl",
        "outputId": "5f206c47-3eb6-4709-92aa-ead7d9894f08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "247/247 [==============================] - 12s 16ms/step - loss: 1.6401 - accuracy: 0.3462 - val_loss: 1.5667 - val_accuracy: 0.3584 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.5318 - accuracy: 0.3959 - val_loss: 1.4496 - val_accuracy: 0.4372 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 1.4614 - accuracy: 0.4299 - val_loss: 1.3819 - val_accuracy: 0.4578 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.4239 - accuracy: 0.4603 - val_loss: 1.3533 - val_accuracy: 0.4669 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.3886 - accuracy: 0.4744 - val_loss: 1.2916 - val_accuracy: 0.5331 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.3558 - accuracy: 0.4887 - val_loss: 1.3193 - val_accuracy: 0.5091 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "247/247 [==============================] - 5s 21ms/step - loss: 1.3201 - accuracy: 0.5062 - val_loss: 1.2477 - val_accuracy: 0.5228 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "247/247 [==============================] - 5s 19ms/step - loss: 1.2995 - accuracy: 0.5175 - val_loss: 1.2040 - val_accuracy: 0.5491 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2630 - accuracy: 0.5289 - val_loss: 1.1994 - val_accuracy: 0.5548 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2377 - accuracy: 0.5447 - val_loss: 1.1519 - val_accuracy: 0.5811 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2101 - accuracy: 0.5540 - val_loss: 1.1097 - val_accuracy: 0.5742 - lr: 0.0018\n",
            "Epoch 12/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 1.1768 - accuracy: 0.5681 - val_loss: 1.1124 - val_accuracy: 0.5856 - lr: 0.0018\n",
            "Epoch 13/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.1552 - accuracy: 0.5827 - val_loss: 1.1043 - val_accuracy: 0.6119 - lr: 0.0018\n",
            "Epoch 14/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.1235 - accuracy: 0.5909 - val_loss: 1.0545 - val_accuracy: 0.6096 - lr: 0.0018\n",
            "Epoch 15/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.1256 - accuracy: 0.5943 - val_loss: 1.0692 - val_accuracy: 0.5959 - lr: 0.0018\n",
            "Epoch 16/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0975 - accuracy: 0.5995 - val_loss: 1.0602 - val_accuracy: 0.6084 - lr: 0.0018\n",
            "Epoch 17/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 1.0881 - accuracy: 0.6070 - val_loss: 1.0506 - val_accuracy: 0.6062 - lr: 0.0018\n",
            "Epoch 18/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.0784 - accuracy: 0.6091 - val_loss: 1.0283 - val_accuracy: 0.6256 - lr: 0.0018\n",
            "Epoch 19/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.0614 - accuracy: 0.6183 - val_loss: 1.0552 - val_accuracy: 0.6119 - lr: 0.0018\n",
            "Epoch 20/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.0486 - accuracy: 0.6223 - val_loss: 1.0133 - val_accuracy: 0.6507 - lr: 0.0018\n",
            "Epoch 21/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.0123 - accuracy: 0.6383 - val_loss: 0.9692 - val_accuracy: 0.6712 - lr: 0.0016\n",
            "Epoch 22/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 1.0035 - accuracy: 0.6420 - val_loss: 0.9683 - val_accuracy: 0.6564 - lr: 0.0016\n",
            "Epoch 23/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9811 - accuracy: 0.6482 - val_loss: 0.9971 - val_accuracy: 0.6324 - lr: 0.0016\n",
            "Epoch 24/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9705 - accuracy: 0.6577 - val_loss: 0.9804 - val_accuracy: 0.6381 - lr: 0.0016\n",
            "Epoch 25/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9514 - accuracy: 0.6629 - val_loss: 0.9436 - val_accuracy: 0.6587 - lr: 0.0016\n",
            "Epoch 26/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.9403 - accuracy: 0.6679 - val_loss: 0.9125 - val_accuracy: 0.6712 - lr: 0.0016\n",
            "Epoch 27/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.9463 - accuracy: 0.6612 - val_loss: 0.9321 - val_accuracy: 0.6644 - lr: 0.0016\n",
            "Epoch 28/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9197 - accuracy: 0.6728 - val_loss: 0.9263 - val_accuracy: 0.6655 - lr: 0.0016\n",
            "Epoch 29/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9239 - accuracy: 0.6755 - val_loss: 0.9205 - val_accuracy: 0.6895 - lr: 0.0016\n",
            "Epoch 30/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.9067 - accuracy: 0.6795 - val_loss: 0.8885 - val_accuracy: 0.6884 - lr: 0.0016\n",
            "Epoch 31/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.8880 - accuracy: 0.6915 - val_loss: 0.9197 - val_accuracy: 0.6906 - lr: 0.0015\n",
            "Epoch 32/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.8517 - accuracy: 0.7023 - val_loss: 0.8987 - val_accuracy: 0.7009 - lr: 0.0015\n",
            "Epoch 33/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8529 - accuracy: 0.7044 - val_loss: 0.8584 - val_accuracy: 0.7055 - lr: 0.0015\n",
            "Epoch 34/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8543 - accuracy: 0.7061 - val_loss: 0.8553 - val_accuracy: 0.7249 - lr: 0.0015\n",
            "Epoch 35/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.8409 - accuracy: 0.7054 - val_loss: 0.8454 - val_accuracy: 0.7100 - lr: 0.0015\n",
            "Epoch 36/100\n",
            "247/247 [==============================] - 4s 18ms/step - loss: 0.8413 - accuracy: 0.7063 - val_loss: 0.8022 - val_accuracy: 0.7169 - lr: 0.0015\n",
            "Epoch 37/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8323 - accuracy: 0.7105 - val_loss: 0.8474 - val_accuracy: 0.7192 - lr: 0.0015\n",
            "Epoch 38/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8068 - accuracy: 0.7236 - val_loss: 0.8219 - val_accuracy: 0.7158 - lr: 0.0015\n",
            "Epoch 39/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8092 - accuracy: 0.7226 - val_loss: 0.8031 - val_accuracy: 0.7283 - lr: 0.0015\n",
            "Epoch 40/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.7719 - accuracy: 0.7315 - val_loss: 0.8225 - val_accuracy: 0.7021 - lr: 0.0015\n",
            "Epoch 41/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.7721 - accuracy: 0.7368 - val_loss: 0.7937 - val_accuracy: 0.7203 - lr: 0.0013\n",
            "Epoch 42/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7480 - accuracy: 0.7395 - val_loss: 0.7971 - val_accuracy: 0.7363 - lr: 0.0013\n",
            "Epoch 43/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7451 - accuracy: 0.7467 - val_loss: 0.8296 - val_accuracy: 0.7146 - lr: 0.0013\n",
            "Epoch 44/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7375 - accuracy: 0.7417 - val_loss: 0.7570 - val_accuracy: 0.7329 - lr: 0.0013\n",
            "Epoch 45/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.7385 - accuracy: 0.7447 - val_loss: 0.8227 - val_accuracy: 0.7169 - lr: 0.0013\n",
            "Epoch 46/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.7232 - accuracy: 0.7539 - val_loss: 0.8013 - val_accuracy: 0.7295 - lr: 0.0013\n",
            "Epoch 47/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7155 - accuracy: 0.7570 - val_loss: 0.8046 - val_accuracy: 0.7409 - lr: 0.0013\n",
            "Epoch 48/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7098 - accuracy: 0.7594 - val_loss: 0.8132 - val_accuracy: 0.7260 - lr: 0.0013\n",
            "Epoch 49/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7159 - accuracy: 0.7541 - val_loss: 0.7789 - val_accuracy: 0.7260 - lr: 0.0013\n",
            "Epoch 50/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.6999 - accuracy: 0.7654 - val_loss: 0.7585 - val_accuracy: 0.7523 - lr: 0.0013\n",
            "Epoch 51/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.6760 - accuracy: 0.7664 - val_loss: 0.7658 - val_accuracy: 0.7397 - lr: 0.0012\n",
            "Epoch 52/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6783 - accuracy: 0.7730 - val_loss: 0.7561 - val_accuracy: 0.7511 - lr: 0.0012\n",
            "Epoch 53/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6635 - accuracy: 0.7767 - val_loss: 0.7521 - val_accuracy: 0.7523 - lr: 0.0012\n",
            "Epoch 54/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6499 - accuracy: 0.7828 - val_loss: 0.7317 - val_accuracy: 0.7717 - lr: 0.0012\n",
            "Epoch 55/100\n",
            "247/247 [==============================] - 4s 17ms/step - loss: 0.6607 - accuracy: 0.7792 - val_loss: 0.7893 - val_accuracy: 0.7466 - lr: 0.0012\n",
            "Epoch 56/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.6474 - accuracy: 0.7787 - val_loss: 0.7508 - val_accuracy: 0.7603 - lr: 0.0012\n",
            "Epoch 57/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6531 - accuracy: 0.7819 - val_loss: 0.7416 - val_accuracy: 0.7626 - lr: 0.0012\n",
            "Epoch 58/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6277 - accuracy: 0.7863 - val_loss: 0.7857 - val_accuracy: 0.7523 - lr: 0.0012\n",
            "Epoch 59/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.6428 - accuracy: 0.7797 - val_loss: 0.7588 - val_accuracy: 0.7614 - lr: 0.0012\n",
            "Epoch 60/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.6244 - accuracy: 0.7915 - val_loss: 0.7965 - val_accuracy: 0.7626 - lr: 0.0012\n",
            "Epoch 61/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6111 - accuracy: 0.7919 - val_loss: 0.7924 - val_accuracy: 0.7568 - lr: 0.0011\n",
            "Epoch 62/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5996 - accuracy: 0.7985 - val_loss: 0.7822 - val_accuracy: 0.7683 - lr: 0.0011\n",
            "Epoch 63/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.6003 - accuracy: 0.7993 - val_loss: 0.7510 - val_accuracy: 0.7648 - lr: 0.0011\n",
            "Epoch 64/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.5733 - accuracy: 0.8021 - val_loss: 0.7643 - val_accuracy: 0.7797 - lr: 0.0011\n",
            "Epoch 65/100\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.6041 - accuracy: 0.8002 - val_loss: 0.7498 - val_accuracy: 0.7751 - lr: 0.0011\n",
            "Epoch 66/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5804 - accuracy: 0.8014 - val_loss: 0.7179 - val_accuracy: 0.7740 - lr: 0.0011\n",
            "Epoch 67/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5697 - accuracy: 0.8075 - val_loss: 0.7423 - val_accuracy: 0.7660 - lr: 0.0011\n",
            "Epoch 68/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.5689 - accuracy: 0.8108 - val_loss: 0.7147 - val_accuracy: 0.7865 - lr: 0.0011\n",
            "Epoch 69/100\n",
            "247/247 [==============================] - 5s 20ms/step - loss: 0.5550 - accuracy: 0.8160 - val_loss: 0.7129 - val_accuracy: 0.7900 - lr: 0.0011\n",
            "Epoch 70/100\n",
            "247/247 [==============================] - 5s 18ms/step - loss: 0.5432 - accuracy: 0.8205 - val_loss: 0.7140 - val_accuracy: 0.7877 - lr: 0.0011\n",
            "Epoch 71/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5654 - accuracy: 0.8131 - val_loss: 0.6880 - val_accuracy: 0.7900 - lr: 9.5659e-04\n",
            "Epoch 72/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5516 - accuracy: 0.8172 - val_loss: 0.7189 - val_accuracy: 0.7842 - lr: 9.5659e-04\n",
            "Epoch 73/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.5272 - accuracy: 0.8202 - val_loss: 0.6844 - val_accuracy: 0.7991 - lr: 9.5659e-04\n",
            "Epoch 74/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.5367 - accuracy: 0.8233 - val_loss: 0.7048 - val_accuracy: 0.7957 - lr: 9.5659e-04\n",
            "Epoch 75/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5256 - accuracy: 0.8229 - val_loss: 0.7427 - val_accuracy: 0.7831 - lr: 9.5659e-04\n",
            "Epoch 76/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5143 - accuracy: 0.8280 - val_loss: 0.6938 - val_accuracy: 0.8048 - lr: 9.5659e-04\n",
            "Epoch 77/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5244 - accuracy: 0.8241 - val_loss: 0.6899 - val_accuracy: 0.8037 - lr: 9.5659e-04\n",
            "Epoch 78/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.5123 - accuracy: 0.8277 - val_loss: 0.7228 - val_accuracy: 0.7979 - lr: 9.5659e-04\n",
            "Epoch 79/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.4986 - accuracy: 0.8321 - val_loss: 0.7034 - val_accuracy: 0.8037 - lr: 9.5659e-04\n",
            "Epoch 80/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4933 - accuracy: 0.8313 - val_loss: 0.6839 - val_accuracy: 0.8128 - lr: 9.5659e-04\n",
            "Epoch 81/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4849 - accuracy: 0.8376 - val_loss: 0.7013 - val_accuracy: 0.8082 - lr: 8.6093e-04\n",
            "Epoch 82/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4707 - accuracy: 0.8440 - val_loss: 0.7131 - val_accuracy: 0.8037 - lr: 8.6093e-04\n",
            "Epoch 83/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.4777 - accuracy: 0.8417 - val_loss: 0.6852 - val_accuracy: 0.8105 - lr: 8.6093e-04\n",
            "Epoch 84/100\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.4766 - accuracy: 0.8389 - val_loss: 0.7101 - val_accuracy: 0.8082 - lr: 8.6093e-04\n",
            "Epoch 85/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4465 - accuracy: 0.8522 - val_loss: 0.6787 - val_accuracy: 0.8219 - lr: 8.6093e-04\n",
            "Epoch 86/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4729 - accuracy: 0.8433 - val_loss: 0.6629 - val_accuracy: 0.8219 - lr: 8.6093e-04\n",
            "Epoch 87/100\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4641 - accuracy: 0.8432 - val_loss: 0.6860 - val_accuracy: 0.8037 - lr: 8.6093e-04\n",
            "Epoch 88/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.4575 - accuracy: 0.8479 - val_loss: 0.7112 - val_accuracy: 0.8105 - lr: 8.6093e-04\n",
            "Epoch 89/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.4600 - accuracy: 0.8537 - val_loss: 0.6616 - val_accuracy: 0.8322 - lr: 8.6093e-04\n",
            "Epoch 90/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4328 - accuracy: 0.8577 - val_loss: 0.6711 - val_accuracy: 0.8288 - lr: 8.6093e-04\n",
            "Epoch 91/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4393 - accuracy: 0.8559 - val_loss: 0.6960 - val_accuracy: 0.8208 - lr: 7.7484e-04\n",
            "Epoch 92/100\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.4187 - accuracy: 0.8641 - val_loss: 0.6850 - val_accuracy: 0.8242 - lr: 7.7484e-04\n",
            "Epoch 93/100\n",
            "247/247 [==============================] - 4s 16ms/step - loss: 0.4178 - accuracy: 0.8575 - val_loss: 0.7105 - val_accuracy: 0.8082 - lr: 7.7484e-04\n",
            "Epoch 94/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4212 - accuracy: 0.8607 - val_loss: 0.6819 - val_accuracy: 0.8253 - lr: 7.7484e-04\n",
            "Epoch 95/100\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4230 - accuracy: 0.8573 - val_loss: 0.6966 - val_accuracy: 0.8151 - lr: 7.7484e-04\n",
            "Epoch 96/100\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.4248 - accuracy: 0.8605 - val_loss: 0.6875 - val_accuracy: 0.8196 - lr: 7.7484e-04\n",
            "Epoch 97/100\n",
            "247/247 [==============================] - 6s 23ms/step - loss: 0.4246 - accuracy: 0.8614 - val_loss: 0.6787 - val_accuracy: 0.8253 - lr: 7.7484e-04\n",
            "Epoch 98/100\n",
            "247/247 [==============================] - 5s 20ms/step - loss: 0.4180 - accuracy: 0.8612 - val_loss: 0.6780 - val_accuracy: 0.8242 - lr: 7.7484e-04\n",
            "Epoch 99/100\n",
            "247/247 [==============================] - 5s 18ms/step - loss: 0.4051 - accuracy: 0.8681 - val_loss: 0.7007 - val_accuracy: 0.8139 - lr: 7.7484e-04\n",
            "Epoch 100/100\n",
            "247/247 [==============================] - 7s 27ms/step - loss: 0.4177 - accuracy: 0.8643 - val_loss: 0.6929 - val_accuracy: 0.8208 - lr: 7.7484e-04\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.7764 - accuracy: 0.8036\n",
            "Accuracy: 0.8035632967948914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropout 추가\n",
        "#CRNN\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Reshape\n",
        "import tensorflow as tf\n",
        "\n",
        "# 데이터셋 디렉토리 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 클래스 레이블 설정 (클래스별 디렉토리 이름으로 가정)\n",
        "class_labels = os.listdir(data_dir)\n",
        "\n",
        "# MFCC 계수 개수 설정\n",
        "n_mfcc = 12\n",
        "\n",
        "# 데이터셋과 레이블을 저장할 리스트\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        X.append(mfccs.T)\n",
        "        labels.append(label)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X = np.array(X)\n",
        "\n",
        "# 레이블을 정수형으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(class_labels)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# 최대 길이에 맞춰 MFCC 벡터를 패딩\n",
        "max_length = max(len(mfccs) for mfccs in X)\n",
        "X = np.array([np.pad(mfccs, ((0, max_length - len(mfccs)), (0, 0)), mode='constant') for mfccs in X])\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))  # 추가된 Conv2D 레이어\n",
        "model.add(MaxPooling2D((2, 2)))  # 스트라이드 기본값인 (2, 2)로 유지\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))  # Dropout 비율 높임\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',padding='same'))  # 추가된 Conv2D 레이어\n",
        "model.add(MaxPooling2D((2, 2)))  # 스트라이드 기본값인 (2, 2)로 유지\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))  # Dropout 비율 높임\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',padding='same'))  # 추가된 Conv2D 레이어\n",
        "model.add(MaxPooling2D((2, 2)))  # 스트라이드 기본값인 (2, 2)로 유지\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))  # Dropout 비율 높임\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((1, 2)))  # 스트라이드를 (1, 2)로 변경\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))  # Dropout 비율 높임\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경 (예시로 하나의 LSTM 레이어만 사용)\n",
        "model.add(Reshape((X_train.shape[1] // 16, (X_train.shape[2] // 16) * 256)))  # 수정된 부분\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "initial_lr = 0.001  # 초기 학습률 설정\n",
        "\n",
        "# Learning Rate를 조정할 함수 정의\n",
        "def lr_schedule(epoch):\n",
        "    decay_rate = 0.9   # 학습률 감소 비율\n",
        "    decay_steps = 10    # 학습률 감소 주기 (에폭 단위)\n",
        "    lr = initial_lr * decay_rate**(epoch // decay_steps)\n",
        "    return lr\n",
        "\n",
        "# Learning Rate Scheduler 콜백 생성\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습 (Learning Rate Scheduler 콜백 추가)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[lr_scheduler])\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "eXff3MtDvfAk",
        "outputId": "597a9da9-ceb7-41ee-89f1-6369fe32a8fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7b16461ccd6e>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 스트라이드를 (1, 2)로 변경\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Dropout 비율 높임\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1971\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m   \u001b[0;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_7\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_7/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 1, 2, 1], padding=\"VALID\", strides=[1, 1, 2, 1]](Placeholder)' with input shapes: [?,7,1,256].\n\nCall arguments received by layer \"max_pooling2d_7\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 7, 1, 256), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iy_y0PX3vfDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ahfClDk5vfEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "muljIKNlvfGy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}