{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1T-iAZbRViFIqoFu9dk2A_Vc0ynJav8RG",
      "authorship_tag": "ABX9TyP4R1RLuQECuqYpw4gdrmCC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinJunJA/babymodel/blob/master/crnn_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NhxVuY7RSZkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33dd1ed4-7d1e-4dfa-e153-c946d278c68b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "247/247 [==============================] - 24s 16ms/step - loss: 1.6321 - accuracy: 0.3494 - val_loss: 1.4881 - val_accuracy: 0.4075 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.5012 - accuracy: 0.4196 - val_loss: 1.3659 - val_accuracy: 0.4646 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 1.4203 - accuracy: 0.4595 - val_loss: 1.3244 - val_accuracy: 0.4989 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.3540 - accuracy: 0.4948 - val_loss: 1.2295 - val_accuracy: 0.5445 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.3000 - accuracy: 0.5185 - val_loss: 1.2074 - val_accuracy: 0.5594 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 1.2473 - accuracy: 0.5404 - val_loss: 1.1684 - val_accuracy: 0.5559 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 1.1901 - accuracy: 0.5611 - val_loss: 1.1496 - val_accuracy: 0.5936 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 1.1620 - accuracy: 0.5847 - val_loss: 1.1132 - val_accuracy: 0.5890 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.1154 - accuracy: 0.5999 - val_loss: 1.0808 - val_accuracy: 0.6153 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.0594 - accuracy: 0.6261 - val_loss: 1.0462 - val_accuracy: 0.6301 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 1.0239 - accuracy: 0.6313 - val_loss: 1.0276 - val_accuracy: 0.6187 - lr: 9.0000e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.9803 - accuracy: 0.6571 - val_loss: 0.9542 - val_accuracy: 0.6621 - lr: 9.0000e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.9500 - accuracy: 0.6690 - val_loss: 0.9764 - val_accuracy: 0.6518 - lr: 9.0000e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9139 - accuracy: 0.6771 - val_loss: 0.9282 - val_accuracy: 0.6632 - lr: 9.0000e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.8962 - accuracy: 0.6888 - val_loss: 0.9344 - val_accuracy: 0.6735 - lr: 9.0000e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.8454 - accuracy: 0.7141 - val_loss: 0.9318 - val_accuracy: 0.6781 - lr: 9.0000e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.8196 - accuracy: 0.7181 - val_loss: 0.9033 - val_accuracy: 0.7043 - lr: 9.0000e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.8070 - accuracy: 0.7224 - val_loss: 0.8608 - val_accuracy: 0.7158 - lr: 9.0000e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.7701 - accuracy: 0.7369 - val_loss: 0.8570 - val_accuracy: 0.7100 - lr: 9.0000e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.7654 - accuracy: 0.7362 - val_loss: 0.8240 - val_accuracy: 0.7169 - lr: 9.0000e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.7277 - accuracy: 0.7546 - val_loss: 0.8745 - val_accuracy: 0.7295 - lr: 8.1000e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.7000 - accuracy: 0.7631 - val_loss: 0.8368 - val_accuracy: 0.7215 - lr: 8.1000e-04\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.6657 - accuracy: 0.7835 - val_loss: 0.8528 - val_accuracy: 0.7420 - lr: 8.1000e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.6644 - accuracy: 0.7744 - val_loss: 0.8030 - val_accuracy: 0.7523 - lr: 8.1000e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.6368 - accuracy: 0.7850 - val_loss: 0.8134 - val_accuracy: 0.7432 - lr: 8.1000e-04\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.6234 - accuracy: 0.7938 - val_loss: 0.7957 - val_accuracy: 0.7660 - lr: 8.1000e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.6121 - accuracy: 0.7993 - val_loss: 0.7355 - val_accuracy: 0.7785 - lr: 8.1000e-04\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.5900 - accuracy: 0.8019 - val_loss: 0.7579 - val_accuracy: 0.7705 - lr: 8.1000e-04\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.5828 - accuracy: 0.8073 - val_loss: 0.7546 - val_accuracy: 0.7831 - lr: 8.1000e-04\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.5861 - accuracy: 0.8097 - val_loss: 0.7443 - val_accuracy: 0.7842 - lr: 8.1000e-04\n",
            "Epoch 31/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.5326 - accuracy: 0.8257 - val_loss: 0.7975 - val_accuracy: 0.7763 - lr: 7.2900e-04\n",
            "Epoch 32/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.5488 - accuracy: 0.8162 - val_loss: 0.7517 - val_accuracy: 0.7945 - lr: 7.2900e-04\n",
            "Epoch 33/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.5259 - accuracy: 0.8286 - val_loss: 0.6928 - val_accuracy: 0.7854 - lr: 7.2900e-04\n",
            "Epoch 34/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.5044 - accuracy: 0.8333 - val_loss: 0.7509 - val_accuracy: 0.7854 - lr: 7.2900e-04\n",
            "Epoch 35/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.4896 - accuracy: 0.8431 - val_loss: 0.7422 - val_accuracy: 0.7957 - lr: 7.2900e-04\n",
            "Epoch 36/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4939 - accuracy: 0.8357 - val_loss: 0.7296 - val_accuracy: 0.7945 - lr: 7.2900e-04\n",
            "Epoch 37/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.4767 - accuracy: 0.8418 - val_loss: 0.7152 - val_accuracy: 0.8082 - lr: 7.2900e-04\n",
            "Epoch 38/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.4631 - accuracy: 0.8467 - val_loss: 0.6986 - val_accuracy: 0.8116 - lr: 7.2900e-04\n",
            "Epoch 39/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.4764 - accuracy: 0.8462 - val_loss: 0.7219 - val_accuracy: 0.8048 - lr: 7.2900e-04\n",
            "Epoch 40/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.4465 - accuracy: 0.8526 - val_loss: 0.7676 - val_accuracy: 0.8025 - lr: 7.2900e-04\n",
            "Epoch 41/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.4249 - accuracy: 0.8629 - val_loss: 0.7080 - val_accuracy: 0.8162 - lr: 6.5610e-04\n",
            "Epoch 42/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.4163 - accuracy: 0.8674 - val_loss: 0.7182 - val_accuracy: 0.8128 - lr: 6.5610e-04\n",
            "Epoch 43/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.4106 - accuracy: 0.8672 - val_loss: 0.7169 - val_accuracy: 0.8174 - lr: 6.5610e-04\n",
            "Epoch 44/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.4171 - accuracy: 0.8666 - val_loss: 0.7172 - val_accuracy: 0.8116 - lr: 6.5610e-04\n",
            "Epoch 45/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3893 - accuracy: 0.8776 - val_loss: 0.7307 - val_accuracy: 0.8208 - lr: 6.5610e-04\n",
            "Epoch 46/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3913 - accuracy: 0.8728 - val_loss: 0.7414 - val_accuracy: 0.8139 - lr: 6.5610e-04\n",
            "Epoch 47/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3796 - accuracy: 0.8754 - val_loss: 0.7195 - val_accuracy: 0.8276 - lr: 6.5610e-04\n",
            "Epoch 48/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3787 - accuracy: 0.8768 - val_loss: 0.6925 - val_accuracy: 0.8379 - lr: 6.5610e-04\n",
            "Epoch 49/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3664 - accuracy: 0.8836 - val_loss: 0.7569 - val_accuracy: 0.8185 - lr: 6.5610e-04\n",
            "Epoch 50/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3695 - accuracy: 0.8817 - val_loss: 0.7158 - val_accuracy: 0.8333 - lr: 6.5610e-04\n",
            "Epoch 51/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3661 - accuracy: 0.8861 - val_loss: 0.7309 - val_accuracy: 0.8299 - lr: 5.9049e-04\n",
            "Epoch 52/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3593 - accuracy: 0.8841 - val_loss: 0.6919 - val_accuracy: 0.8402 - lr: 5.9049e-04\n",
            "Epoch 53/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3357 - accuracy: 0.8893 - val_loss: 0.7495 - val_accuracy: 0.8402 - lr: 5.9049e-04\n",
            "Epoch 54/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3443 - accuracy: 0.8911 - val_loss: 0.7076 - val_accuracy: 0.8402 - lr: 5.9049e-04\n",
            "Epoch 55/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3268 - accuracy: 0.8986 - val_loss: 0.7034 - val_accuracy: 0.8402 - lr: 5.9049e-04\n",
            "Epoch 56/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3338 - accuracy: 0.8951 - val_loss: 0.6644 - val_accuracy: 0.8447 - lr: 5.9049e-04\n",
            "Epoch 57/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3285 - accuracy: 0.8951 - val_loss: 0.7082 - val_accuracy: 0.8368 - lr: 5.9049e-04\n",
            "Epoch 58/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3245 - accuracy: 0.8944 - val_loss: 0.7075 - val_accuracy: 0.8436 - lr: 5.9049e-04\n",
            "Epoch 59/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.3012 - accuracy: 0.9062 - val_loss: 0.7014 - val_accuracy: 0.8425 - lr: 5.9049e-04\n",
            "Epoch 60/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2998 - accuracy: 0.9048 - val_loss: 0.6821 - val_accuracy: 0.8436 - lr: 5.9049e-04\n",
            "Epoch 61/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2991 - accuracy: 0.9046 - val_loss: 0.6596 - val_accuracy: 0.8482 - lr: 5.3144e-04\n",
            "Epoch 62/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.3199 - accuracy: 0.8989 - val_loss: 0.6929 - val_accuracy: 0.8436 - lr: 5.3144e-04\n",
            "Epoch 63/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.2831 - accuracy: 0.9091 - val_loss: 0.7207 - val_accuracy: 0.8447 - lr: 5.3144e-04\n",
            "Epoch 64/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2872 - accuracy: 0.9086 - val_loss: 0.7144 - val_accuracy: 0.8413 - lr: 5.3144e-04\n",
            "Epoch 65/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2920 - accuracy: 0.9076 - val_loss: 0.6933 - val_accuracy: 0.8482 - lr: 5.3144e-04\n",
            "Epoch 66/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2844 - accuracy: 0.9079 - val_loss: 0.7494 - val_accuracy: 0.8379 - lr: 5.3144e-04\n",
            "Epoch 67/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2637 - accuracy: 0.9166 - val_loss: 0.7279 - val_accuracy: 0.8493 - lr: 5.3144e-04\n",
            "Epoch 68/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.2802 - accuracy: 0.9134 - val_loss: 0.7025 - val_accuracy: 0.8470 - lr: 5.3144e-04\n",
            "Epoch 69/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2677 - accuracy: 0.9132 - val_loss: 0.6898 - val_accuracy: 0.8596 - lr: 5.3144e-04\n",
            "Epoch 70/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2780 - accuracy: 0.9158 - val_loss: 0.6683 - val_accuracy: 0.8539 - lr: 5.3144e-04\n",
            "Epoch 71/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2449 - accuracy: 0.9204 - val_loss: 0.7061 - val_accuracy: 0.8505 - lr: 4.7830e-04\n",
            "Epoch 72/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.2520 - accuracy: 0.9184 - val_loss: 0.7092 - val_accuracy: 0.8470 - lr: 4.7830e-04\n",
            "Epoch 73/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.2464 - accuracy: 0.9223 - val_loss: 0.7059 - val_accuracy: 0.8413 - lr: 4.7830e-04\n",
            "Epoch 74/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2429 - accuracy: 0.9252 - val_loss: 0.7030 - val_accuracy: 0.8493 - lr: 4.7830e-04\n",
            "Epoch 75/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2319 - accuracy: 0.9253 - val_loss: 0.7154 - val_accuracy: 0.8527 - lr: 4.7830e-04\n",
            "Epoch 76/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2103 - accuracy: 0.9345 - val_loss: 0.7575 - val_accuracy: 0.8436 - lr: 4.7830e-04\n",
            "Epoch 77/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2246 - accuracy: 0.9321 - val_loss: 0.7502 - val_accuracy: 0.8447 - lr: 4.7830e-04\n",
            "Epoch 78/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2346 - accuracy: 0.9271 - val_loss: 0.7361 - val_accuracy: 0.8505 - lr: 4.7830e-04\n",
            "Epoch 79/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2492 - accuracy: 0.9231 - val_loss: 0.6822 - val_accuracy: 0.8470 - lr: 4.7830e-04\n",
            "Epoch 80/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2215 - accuracy: 0.9309 - val_loss: 0.7223 - val_accuracy: 0.8459 - lr: 4.7830e-04\n",
            "Epoch 81/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2281 - accuracy: 0.9294 - val_loss: 0.7322 - val_accuracy: 0.8527 - lr: 4.3047e-04\n",
            "Epoch 82/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2055 - accuracy: 0.9340 - val_loss: 0.7324 - val_accuracy: 0.8539 - lr: 4.3047e-04\n",
            "Epoch 83/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.2255 - accuracy: 0.9280 - val_loss: 0.7296 - val_accuracy: 0.8482 - lr: 4.3047e-04\n",
            "Epoch 84/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.2212 - accuracy: 0.9292 - val_loss: 0.7191 - val_accuracy: 0.8539 - lr: 4.3047e-04\n",
            "Epoch 85/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2160 - accuracy: 0.9316 - val_loss: 0.7390 - val_accuracy: 0.8527 - lr: 4.3047e-04\n",
            "Epoch 86/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2265 - accuracy: 0.9312 - val_loss: 0.7342 - val_accuracy: 0.8470 - lr: 4.3047e-04\n",
            "Epoch 87/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2046 - accuracy: 0.9358 - val_loss: 0.7096 - val_accuracy: 0.8516 - lr: 4.3047e-04\n",
            "Epoch 88/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2076 - accuracy: 0.9341 - val_loss: 0.7430 - val_accuracy: 0.8493 - lr: 4.3047e-04\n",
            "Epoch 89/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.2052 - accuracy: 0.9368 - val_loss: 0.7247 - val_accuracy: 0.8482 - lr: 4.3047e-04\n",
            "Epoch 90/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2038 - accuracy: 0.9375 - val_loss: 0.7365 - val_accuracy: 0.8425 - lr: 4.3047e-04\n",
            "Epoch 91/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.2032 - accuracy: 0.9389 - val_loss: 0.6994 - val_accuracy: 0.8539 - lr: 3.8742e-04\n",
            "Epoch 92/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1956 - accuracy: 0.9392 - val_loss: 0.7505 - val_accuracy: 0.8459 - lr: 3.8742e-04\n",
            "Epoch 93/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1932 - accuracy: 0.9407 - val_loss: 0.7571 - val_accuracy: 0.8505 - lr: 3.8742e-04\n",
            "Epoch 94/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1914 - accuracy: 0.9411 - val_loss: 0.7552 - val_accuracy: 0.8482 - lr: 3.8742e-04\n",
            "Epoch 95/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1909 - accuracy: 0.9399 - val_loss: 0.7650 - val_accuracy: 0.8493 - lr: 3.8742e-04\n",
            "Epoch 96/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1827 - accuracy: 0.9441 - val_loss: 0.7419 - val_accuracy: 0.8482 - lr: 3.8742e-04\n",
            "Epoch 97/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1813 - accuracy: 0.9445 - val_loss: 0.7809 - val_accuracy: 0.8493 - lr: 3.8742e-04\n",
            "Epoch 98/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1820 - accuracy: 0.9410 - val_loss: 0.7580 - val_accuracy: 0.8493 - lr: 3.8742e-04\n",
            "Epoch 99/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1741 - accuracy: 0.9465 - val_loss: 0.7400 - val_accuracy: 0.8539 - lr: 3.8742e-04\n",
            "Epoch 100/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1767 - accuracy: 0.9458 - val_loss: 0.7709 - val_accuracy: 0.8447 - lr: 3.8742e-04\n",
            "Epoch 101/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1806 - accuracy: 0.9441 - val_loss: 0.7807 - val_accuracy: 0.8550 - lr: 3.4868e-04\n",
            "Epoch 102/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1755 - accuracy: 0.9460 - val_loss: 0.7608 - val_accuracy: 0.8470 - lr: 3.4868e-04\n",
            "Epoch 103/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1913 - accuracy: 0.9387 - val_loss: 0.7662 - val_accuracy: 0.8470 - lr: 3.4868e-04\n",
            "Epoch 104/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1697 - accuracy: 0.9490 - val_loss: 0.7583 - val_accuracy: 0.8482 - lr: 3.4868e-04\n",
            "Epoch 105/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1722 - accuracy: 0.9488 - val_loss: 0.7460 - val_accuracy: 0.8550 - lr: 3.4868e-04\n",
            "Epoch 106/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1742 - accuracy: 0.9457 - val_loss: 0.7597 - val_accuracy: 0.8447 - lr: 3.4868e-04\n",
            "Epoch 107/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1657 - accuracy: 0.9474 - val_loss: 0.7199 - val_accuracy: 0.8493 - lr: 3.4868e-04\n",
            "Epoch 108/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1763 - accuracy: 0.9468 - val_loss: 0.7541 - val_accuracy: 0.8493 - lr: 3.4868e-04\n",
            "Epoch 109/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1582 - accuracy: 0.9516 - val_loss: 0.7650 - val_accuracy: 0.8482 - lr: 3.4868e-04\n",
            "Epoch 110/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1602 - accuracy: 0.9481 - val_loss: 0.7456 - val_accuracy: 0.8607 - lr: 3.4868e-04\n",
            "Epoch 111/200\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.1539 - accuracy: 0.9534 - val_loss: 0.7464 - val_accuracy: 0.8550 - lr: 3.1381e-04\n",
            "Epoch 112/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1541 - accuracy: 0.9526 - val_loss: 0.7494 - val_accuracy: 0.8619 - lr: 3.1381e-04\n",
            "Epoch 113/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1568 - accuracy: 0.9523 - val_loss: 0.7403 - val_accuracy: 0.8550 - lr: 3.1381e-04\n",
            "Epoch 114/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1513 - accuracy: 0.9528 - val_loss: 0.7711 - val_accuracy: 0.8527 - lr: 3.1381e-04\n",
            "Epoch 115/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1521 - accuracy: 0.9509 - val_loss: 0.7571 - val_accuracy: 0.8550 - lr: 3.1381e-04\n",
            "Epoch 116/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1616 - accuracy: 0.9516 - val_loss: 0.7652 - val_accuracy: 0.8619 - lr: 3.1381e-04\n",
            "Epoch 117/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1491 - accuracy: 0.9528 - val_loss: 0.8118 - val_accuracy: 0.8516 - lr: 3.1381e-04\n",
            "Epoch 118/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1438 - accuracy: 0.9577 - val_loss: 0.7805 - val_accuracy: 0.8550 - lr: 3.1381e-04\n",
            "Epoch 119/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1566 - accuracy: 0.9521 - val_loss: 0.7154 - val_accuracy: 0.8584 - lr: 3.1381e-04\n",
            "Epoch 120/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1529 - accuracy: 0.9523 - val_loss: 0.7368 - val_accuracy: 0.8505 - lr: 3.1381e-04\n",
            "Epoch 121/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1340 - accuracy: 0.9598 - val_loss: 0.7501 - val_accuracy: 0.8607 - lr: 2.8243e-04\n",
            "Epoch 122/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1466 - accuracy: 0.9562 - val_loss: 0.7459 - val_accuracy: 0.8607 - lr: 2.8243e-04\n",
            "Epoch 123/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1309 - accuracy: 0.9603 - val_loss: 0.7336 - val_accuracy: 0.8550 - lr: 2.8243e-04\n",
            "Epoch 124/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1420 - accuracy: 0.9598 - val_loss: 0.6876 - val_accuracy: 0.8607 - lr: 2.8243e-04\n",
            "Epoch 125/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1348 - accuracy: 0.9608 - val_loss: 0.7148 - val_accuracy: 0.8573 - lr: 2.8243e-04\n",
            "Epoch 126/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1235 - accuracy: 0.9617 - val_loss: 0.7269 - val_accuracy: 0.8573 - lr: 2.8243e-04\n",
            "Epoch 127/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1465 - accuracy: 0.9549 - val_loss: 0.7386 - val_accuracy: 0.8539 - lr: 2.8243e-04\n",
            "Epoch 128/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1428 - accuracy: 0.9576 - val_loss: 0.7576 - val_accuracy: 0.8527 - lr: 2.8243e-04\n",
            "Epoch 129/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1265 - accuracy: 0.9614 - val_loss: 0.7751 - val_accuracy: 0.8527 - lr: 2.8243e-04\n",
            "Epoch 130/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1338 - accuracy: 0.9592 - val_loss: 0.7770 - val_accuracy: 0.8493 - lr: 2.8243e-04\n",
            "Epoch 131/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1378 - accuracy: 0.9577 - val_loss: 0.7705 - val_accuracy: 0.8573 - lr: 2.5419e-04\n",
            "Epoch 132/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1279 - accuracy: 0.9585 - val_loss: 0.7736 - val_accuracy: 0.8527 - lr: 2.5419e-04\n",
            "Epoch 133/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1252 - accuracy: 0.9619 - val_loss: 0.7608 - val_accuracy: 0.8539 - lr: 2.5419e-04\n",
            "Epoch 134/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1270 - accuracy: 0.9619 - val_loss: 0.7872 - val_accuracy: 0.8539 - lr: 2.5419e-04\n",
            "Epoch 135/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1251 - accuracy: 0.9625 - val_loss: 0.7513 - val_accuracy: 0.8550 - lr: 2.5419e-04\n",
            "Epoch 136/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1206 - accuracy: 0.9647 - val_loss: 0.7671 - val_accuracy: 0.8562 - lr: 2.5419e-04\n",
            "Epoch 137/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1311 - accuracy: 0.9603 - val_loss: 0.8127 - val_accuracy: 0.8527 - lr: 2.5419e-04\n",
            "Epoch 138/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1231 - accuracy: 0.9634 - val_loss: 0.8396 - val_accuracy: 0.8516 - lr: 2.5419e-04\n",
            "Epoch 139/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1273 - accuracy: 0.9614 - val_loss: 0.8029 - val_accuracy: 0.8505 - lr: 2.5419e-04\n",
            "Epoch 140/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1351 - accuracy: 0.9604 - val_loss: 0.8090 - val_accuracy: 0.8550 - lr: 2.5419e-04\n",
            "Epoch 141/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1235 - accuracy: 0.9611 - val_loss: 0.7678 - val_accuracy: 0.8596 - lr: 2.2877e-04\n",
            "Epoch 142/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1230 - accuracy: 0.9610 - val_loss: 0.7732 - val_accuracy: 0.8516 - lr: 2.2877e-04\n",
            "Epoch 143/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1356 - accuracy: 0.9604 - val_loss: 0.7870 - val_accuracy: 0.8539 - lr: 2.2877e-04\n",
            "Epoch 144/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1201 - accuracy: 0.9641 - val_loss: 0.7852 - val_accuracy: 0.8584 - lr: 2.2877e-04\n",
            "Epoch 145/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1168 - accuracy: 0.9632 - val_loss: 0.7778 - val_accuracy: 0.8539 - lr: 2.2877e-04\n",
            "Epoch 146/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1096 - accuracy: 0.9667 - val_loss: 0.7837 - val_accuracy: 0.8607 - lr: 2.2877e-04\n",
            "Epoch 147/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1235 - accuracy: 0.9625 - val_loss: 0.7937 - val_accuracy: 0.8539 - lr: 2.2877e-04\n",
            "Epoch 148/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1222 - accuracy: 0.9637 - val_loss: 0.7885 - val_accuracy: 0.8539 - lr: 2.2877e-04\n",
            "Epoch 149/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1053 - accuracy: 0.9688 - val_loss: 0.7990 - val_accuracy: 0.8562 - lr: 2.2877e-04\n",
            "Epoch 150/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1187 - accuracy: 0.9634 - val_loss: 0.8211 - val_accuracy: 0.8562 - lr: 2.2877e-04\n",
            "Epoch 151/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1035 - accuracy: 0.9689 - val_loss: 0.8161 - val_accuracy: 0.8539 - lr: 2.0589e-04\n",
            "Epoch 152/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1091 - accuracy: 0.9669 - val_loss: 0.8238 - val_accuracy: 0.8493 - lr: 2.0589e-04\n",
            "Epoch 153/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1127 - accuracy: 0.9653 - val_loss: 0.8360 - val_accuracy: 0.8539 - lr: 2.0589e-04\n",
            "Epoch 154/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1267 - accuracy: 0.9589 - val_loss: 0.8266 - val_accuracy: 0.8550 - lr: 2.0589e-04\n",
            "Epoch 155/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1107 - accuracy: 0.9667 - val_loss: 0.8301 - val_accuracy: 0.8470 - lr: 2.0589e-04\n",
            "Epoch 156/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1122 - accuracy: 0.9651 - val_loss: 0.8239 - val_accuracy: 0.8505 - lr: 2.0589e-04\n",
            "Epoch 157/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1059 - accuracy: 0.9671 - val_loss: 0.8059 - val_accuracy: 0.8493 - lr: 2.0589e-04\n",
            "Epoch 158/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1010 - accuracy: 0.9698 - val_loss: 0.8348 - val_accuracy: 0.8516 - lr: 2.0589e-04\n",
            "Epoch 159/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1043 - accuracy: 0.9669 - val_loss: 0.8110 - val_accuracy: 0.8539 - lr: 2.0589e-04\n",
            "Epoch 160/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1046 - accuracy: 0.9670 - val_loss: 0.8359 - val_accuracy: 0.8550 - lr: 2.0589e-04\n",
            "Epoch 161/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1045 - accuracy: 0.9680 - val_loss: 0.8454 - val_accuracy: 0.8550 - lr: 1.8530e-04\n",
            "Epoch 162/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1081 - accuracy: 0.9683 - val_loss: 0.8206 - val_accuracy: 0.8516 - lr: 1.8530e-04\n",
            "Epoch 163/200\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.1066 - accuracy: 0.9690 - val_loss: 0.8053 - val_accuracy: 0.8550 - lr: 1.8530e-04\n",
            "Epoch 164/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0999 - accuracy: 0.9705 - val_loss: 0.8127 - val_accuracy: 0.8607 - lr: 1.8530e-04\n",
            "Epoch 165/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1026 - accuracy: 0.9693 - val_loss: 0.8517 - val_accuracy: 0.8550 - lr: 1.8530e-04\n",
            "Epoch 166/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.0994 - accuracy: 0.9705 - val_loss: 0.8640 - val_accuracy: 0.8539 - lr: 1.8530e-04\n",
            "Epoch 167/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0969 - accuracy: 0.9690 - val_loss: 0.8458 - val_accuracy: 0.8505 - lr: 1.8530e-04\n",
            "Epoch 168/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0979 - accuracy: 0.9714 - val_loss: 0.8557 - val_accuracy: 0.8562 - lr: 1.8530e-04\n",
            "Epoch 169/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0936 - accuracy: 0.9686 - val_loss: 0.8569 - val_accuracy: 0.8584 - lr: 1.8530e-04\n",
            "Epoch 170/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0945 - accuracy: 0.9727 - val_loss: 0.8353 - val_accuracy: 0.8584 - lr: 1.8530e-04\n",
            "Epoch 171/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1012 - accuracy: 0.9690 - val_loss: 0.8521 - val_accuracy: 0.8550 - lr: 1.6677e-04\n",
            "Epoch 172/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0922 - accuracy: 0.9737 - val_loss: 0.8675 - val_accuracy: 0.8516 - lr: 1.6677e-04\n",
            "Epoch 173/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0964 - accuracy: 0.9712 - val_loss: 0.8597 - val_accuracy: 0.8527 - lr: 1.6677e-04\n",
            "Epoch 174/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0957 - accuracy: 0.9730 - val_loss: 0.8655 - val_accuracy: 0.8562 - lr: 1.6677e-04\n",
            "Epoch 175/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.1014 - accuracy: 0.9700 - val_loss: 0.8303 - val_accuracy: 0.8607 - lr: 1.6677e-04\n",
            "Epoch 176/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.0899 - accuracy: 0.9707 - val_loss: 0.8560 - val_accuracy: 0.8539 - lr: 1.6677e-04\n",
            "Epoch 177/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0940 - accuracy: 0.9714 - val_loss: 0.8542 - val_accuracy: 0.8596 - lr: 1.6677e-04\n",
            "Epoch 178/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0992 - accuracy: 0.9702 - val_loss: 0.8681 - val_accuracy: 0.8516 - lr: 1.6677e-04\n",
            "Epoch 179/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0869 - accuracy: 0.9749 - val_loss: 0.8475 - val_accuracy: 0.8550 - lr: 1.6677e-04\n",
            "Epoch 180/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0964 - accuracy: 0.9728 - val_loss: 0.8562 - val_accuracy: 0.8539 - lr: 1.6677e-04\n",
            "Epoch 181/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.0888 - accuracy: 0.9749 - val_loss: 0.8442 - val_accuracy: 0.8573 - lr: 1.5009e-04\n",
            "Epoch 182/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0967 - accuracy: 0.9695 - val_loss: 0.8445 - val_accuracy: 0.8550 - lr: 1.5009e-04\n",
            "Epoch 183/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0964 - accuracy: 0.9702 - val_loss: 0.8550 - val_accuracy: 0.8527 - lr: 1.5009e-04\n",
            "Epoch 184/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0862 - accuracy: 0.9726 - val_loss: 0.8726 - val_accuracy: 0.8516 - lr: 1.5009e-04\n",
            "Epoch 185/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0920 - accuracy: 0.9731 - val_loss: 0.8648 - val_accuracy: 0.8550 - lr: 1.5009e-04\n",
            "Epoch 186/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.0734 - accuracy: 0.9785 - val_loss: 0.8631 - val_accuracy: 0.8539 - lr: 1.5009e-04\n",
            "Epoch 187/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0849 - accuracy: 0.9731 - val_loss: 0.8366 - val_accuracy: 0.8539 - lr: 1.5009e-04\n",
            "Epoch 188/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0885 - accuracy: 0.9738 - val_loss: 0.8484 - val_accuracy: 0.8550 - lr: 1.5009e-04\n",
            "Epoch 189/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0913 - accuracy: 0.9712 - val_loss: 0.8387 - val_accuracy: 0.8516 - lr: 1.5009e-04\n",
            "Epoch 190/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0795 - accuracy: 0.9769 - val_loss: 0.8660 - val_accuracy: 0.8539 - lr: 1.5009e-04\n",
            "Epoch 191/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0895 - accuracy: 0.9745 - val_loss: 0.8478 - val_accuracy: 0.8584 - lr: 1.3509e-04\n",
            "Epoch 192/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0789 - accuracy: 0.9769 - val_loss: 0.8799 - val_accuracy: 0.8527 - lr: 1.3509e-04\n",
            "Epoch 193/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0849 - accuracy: 0.9744 - val_loss: 0.8613 - val_accuracy: 0.8550 - lr: 1.3509e-04\n",
            "Epoch 194/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0816 - accuracy: 0.9774 - val_loss: 0.8990 - val_accuracy: 0.8493 - lr: 1.3509e-04\n",
            "Epoch 195/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0842 - accuracy: 0.9742 - val_loss: 0.8756 - val_accuracy: 0.8527 - lr: 1.3509e-04\n",
            "Epoch 196/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0895 - accuracy: 0.9728 - val_loss: 0.8843 - val_accuracy: 0.8539 - lr: 1.3509e-04\n",
            "Epoch 197/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0858 - accuracy: 0.9770 - val_loss: 0.8921 - val_accuracy: 0.8516 - lr: 1.3509e-04\n",
            "Epoch 198/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0805 - accuracy: 0.9763 - val_loss: 0.8919 - val_accuracy: 0.8505 - lr: 1.3509e-04\n",
            "Epoch 199/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.0797 - accuracy: 0.9771 - val_loss: 0.8792 - val_accuracy: 0.8596 - lr: 1.3509e-04\n",
            "Epoch 200/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0873 - accuracy: 0.9749 - val_loss: 0.8629 - val_accuracy: 0.8550 - lr: 1.3509e-04\n",
            "Epoch 1/200\n",
            "247/247 [==============================] - 10s 15ms/step - loss: 1.6308 - accuracy: 0.3474 - val_loss: 1.4680 - val_accuracy: 0.4269 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 1.4991 - accuracy: 0.4210 - val_loss: 1.3816 - val_accuracy: 0.4783 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.4148 - accuracy: 0.4634 - val_loss: 1.3162 - val_accuracy: 0.5023 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.3616 - accuracy: 0.4958 - val_loss: 1.2602 - val_accuracy: 0.5251 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 1.2909 - accuracy: 0.5216 - val_loss: 1.2341 - val_accuracy: 0.5468 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 1.2554 - accuracy: 0.5434 - val_loss: 1.1693 - val_accuracy: 0.5616 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.1851 - accuracy: 0.5639 - val_loss: 1.1504 - val_accuracy: 0.5799 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.1468 - accuracy: 0.5865 - val_loss: 1.1253 - val_accuracy: 0.6039 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.1040 - accuracy: 0.6091 - val_loss: 1.0800 - val_accuracy: 0.6062 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 1.0513 - accuracy: 0.6187 - val_loss: 1.0119 - val_accuracy: 0.6324 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 1.0238 - accuracy: 0.6378 - val_loss: 0.9863 - val_accuracy: 0.6530 - lr: 9.0000e-04\n",
            "Epoch 12/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.9651 - accuracy: 0.6616 - val_loss: 0.9636 - val_accuracy: 0.6678 - lr: 9.0000e-04\n",
            "Epoch 13/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.9309 - accuracy: 0.6745 - val_loss: 0.9710 - val_accuracy: 0.6587 - lr: 9.0000e-04\n",
            "Epoch 14/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.8937 - accuracy: 0.6902 - val_loss: 0.8821 - val_accuracy: 0.6998 - lr: 9.0000e-04\n",
            "Epoch 15/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.8641 - accuracy: 0.6991 - val_loss: 0.8633 - val_accuracy: 0.7032 - lr: 9.0000e-04\n",
            "Epoch 16/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.8522 - accuracy: 0.7067 - val_loss: 0.8535 - val_accuracy: 0.7078 - lr: 9.0000e-04\n",
            "Epoch 17/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.8248 - accuracy: 0.7103 - val_loss: 0.8903 - val_accuracy: 0.7066 - lr: 9.0000e-04\n",
            "Epoch 18/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.8017 - accuracy: 0.7249 - val_loss: 0.8425 - val_accuracy: 0.7100 - lr: 9.0000e-04\n",
            "Epoch 19/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.7670 - accuracy: 0.7406 - val_loss: 0.8225 - val_accuracy: 0.7329 - lr: 9.0000e-04\n",
            "Epoch 20/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.7486 - accuracy: 0.7495 - val_loss: 0.8219 - val_accuracy: 0.7317 - lr: 9.0000e-04\n",
            "Epoch 21/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.7246 - accuracy: 0.7557 - val_loss: 0.8252 - val_accuracy: 0.7363 - lr: 8.1000e-04\n",
            "Epoch 22/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.6772 - accuracy: 0.7694 - val_loss: 0.8035 - val_accuracy: 0.7523 - lr: 8.1000e-04\n",
            "Epoch 23/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6515 - accuracy: 0.7842 - val_loss: 0.7932 - val_accuracy: 0.7500 - lr: 8.1000e-04\n",
            "Epoch 24/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.6551 - accuracy: 0.7803 - val_loss: 0.7706 - val_accuracy: 0.7568 - lr: 8.1000e-04\n",
            "Epoch 25/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.6457 - accuracy: 0.7847 - val_loss: 0.7311 - val_accuracy: 0.7865 - lr: 8.1000e-04\n",
            "Epoch 26/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.6126 - accuracy: 0.7915 - val_loss: 0.7760 - val_accuracy: 0.7546 - lr: 8.1000e-04\n",
            "Epoch 27/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5918 - accuracy: 0.8028 - val_loss: 0.7656 - val_accuracy: 0.7671 - lr: 8.1000e-04\n",
            "Epoch 28/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.5983 - accuracy: 0.8007 - val_loss: 0.7481 - val_accuracy: 0.7660 - lr: 8.1000e-04\n",
            "Epoch 29/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.5517 - accuracy: 0.8188 - val_loss: 0.7243 - val_accuracy: 0.7877 - lr: 8.1000e-04\n",
            "Epoch 30/200\n",
            "247/247 [==============================] - 3s 10ms/step - loss: 0.5674 - accuracy: 0.8184 - val_loss: 0.7708 - val_accuracy: 0.7740 - lr: 8.1000e-04\n",
            "Epoch 31/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.5502 - accuracy: 0.8235 - val_loss: 0.7419 - val_accuracy: 0.7820 - lr: 7.2900e-04\n",
            "Epoch 32/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5259 - accuracy: 0.8281 - val_loss: 0.7159 - val_accuracy: 0.7797 - lr: 7.2900e-04\n",
            "Epoch 33/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.5110 - accuracy: 0.8332 - val_loss: 0.7114 - val_accuracy: 0.7991 - lr: 7.2900e-04\n",
            "Epoch 34/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4936 - accuracy: 0.8400 - val_loss: 0.7404 - val_accuracy: 0.7877 - lr: 7.2900e-04\n",
            "Epoch 35/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4965 - accuracy: 0.8360 - val_loss: 0.7415 - val_accuracy: 0.7979 - lr: 7.2900e-04\n",
            "Epoch 36/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.4649 - accuracy: 0.8506 - val_loss: 0.7671 - val_accuracy: 0.7785 - lr: 7.2900e-04\n",
            "Epoch 37/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.5053 - accuracy: 0.8389 - val_loss: 0.6942 - val_accuracy: 0.8105 - lr: 7.2900e-04\n",
            "Epoch 38/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4662 - accuracy: 0.8469 - val_loss: 0.6944 - val_accuracy: 0.8116 - lr: 7.2900e-04\n",
            "Epoch 39/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4642 - accuracy: 0.8497 - val_loss: 0.6954 - val_accuracy: 0.8151 - lr: 7.2900e-04\n",
            "Epoch 40/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4390 - accuracy: 0.8579 - val_loss: 0.7021 - val_accuracy: 0.8174 - lr: 7.2900e-04\n",
            "Epoch 41/200\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.4270 - accuracy: 0.8643 - val_loss: 0.6770 - val_accuracy: 0.8276 - lr: 6.5610e-04\n",
            "Epoch 42/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4213 - accuracy: 0.8643 - val_loss: 0.6914 - val_accuracy: 0.8185 - lr: 6.5610e-04\n",
            "Epoch 43/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4197 - accuracy: 0.8657 - val_loss: 0.6878 - val_accuracy: 0.8151 - lr: 6.5610e-04\n",
            "Epoch 44/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.4016 - accuracy: 0.8723 - val_loss: 0.6902 - val_accuracy: 0.8105 - lr: 6.5610e-04\n",
            "Epoch 45/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3742 - accuracy: 0.8804 - val_loss: 0.6831 - val_accuracy: 0.8208 - lr: 6.5610e-04\n",
            "Epoch 46/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3829 - accuracy: 0.8796 - val_loss: 0.6667 - val_accuracy: 0.8253 - lr: 6.5610e-04\n",
            "Epoch 47/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3747 - accuracy: 0.8805 - val_loss: 0.6995 - val_accuracy: 0.8208 - lr: 6.5610e-04\n",
            "Epoch 48/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3834 - accuracy: 0.8799 - val_loss: 0.6909 - val_accuracy: 0.8311 - lr: 6.5610e-04\n",
            "Epoch 49/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3733 - accuracy: 0.8776 - val_loss: 0.6924 - val_accuracy: 0.8185 - lr: 6.5610e-04\n",
            "Epoch 50/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3715 - accuracy: 0.8862 - val_loss: 0.6816 - val_accuracy: 0.8345 - lr: 6.5610e-04\n",
            "Epoch 51/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.3666 - accuracy: 0.8822 - val_loss: 0.7664 - val_accuracy: 0.8116 - lr: 5.9049e-04\n",
            "Epoch 52/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3332 - accuracy: 0.8956 - val_loss: 0.7005 - val_accuracy: 0.8208 - lr: 5.9049e-04\n",
            "Epoch 53/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3396 - accuracy: 0.8937 - val_loss: 0.6876 - val_accuracy: 0.8276 - lr: 5.9049e-04\n",
            "Epoch 54/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3212 - accuracy: 0.8986 - val_loss: 0.6809 - val_accuracy: 0.8265 - lr: 5.9049e-04\n",
            "Epoch 55/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.3377 - accuracy: 0.8942 - val_loss: 0.7093 - val_accuracy: 0.8276 - lr: 5.9049e-04\n",
            "Epoch 56/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.3049 - accuracy: 0.9035 - val_loss: 0.7550 - val_accuracy: 0.8322 - lr: 5.9049e-04\n",
            "Epoch 57/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3162 - accuracy: 0.9022 - val_loss: 0.7065 - val_accuracy: 0.8299 - lr: 5.9049e-04\n",
            "Epoch 58/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3049 - accuracy: 0.9008 - val_loss: 0.7128 - val_accuracy: 0.8311 - lr: 5.9049e-04\n",
            "Epoch 59/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3002 - accuracy: 0.9088 - val_loss: 0.7036 - val_accuracy: 0.8231 - lr: 5.9049e-04\n",
            "Epoch 60/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.3100 - accuracy: 0.9027 - val_loss: 0.7150 - val_accuracy: 0.8288 - lr: 5.9049e-04\n",
            "Epoch 61/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2900 - accuracy: 0.9081 - val_loss: 0.7320 - val_accuracy: 0.8322 - lr: 5.3144e-04\n",
            "Epoch 62/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2998 - accuracy: 0.9040 - val_loss: 0.7006 - val_accuracy: 0.8242 - lr: 5.3144e-04\n",
            "Epoch 63/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.3065 - accuracy: 0.9029 - val_loss: 0.6718 - val_accuracy: 0.8379 - lr: 5.3144e-04\n",
            "Epoch 64/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2810 - accuracy: 0.9146 - val_loss: 0.6663 - val_accuracy: 0.8436 - lr: 5.3144e-04\n",
            "Epoch 65/200\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.2656 - accuracy: 0.9163 - val_loss: 0.7124 - val_accuracy: 0.8459 - lr: 5.3144e-04\n",
            "Epoch 66/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2659 - accuracy: 0.9187 - val_loss: 0.7160 - val_accuracy: 0.8459 - lr: 5.3144e-04\n",
            "Epoch 67/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2863 - accuracy: 0.9097 - val_loss: 0.7293 - val_accuracy: 0.8356 - lr: 5.3144e-04\n",
            "Epoch 68/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2831 - accuracy: 0.9074 - val_loss: 0.7352 - val_accuracy: 0.8368 - lr: 5.3144e-04\n",
            "Epoch 69/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2576 - accuracy: 0.9187 - val_loss: 0.7497 - val_accuracy: 0.8299 - lr: 5.3144e-04\n",
            "Epoch 70/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2527 - accuracy: 0.9242 - val_loss: 0.7267 - val_accuracy: 0.8368 - lr: 5.3144e-04\n",
            "Epoch 71/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2468 - accuracy: 0.9208 - val_loss: 0.7354 - val_accuracy: 0.8311 - lr: 4.7830e-04\n",
            "Epoch 72/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2389 - accuracy: 0.9271 - val_loss: 0.7451 - val_accuracy: 0.8368 - lr: 4.7830e-04\n",
            "Epoch 73/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2371 - accuracy: 0.9284 - val_loss: 0.7085 - val_accuracy: 0.8356 - lr: 4.7830e-04\n",
            "Epoch 74/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2556 - accuracy: 0.9182 - val_loss: 0.7014 - val_accuracy: 0.8368 - lr: 4.7830e-04\n",
            "Epoch 75/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2389 - accuracy: 0.9252 - val_loss: 0.7310 - val_accuracy: 0.8425 - lr: 4.7830e-04\n",
            "Epoch 76/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2315 - accuracy: 0.9272 - val_loss: 0.7197 - val_accuracy: 0.8368 - lr: 4.7830e-04\n",
            "Epoch 77/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2269 - accuracy: 0.9288 - val_loss: 0.7136 - val_accuracy: 0.8379 - lr: 4.7830e-04\n",
            "Epoch 78/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2366 - accuracy: 0.9269 - val_loss: 0.7512 - val_accuracy: 0.8333 - lr: 4.7830e-04\n",
            "Epoch 79/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2129 - accuracy: 0.9345 - val_loss: 0.7467 - val_accuracy: 0.8402 - lr: 4.7830e-04\n",
            "Epoch 80/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.2236 - accuracy: 0.9327 - val_loss: 0.7414 - val_accuracy: 0.8333 - lr: 4.7830e-04\n",
            "Epoch 81/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2169 - accuracy: 0.9361 - val_loss: 0.7687 - val_accuracy: 0.8379 - lr: 4.3047e-04\n",
            "Epoch 82/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2222 - accuracy: 0.9292 - val_loss: 0.7842 - val_accuracy: 0.8356 - lr: 4.3047e-04\n",
            "Epoch 83/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2099 - accuracy: 0.9345 - val_loss: 0.7627 - val_accuracy: 0.8345 - lr: 4.3047e-04\n",
            "Epoch 84/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.2062 - accuracy: 0.9365 - val_loss: 0.7563 - val_accuracy: 0.8390 - lr: 4.3047e-04\n",
            "Epoch 85/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2175 - accuracy: 0.9344 - val_loss: 0.7698 - val_accuracy: 0.8413 - lr: 4.3047e-04\n",
            "Epoch 86/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2064 - accuracy: 0.9345 - val_loss: 0.7042 - val_accuracy: 0.8505 - lr: 4.3047e-04\n",
            "Epoch 87/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2083 - accuracy: 0.9364 - val_loss: 0.7236 - val_accuracy: 0.8505 - lr: 4.3047e-04\n",
            "Epoch 88/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.2015 - accuracy: 0.9352 - val_loss: 0.7335 - val_accuracy: 0.8459 - lr: 4.3047e-04\n",
            "Epoch 89/200\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.1865 - accuracy: 0.9411 - val_loss: 0.7336 - val_accuracy: 0.8368 - lr: 4.3047e-04\n",
            "Epoch 90/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1885 - accuracy: 0.9399 - val_loss: 0.7550 - val_accuracy: 0.8436 - lr: 4.3047e-04\n",
            "Epoch 91/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1986 - accuracy: 0.9378 - val_loss: 0.7494 - val_accuracy: 0.8425 - lr: 3.8742e-04\n",
            "Epoch 92/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1879 - accuracy: 0.9394 - val_loss: 0.7867 - val_accuracy: 0.8402 - lr: 3.8742e-04\n",
            "Epoch 93/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.2116 - accuracy: 0.9352 - val_loss: 0.7808 - val_accuracy: 0.8447 - lr: 3.8742e-04\n",
            "Epoch 94/200\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.1891 - accuracy: 0.9418 - val_loss: 0.7904 - val_accuracy: 0.8425 - lr: 3.8742e-04\n",
            "Epoch 95/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1910 - accuracy: 0.9417 - val_loss: 0.7782 - val_accuracy: 0.8482 - lr: 3.8742e-04\n",
            "Epoch 96/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1925 - accuracy: 0.9416 - val_loss: 0.7745 - val_accuracy: 0.8425 - lr: 3.8742e-04\n",
            "Epoch 97/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1998 - accuracy: 0.9416 - val_loss: 0.8117 - val_accuracy: 0.8356 - lr: 3.8742e-04\n",
            "Epoch 98/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1753 - accuracy: 0.9473 - val_loss: 0.7888 - val_accuracy: 0.8299 - lr: 3.8742e-04\n",
            "Epoch 99/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1774 - accuracy: 0.9446 - val_loss: 0.7791 - val_accuracy: 0.8459 - lr: 3.8742e-04\n",
            "Epoch 100/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1795 - accuracy: 0.9458 - val_loss: 0.8045 - val_accuracy: 0.8402 - lr: 3.8742e-04\n",
            "Epoch 101/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1669 - accuracy: 0.9497 - val_loss: 0.8093 - val_accuracy: 0.8390 - lr: 3.4868e-04\n",
            "Epoch 102/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1779 - accuracy: 0.9458 - val_loss: 0.7746 - val_accuracy: 0.8482 - lr: 3.4868e-04\n",
            "Epoch 103/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1684 - accuracy: 0.9469 - val_loss: 0.7826 - val_accuracy: 0.8505 - lr: 3.4868e-04\n",
            "Epoch 104/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1690 - accuracy: 0.9449 - val_loss: 0.7899 - val_accuracy: 0.8516 - lr: 3.4868e-04\n",
            "Epoch 105/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1644 - accuracy: 0.9465 - val_loss: 0.8186 - val_accuracy: 0.8402 - lr: 3.4868e-04\n",
            "Epoch 106/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1677 - accuracy: 0.9476 - val_loss: 0.8350 - val_accuracy: 0.8470 - lr: 3.4868e-04\n",
            "Epoch 107/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1709 - accuracy: 0.9464 - val_loss: 0.7779 - val_accuracy: 0.8493 - lr: 3.4868e-04\n",
            "Epoch 108/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1578 - accuracy: 0.9528 - val_loss: 0.8065 - val_accuracy: 0.8425 - lr: 3.4868e-04\n",
            "Epoch 109/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1591 - accuracy: 0.9521 - val_loss: 0.7942 - val_accuracy: 0.8425 - lr: 3.4868e-04\n",
            "Epoch 110/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1607 - accuracy: 0.9509 - val_loss: 0.8114 - val_accuracy: 0.8436 - lr: 3.4868e-04\n",
            "Epoch 111/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1569 - accuracy: 0.9526 - val_loss: 0.8077 - val_accuracy: 0.8379 - lr: 3.1381e-04\n",
            "Epoch 112/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1673 - accuracy: 0.9460 - val_loss: 0.7785 - val_accuracy: 0.8447 - lr: 3.1381e-04\n",
            "Epoch 113/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1567 - accuracy: 0.9512 - val_loss: 0.7910 - val_accuracy: 0.8459 - lr: 3.1381e-04\n",
            "Epoch 114/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1484 - accuracy: 0.9544 - val_loss: 0.7891 - val_accuracy: 0.8413 - lr: 3.1381e-04\n",
            "Epoch 115/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1486 - accuracy: 0.9549 - val_loss: 0.7920 - val_accuracy: 0.8459 - lr: 3.1381e-04\n",
            "Epoch 116/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1547 - accuracy: 0.9537 - val_loss: 0.7954 - val_accuracy: 0.8482 - lr: 3.1381e-04\n",
            "Epoch 117/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1584 - accuracy: 0.9491 - val_loss: 0.7873 - val_accuracy: 0.8402 - lr: 3.1381e-04\n",
            "Epoch 118/200\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.1593 - accuracy: 0.9514 - val_loss: 0.8557 - val_accuracy: 0.8322 - lr: 3.1381e-04\n",
            "Epoch 119/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1365 - accuracy: 0.9595 - val_loss: 0.8021 - val_accuracy: 0.8402 - lr: 3.1381e-04\n",
            "Epoch 120/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1410 - accuracy: 0.9591 - val_loss: 0.7925 - val_accuracy: 0.8447 - lr: 3.1381e-04\n",
            "Epoch 121/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1430 - accuracy: 0.9561 - val_loss: 0.7896 - val_accuracy: 0.8447 - lr: 2.8243e-04\n",
            "Epoch 122/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1343 - accuracy: 0.9601 - val_loss: 0.8020 - val_accuracy: 0.8402 - lr: 2.8243e-04\n",
            "Epoch 123/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1324 - accuracy: 0.9594 - val_loss: 0.8039 - val_accuracy: 0.8436 - lr: 2.8243e-04\n",
            "Epoch 124/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1261 - accuracy: 0.9629 - val_loss: 0.8086 - val_accuracy: 0.8447 - lr: 2.8243e-04\n",
            "Epoch 125/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1347 - accuracy: 0.9592 - val_loss: 0.8126 - val_accuracy: 0.8402 - lr: 2.8243e-04\n",
            "Epoch 126/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1374 - accuracy: 0.9590 - val_loss: 0.8177 - val_accuracy: 0.8425 - lr: 2.8243e-04\n",
            "Epoch 127/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1296 - accuracy: 0.9606 - val_loss: 0.8135 - val_accuracy: 0.8482 - lr: 2.8243e-04\n",
            "Epoch 128/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1299 - accuracy: 0.9605 - val_loss: 0.8091 - val_accuracy: 0.8470 - lr: 2.8243e-04\n",
            "Epoch 129/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1354 - accuracy: 0.9589 - val_loss: 0.8005 - val_accuracy: 0.8425 - lr: 2.8243e-04\n",
            "Epoch 130/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1329 - accuracy: 0.9603 - val_loss: 0.7928 - val_accuracy: 0.8470 - lr: 2.8243e-04\n",
            "Epoch 131/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1264 - accuracy: 0.9631 - val_loss: 0.7854 - val_accuracy: 0.8413 - lr: 2.5419e-04\n",
            "Epoch 132/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1257 - accuracy: 0.9634 - val_loss: 0.8073 - val_accuracy: 0.8413 - lr: 2.5419e-04\n",
            "Epoch 133/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1297 - accuracy: 0.9624 - val_loss: 0.8042 - val_accuracy: 0.8447 - lr: 2.5419e-04\n",
            "Epoch 134/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1306 - accuracy: 0.9614 - val_loss: 0.8033 - val_accuracy: 0.8470 - lr: 2.5419e-04\n",
            "Epoch 135/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1243 - accuracy: 0.9632 - val_loss: 0.8133 - val_accuracy: 0.8470 - lr: 2.5419e-04\n",
            "Epoch 136/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1189 - accuracy: 0.9660 - val_loss: 0.8136 - val_accuracy: 0.8413 - lr: 2.5419e-04\n",
            "Epoch 137/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1225 - accuracy: 0.9625 - val_loss: 0.8185 - val_accuracy: 0.8413 - lr: 2.5419e-04\n",
            "Epoch 138/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1223 - accuracy: 0.9639 - val_loss: 0.7889 - val_accuracy: 0.8482 - lr: 2.5419e-04\n",
            "Epoch 139/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1308 - accuracy: 0.9617 - val_loss: 0.8283 - val_accuracy: 0.8413 - lr: 2.5419e-04\n",
            "Epoch 140/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1250 - accuracy: 0.9629 - val_loss: 0.8315 - val_accuracy: 0.8459 - lr: 2.5419e-04\n",
            "Epoch 141/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1220 - accuracy: 0.9641 - val_loss: 0.8306 - val_accuracy: 0.8459 - lr: 2.2877e-04\n",
            "Epoch 142/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.1152 - accuracy: 0.9652 - val_loss: 0.8022 - val_accuracy: 0.8447 - lr: 2.2877e-04\n",
            "Epoch 143/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1279 - accuracy: 0.9617 - val_loss: 0.8364 - val_accuracy: 0.8356 - lr: 2.2877e-04\n",
            "Epoch 144/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1138 - accuracy: 0.9671 - val_loss: 0.8390 - val_accuracy: 0.8459 - lr: 2.2877e-04\n",
            "Epoch 145/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1057 - accuracy: 0.9690 - val_loss: 0.8489 - val_accuracy: 0.8413 - lr: 2.2877e-04\n",
            "Epoch 146/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1176 - accuracy: 0.9661 - val_loss: 0.8421 - val_accuracy: 0.8459 - lr: 2.2877e-04\n",
            "Epoch 147/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1071 - accuracy: 0.9689 - val_loss: 0.8291 - val_accuracy: 0.8482 - lr: 2.2877e-04\n",
            "Epoch 148/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1147 - accuracy: 0.9667 - val_loss: 0.8318 - val_accuracy: 0.8482 - lr: 2.2877e-04\n",
            "Epoch 149/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1098 - accuracy: 0.9662 - val_loss: 0.8163 - val_accuracy: 0.8562 - lr: 2.2877e-04\n",
            "Epoch 150/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1077 - accuracy: 0.9694 - val_loss: 0.8297 - val_accuracy: 0.8459 - lr: 2.2877e-04\n",
            "Epoch 151/200\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.1052 - accuracy: 0.9678 - val_loss: 0.8301 - val_accuracy: 0.8459 - lr: 2.0589e-04\n",
            "Epoch 152/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1041 - accuracy: 0.9695 - val_loss: 0.8278 - val_accuracy: 0.8425 - lr: 2.0589e-04\n",
            "Epoch 153/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1075 - accuracy: 0.9669 - val_loss: 0.8322 - val_accuracy: 0.8470 - lr: 2.0589e-04\n",
            "Epoch 154/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1103 - accuracy: 0.9674 - val_loss: 0.8211 - val_accuracy: 0.8470 - lr: 2.0589e-04\n",
            "Epoch 155/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1034 - accuracy: 0.9684 - val_loss: 0.8342 - val_accuracy: 0.8505 - lr: 2.0589e-04\n",
            "Epoch 156/200\n",
            "247/247 [==============================] - 4s 14ms/step - loss: 0.1138 - accuracy: 0.9669 - val_loss: 0.8239 - val_accuracy: 0.8505 - lr: 2.0589e-04\n",
            "Epoch 157/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1061 - accuracy: 0.9694 - val_loss: 0.8434 - val_accuracy: 0.8493 - lr: 2.0589e-04\n",
            "Epoch 158/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1188 - accuracy: 0.9644 - val_loss: 0.8399 - val_accuracy: 0.8413 - lr: 2.0589e-04\n",
            "Epoch 159/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1051 - accuracy: 0.9703 - val_loss: 0.8495 - val_accuracy: 0.8470 - lr: 2.0589e-04\n",
            "Epoch 160/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.1032 - accuracy: 0.9676 - val_loss: 0.8182 - val_accuracy: 0.8550 - lr: 2.0589e-04\n",
            "Epoch 161/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1049 - accuracy: 0.9679 - val_loss: 0.8343 - val_accuracy: 0.8482 - lr: 1.8530e-04\n",
            "Epoch 162/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0998 - accuracy: 0.9685 - val_loss: 0.8387 - val_accuracy: 0.8505 - lr: 1.8530e-04\n",
            "Epoch 163/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0997 - accuracy: 0.9714 - val_loss: 0.8379 - val_accuracy: 0.8505 - lr: 1.8530e-04\n",
            "Epoch 164/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0981 - accuracy: 0.9698 - val_loss: 0.8422 - val_accuracy: 0.8493 - lr: 1.8530e-04\n",
            "Epoch 165/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0963 - accuracy: 0.9708 - val_loss: 0.8593 - val_accuracy: 0.8447 - lr: 1.8530e-04\n",
            "Epoch 166/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0999 - accuracy: 0.9695 - val_loss: 0.8498 - val_accuracy: 0.8447 - lr: 1.8530e-04\n",
            "Epoch 167/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0971 - accuracy: 0.9704 - val_loss: 0.8375 - val_accuracy: 0.8505 - lr: 1.8530e-04\n",
            "Epoch 168/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0934 - accuracy: 0.9723 - val_loss: 0.8798 - val_accuracy: 0.8482 - lr: 1.8530e-04\n",
            "Epoch 169/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0942 - accuracy: 0.9697 - val_loss: 0.8726 - val_accuracy: 0.8413 - lr: 1.8530e-04\n",
            "Epoch 170/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.1039 - accuracy: 0.9688 - val_loss: 0.8746 - val_accuracy: 0.8425 - lr: 1.8530e-04\n",
            "Epoch 171/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0930 - accuracy: 0.9716 - val_loss: 0.8749 - val_accuracy: 0.8447 - lr: 1.6677e-04\n",
            "Epoch 172/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.1052 - accuracy: 0.9681 - val_loss: 0.8748 - val_accuracy: 0.8436 - lr: 1.6677e-04\n",
            "Epoch 173/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0948 - accuracy: 0.9726 - val_loss: 0.8999 - val_accuracy: 0.8470 - lr: 1.6677e-04\n",
            "Epoch 174/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0913 - accuracy: 0.9717 - val_loss: 0.8699 - val_accuracy: 0.8493 - lr: 1.6677e-04\n",
            "Epoch 175/200\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.0939 - accuracy: 0.9704 - val_loss: 0.8661 - val_accuracy: 0.8505 - lr: 1.6677e-04\n",
            "Epoch 176/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0892 - accuracy: 0.9731 - val_loss: 0.8693 - val_accuracy: 0.8539 - lr: 1.6677e-04\n",
            "Epoch 177/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0945 - accuracy: 0.9728 - val_loss: 0.8588 - val_accuracy: 0.8527 - lr: 1.6677e-04\n",
            "Epoch 178/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0883 - accuracy: 0.9756 - val_loss: 0.8367 - val_accuracy: 0.8527 - lr: 1.6677e-04\n",
            "Epoch 179/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0981 - accuracy: 0.9684 - val_loss: 0.8560 - val_accuracy: 0.8493 - lr: 1.6677e-04\n",
            "Epoch 180/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.0904 - accuracy: 0.9728 - val_loss: 0.8725 - val_accuracy: 0.8436 - lr: 1.6677e-04\n",
            "Epoch 181/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0824 - accuracy: 0.9760 - val_loss: 0.8839 - val_accuracy: 0.8459 - lr: 1.5009e-04\n",
            "Epoch 182/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0897 - accuracy: 0.9735 - val_loss: 0.8755 - val_accuracy: 0.8447 - lr: 1.5009e-04\n",
            "Epoch 183/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0930 - accuracy: 0.9712 - val_loss: 0.8755 - val_accuracy: 0.8447 - lr: 1.5009e-04\n",
            "Epoch 184/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0979 - accuracy: 0.9718 - val_loss: 0.8822 - val_accuracy: 0.8436 - lr: 1.5009e-04\n",
            "Epoch 185/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0908 - accuracy: 0.9747 - val_loss: 0.8664 - val_accuracy: 0.8482 - lr: 1.5009e-04\n",
            "Epoch 186/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0871 - accuracy: 0.9744 - val_loss: 0.8847 - val_accuracy: 0.8470 - lr: 1.5009e-04\n",
            "Epoch 187/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0866 - accuracy: 0.9745 - val_loss: 0.8858 - val_accuracy: 0.8516 - lr: 1.5009e-04\n",
            "Epoch 188/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0791 - accuracy: 0.9777 - val_loss: 0.8892 - val_accuracy: 0.8493 - lr: 1.5009e-04\n",
            "Epoch 189/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.0900 - accuracy: 0.9737 - val_loss: 0.8956 - val_accuracy: 0.8493 - lr: 1.5009e-04\n",
            "Epoch 190/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0720 - accuracy: 0.9774 - val_loss: 0.8995 - val_accuracy: 0.8527 - lr: 1.5009e-04\n",
            "Epoch 191/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0901 - accuracy: 0.9722 - val_loss: 0.8934 - val_accuracy: 0.8493 - lr: 1.3509e-04\n",
            "Epoch 192/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0849 - accuracy: 0.9746 - val_loss: 0.8855 - val_accuracy: 0.8505 - lr: 1.3509e-04\n",
            "Epoch 193/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0798 - accuracy: 0.9771 - val_loss: 0.8846 - val_accuracy: 0.8505 - lr: 1.3509e-04\n",
            "Epoch 194/200\n",
            "247/247 [==============================] - 4s 15ms/step - loss: 0.0864 - accuracy: 0.9759 - val_loss: 0.8954 - val_accuracy: 0.8527 - lr: 1.3509e-04\n",
            "Epoch 195/200\n",
            "247/247 [==============================] - 3s 12ms/step - loss: 0.0764 - accuracy: 0.9791 - val_loss: 0.8832 - val_accuracy: 0.8482 - lr: 1.3509e-04\n",
            "Epoch 196/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0800 - accuracy: 0.9765 - val_loss: 0.8855 - val_accuracy: 0.8505 - lr: 1.3509e-04\n",
            "Epoch 197/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0876 - accuracy: 0.9747 - val_loss: 0.8822 - val_accuracy: 0.8493 - lr: 1.3509e-04\n",
            "Epoch 198/200\n",
            "247/247 [==============================] - 3s 13ms/step - loss: 0.0756 - accuracy: 0.9746 - val_loss: 0.9045 - val_accuracy: 0.8493 - lr: 1.3509e-04\n",
            "Epoch 199/200\n",
            "247/247 [==============================] - 3s 14ms/step - loss: 0.0770 - accuracy: 0.9764 - val_loss: 0.9049 - val_accuracy: 0.8436 - lr: 1.3509e-04\n",
            "Epoch 200/200\n",
            "247/247 [==============================] - 3s 11ms/step - loss: 0.0874 - accuracy: 0.9731 - val_loss: 0.8972 - val_accuracy: 0.8482 - lr: 1.3509e-04\n",
            "69/69 [==============================] - 1s 6ms/step\n",
            "69/69 [==============================] - 1s 4ms/step\n",
            "Ensemble Accuracy: 0.8423937871174052\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import tensorflow as tf\n",
        "\n",
        "# 데이터셋 디렉토리 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/data2'\n",
        "\n",
        "# 클래스 레이블 설정 (클래스별 디렉토리 이름으로 가정)\n",
        "class_labels = os.listdir(data_dir)\n",
        "\n",
        "# MFCC 계수 개수 설정\n",
        "n_mfcc = 12\n",
        "\n",
        "# 데이터셋과 레이블을 저장할 리스트\n",
        "X = []\n",
        "labels = []\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "for label_idx, label in enumerate(class_labels):\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        y, sr = librosa.load(file_path, sr=16000)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        X.append(mfccs.T)\n",
        "        labels.append(label)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "X = np.array(X)\n",
        "\n",
        "# 레이블을 정수형으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(class_labels)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# 최대 길이에 맞춰 MFCC 벡터를 패딩\n",
        "max_length = max(len(mfccs) for mfccs in X)\n",
        "X = np.array([np.pad(mfccs, ((0, max_length - len(mfccs)), (0, 0)), mode='constant') for mfccs in X])\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "# 첫 번째 모델 생성\n",
        "model1 = Sequential()\n",
        "# 모델1의 레이어 추가 및 컴파일 설정\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model1.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model1.add(MaxPooling2D((2, 2)))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model1.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model1.add(MaxPooling2D((2, 2)))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model1.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model1.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "model1.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경\n",
        "model1.add(Reshape((X_train.shape[1] // 8, (X_train.shape[2] // 8) * 256)))\n",
        "model1.add(LSTM(128, return_sequences=True))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(LSTM(64, return_sequences=True))\n",
        "model1.add(LSTM(32))\n",
        "model1.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model1.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델1 컴파일\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 두 번째 모델 생성\n",
        "model2 = Sequential()\n",
        "# 모델2의 레이어 추가 및 컴파일 설정\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "# Convolutional Layer 추가\n",
        "model2.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.3))  # Dropout 추가\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "# LSTM 레이어 변경\n",
        "model2.add(Reshape((X_train.shape[1] // 8, (X_train.shape[2] // 8) * 256)))\n",
        "model2.add(LSTM(128, return_sequences=True))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(LSTM(64, return_sequences=True))\n",
        "model2.add(LSTM(32))\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "# Output 레이어 변경\n",
        "model2.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "initial_lr = 0.001  # 초기 학습률 설정\n",
        "\n",
        "# Learning Rate를 조정할 함수 정의\n",
        "def lr_schedule(epoch):\n",
        "    decay_rate = 0.9   # 학습률 감소 비율\n",
        "    decay_steps = 10    # 학습률 감소 주기 (에폭 단위)\n",
        "    lr = initial_lr * decay_rate**(epoch // decay_steps)\n",
        "    return lr\n",
        "\n",
        "# Learning Rate Scheduler 콜백 생성\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# 모델 컴파일\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 두 모델 학습\n",
        "model1.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.1, callbacks=[LearningRateScheduler(lr_schedule)])\n",
        "model2.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.1, callbacks=[LearningRateScheduler(lr_schedule)])\n",
        "\n",
        "# 각 모델의 예측 결과 가져오기\n",
        "predictions1 = model1.predict(X_test)\n",
        "predictions2 = model2.predict(X_test)\n",
        "\n",
        "# 예측 결과 앙상블 (여기서는 간단히 평균 값을 사용)\n",
        "ensemble_predictions = (predictions1 + predictions2) / 2\n",
        "\n",
        "# 최종 예측 결과 평가\n",
        "ensemble_accuracy = np.mean(np.argmax(ensemble_predictions, axis=1) == np.argmax(y_test, axis=1))\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0s_tuOFxQzyX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}